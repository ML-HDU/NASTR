[2025-01-21 08:35:51,515 - train - INFO] - One GPU or CPU training mode start...
[2025-01-21 08:35:51,515 - train - WARNING] - You have chosen to deterministic training. This will fix random seed, turn on the CUDNN deterministic setting, turn off the CUDNN benchmark which can slow down your training considerably! 
[2025-01-21 08:35:54,393 - train - INFO] - Dataloader instances have finished. Train datasets: 3221637 Val datasets: 7665 Train_batch_size/gpu: 128 Val_batch_size/gpu: 128.
[2025-01-21 08:35:54,569 - train - INFO] - Model created, trainable parameters: 31.327794 MB.
[2025-01-21 08:35:54,570 - train - INFO] - Optimizer and lr_scheduler created.
[2025-01-21 08:35:54,570 - train - INFO] - Max_epochs: 30 Log_step_interval: 1000 Validation_step_interval: 3000.
[2025-01-21 08:35:54,570 - train - INFO] - Training start...
[2025-01-21 08:35:54,629 - trainer - WARNING] - Training is using GPU 0!
[2025-01-21 08:36:04,411 - trainer - INFO] - [Epoch Start] Epoch:[1/30] LR: 0.00003200
Validation result at 1 epoch: Word_acc: 0.000000 Word_acc_case_ins: 0.000000 Edit_distance_acc: -2.684955
[2025-01-21 08:36:05,788 - trainer - INFO] - Train Epoch:[1/30] Step:[1/25169] Loss: 4.604466 Loss_avg: 4.604466 LR: 0.00003200 Loss Fine: 4.604466 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:39:25,774 - trainer - INFO] - Train Epoch:[1/30] Step:[1000/25169] Loss: 2.989816 Loss_avg: 3.100872 LR: 0.00003731 Loss Fine: 2.989816 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:42:45,988 - trainer - INFO] - Train Epoch:[1/30] Step:[2000/25169] Loss: 2.828302 Loss_avg: 3.023374 LR: 0.00005308 Loss Fine: 2.828302 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:46:06,092 - trainer - INFO] - Train Epoch:[1/30] Step:[3000/25169] Loss: 2.816562 Loss_avg: 2.971181 LR: 0.00007888 Loss Fine: 2.816562 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:46:11,464 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[3000/25169] Word_acc: 0.012394 Word_acc_case_ins 0.012394 Edit_distance_acc: 0.147085
[2025-01-21 08:46:11,708 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.012394
[2025-01-21 08:49:31,985 - trainer - INFO] - Train Epoch:[1/30] Step:[4000/25169] Loss: 2.640965 Loss_avg: 2.917031 LR: 0.00011400 Loss Fine: 2.640965 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:52:52,204 - trainer - INFO] - Train Epoch:[1/30] Step:[5000/25169] Loss: 2.365728 Loss_avg: 2.830913 LR: 0.00015747 Loss Fine: 2.365728 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:56:12,207 - trainer - INFO] - Train Epoch:[1/30] Step:[6000/25169] Loss: 2.166024 Loss_avg: 2.729292 LR: 0.00020808 Loss Fine: 2.166024 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 08:56:17,628 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[6000/25169] Word_acc: 0.161774 Word_acc_case_ins 0.161774 Edit_distance_acc: 0.476546
[2025-01-21 08:56:17,958 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.161774
[2025-01-21 08:59:38,275 - trainer - INFO] - Train Epoch:[1/30] Step:[7000/25169] Loss: 2.044778 Loss_avg: 2.633386 LR: 0.00026443 Loss Fine: 2.044778 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:02:58,389 - trainer - INFO] - Train Epoch:[1/30] Step:[8000/25169] Loss: 1.906787 Loss_avg: 2.547775 LR: 0.00032498 Loss Fine: 1.906787 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:06:18,596 - trainer - INFO] - Train Epoch:[1/30] Step:[9000/25169] Loss: 1.914785 Loss_avg: 2.471848 LR: 0.00038804 Loss Fine: 1.914785 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:06:24,112 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[9000/25169] Word_acc: 0.257534 Word_acc_case_ins 0.257534 Edit_distance_acc: 0.560980
[2025-01-21 09:06:24,454 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.257534
[2025-01-21 09:09:44,548 - trainer - INFO] - Train Epoch:[1/30] Step:[10000/25169] Loss: 1.650353 Loss_avg: 2.404638 LR: 0.00045187 Loss Fine: 1.650353 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:13:04,811 - trainer - INFO] - Train Epoch:[1/30] Step:[11000/25169] Loss: 1.704030 Loss_avg: 2.345551 LR: 0.00051472 Loss Fine: 1.704030 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:16:24,936 - trainer - INFO] - Train Epoch:[1/30] Step:[12000/25169] Loss: 1.577069 Loss_avg: 2.292475 LR: 0.00057483 Loss Fine: 1.577069 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:16:30,399 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[12000/25169] Word_acc: 0.329159 Word_acc_case_ins 0.329159 Edit_distance_acc: 0.616042
[2025-01-21 09:16:30,736 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.329159
[2025-01-21 09:19:50,800 - trainer - INFO] - Train Epoch:[1/30] Step:[13000/25169] Loss: 1.761019 Loss_avg: 2.244880 LR: 0.00063056 Loss Fine: 1.761019 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:23:10,956 - trainer - INFO] - Train Epoch:[1/30] Step:[14000/25169] Loss: 1.469144 Loss_avg: 2.202019 LR: 0.00068035 Loss Fine: 1.469144 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:26:31,080 - trainer - INFO] - Train Epoch:[1/30] Step:[15000/25169] Loss: 1.918496 Loss_avg: 2.163418 LR: 0.00072284 Loss Fine: 1.918496 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:26:36,591 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[15000/25169] Word_acc: 0.358513 Word_acc_case_ins 0.358513 Edit_distance_acc: 0.666069
[2025-01-21 09:26:36,916 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.358513
[2025-01-21 09:29:56,997 - trainer - INFO] - Train Epoch:[1/30] Step:[16000/25169] Loss: 1.458243 Loss_avg: 2.127306 LR: 0.00075685 Loss Fine: 1.458243 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:33:17,285 - trainer - INFO] - Train Epoch:[1/30] Step:[17000/25169] Loss: 1.674061 Loss_avg: 2.093841 LR: 0.00078144 Loss Fine: 1.674061 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:36:37,451 - trainer - INFO] - Train Epoch:[1/30] Step:[18000/25169] Loss: 1.589091 Loss_avg: 2.062737 LR: 0.00079593 Loss Fine: 1.589091 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:36:42,889 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[18000/25169] Word_acc: 0.388519 Word_acc_case_ins 0.388519 Edit_distance_acc: 0.677612
[2025-01-21 09:36:43,228 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.388519
[2025-01-21 09:40:03,443 - trainer - INFO] - Train Epoch:[1/30] Step:[19000/25169] Loss: 1.314978 Loss_avg: 2.034268 LR: 0.00080000 Loss Fine: 1.314978 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:43:23,791 - trainer - INFO] - Train Epoch:[1/30] Step:[20000/25169] Loss: 1.297613 Loss_avg: 2.006444 LR: 0.00080000 Loss Fine: 1.297613 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:46:43,953 - trainer - INFO] - Train Epoch:[1/30] Step:[21000/25169] Loss: 1.352687 Loss_avg: 1.980204 LR: 0.00079998 Loss Fine: 1.352687 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:46:49,360 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[21000/25169] Word_acc: 0.470711 Word_acc_case_ins 0.470711 Edit_distance_acc: 0.727565
[2025-01-21 09:46:49,703 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.470711
[2025-01-21 09:50:10,012 - trainer - INFO] - Train Epoch:[1/30] Step:[22000/25169] Loss: 1.202937 Loss_avg: 1.955065 LR: 0.00079996 Loss Fine: 1.202937 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:53:30,235 - trainer - INFO] - Train Epoch:[1/30] Step:[23000/25169] Loss: 1.436838 Loss_avg: 1.931482 LR: 0.00079994 Loss Fine: 1.436838 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:56:50,603 - trainer - INFO] - Train Epoch:[1/30] Step:[24000/25169] Loss: 1.635608 Loss_avg: 1.908552 LR: 0.00079990 Loss Fine: 1.635608 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 09:56:56,024 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[24000/25169] Word_acc: 0.487671 Word_acc_case_ins 0.487671 Edit_distance_acc: 0.740729
[2025-01-21 09:56:56,324 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.487671
[2025-01-21 10:00:16,477 - trainer - INFO] - Train Epoch:[1/30] Step:[25000/25169] Loss: 1.402488 Loss_avg: 1.886748 LR: 0.00079986 Loss Fine: 1.402488 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:00:55,931 - trainer - INFO] - [Epoch End] Epoch:[1/30] Loss: 1.883152 LR: 0.00079986
 Validation result after 1 epoch: Word_acc: 0.500718 Word_acc_case_ins: 0.500718 Edit_distance_acc: 0.751363
[2025-01-21 10:00:56,262 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.500718
[2025-01-21 10:00:57,864 - trainer - INFO] - Train Epoch:[2/30] Step:[1/25169] Loss: 1.390211 Loss_avg: 1.390211 LR: 0.00079986 Loss Fine: 1.390211 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:04:17,832 - trainer - INFO] - Train Epoch:[2/30] Step:[1000/25169] Loss: 1.360647 Loss_avg: 1.335890 LR: 0.00079981 Loss Fine: 1.360647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:07:37,945 - trainer - INFO] - Train Epoch:[2/30] Step:[2000/25169] Loss: 1.334787 Loss_avg: 1.331899 LR: 0.00079975 Loss Fine: 1.334787 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:10:58,333 - trainer - INFO] - Train Epoch:[2/30] Step:[3000/25169] Loss: 1.320096 Loss_avg: 1.324678 LR: 0.00079969 Loss Fine: 1.320096 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:11:03,765 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[3000/25169] Word_acc: 0.548858 Word_acc_case_ins 0.548858 Edit_distance_acc: 0.779974
[2025-01-21 10:11:04,081 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.548858
[2025-01-21 10:14:24,395 - trainer - INFO] - Train Epoch:[2/30] Step:[4000/25169] Loss: 1.301911 Loss_avg: 1.319070 LR: 0.00079961 Loss Fine: 1.301911 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:17:44,598 - trainer - INFO] - Train Epoch:[2/30] Step:[5000/25169] Loss: 1.336634 Loss_avg: 1.310852 LR: 0.00079954 Loss Fine: 1.336634 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:21:04,847 - trainer - INFO] - Train Epoch:[2/30] Step:[6000/25169] Loss: 1.116153 Loss_avg: 1.303690 LR: 0.00079945 Loss Fine: 1.116153 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:21:10,241 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[6000/25169] Word_acc: 0.577821 Word_acc_case_ins 0.577821 Edit_distance_acc: 0.800432
[2025-01-21 10:21:10,566 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.577821
[2025-01-21 10:24:30,831 - trainer - INFO] - Train Epoch:[2/30] Step:[7000/25169] Loss: 1.164269 Loss_avg: 1.297735 LR: 0.00079936 Loss Fine: 1.164269 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:27:51,280 - trainer - INFO] - Train Epoch:[2/30] Step:[8000/25169] Loss: 1.333755 Loss_avg: 1.291641 LR: 0.00079926 Loss Fine: 1.333755 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:31:11,341 - trainer - INFO] - Train Epoch:[2/30] Step:[9000/25169] Loss: 1.403417 Loss_avg: 1.285667 LR: 0.00079915 Loss Fine: 1.403417 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:31:16,774 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[9000/25169] Word_acc: 0.571429 Word_acc_case_ins 0.571429 Edit_distance_acc: 0.791394
[2025-01-21 10:34:36,954 - trainer - INFO] - Train Epoch:[2/30] Step:[10000/25169] Loss: 1.089273 Loss_avg: 1.280412 LR: 0.00079903 Loss Fine: 1.089273 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:37:57,156 - trainer - INFO] - Train Epoch:[2/30] Step:[11000/25169] Loss: 1.302945 Loss_avg: 1.274834 LR: 0.00079891 Loss Fine: 1.302945 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:41:17,379 - trainer - INFO] - Train Epoch:[2/30] Step:[12000/25169] Loss: 1.017946 Loss_avg: 1.268996 LR: 0.00079878 Loss Fine: 1.017946 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:41:22,762 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[12000/25169] Word_acc: 0.582257 Word_acc_case_ins 0.582257 Edit_distance_acc: 0.799597
[2025-01-21 10:41:23,101 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.582257
[2025-01-21 10:44:43,322 - trainer - INFO] - Train Epoch:[2/30] Step:[13000/25169] Loss: 1.425044 Loss_avg: 1.263354 LR: 0.00079865 Loss Fine: 1.425044 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:48:03,831 - trainer - INFO] - Train Epoch:[2/30] Step:[14000/25169] Loss: 1.096679 Loss_avg: 1.258053 LR: 0.00079850 Loss Fine: 1.096679 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:51:23,976 - trainer - INFO] - Train Epoch:[2/30] Step:[15000/25169] Loss: 1.207474 Loss_avg: 1.252447 LR: 0.00079835 Loss Fine: 1.207474 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:51:29,407 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[15000/25169] Word_acc: 0.603914 Word_acc_case_ins 0.603914 Edit_distance_acc: 0.813621
[2025-01-21 10:51:29,717 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.603914
[2025-01-21 10:54:49,942 - trainer - INFO] - Train Epoch:[2/30] Step:[16000/25169] Loss: 1.268909 Loss_avg: 1.247464 LR: 0.00079819 Loss Fine: 1.268909 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 10:58:10,224 - trainer - INFO] - Train Epoch:[2/30] Step:[17000/25169] Loss: 1.082584 Loss_avg: 1.241841 LR: 0.00079803 Loss Fine: 1.082584 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:01:30,443 - trainer - INFO] - Train Epoch:[2/30] Step:[18000/25169] Loss: 1.176127 Loss_avg: 1.235875 LR: 0.00079785 Loss Fine: 1.176127 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:01:35,871 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[18000/25169] Word_acc: 0.636399 Word_acc_case_ins 0.636399 Edit_distance_acc: 0.823714
[2025-01-21 11:01:36,180 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.636399
[2025-01-21 11:04:56,382 - trainer - INFO] - Train Epoch:[2/30] Step:[19000/25169] Loss: 0.952316 Loss_avg: 1.230089 LR: 0.00079767 Loss Fine: 0.952316 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:08:17,064 - trainer - INFO] - Train Epoch:[2/30] Step:[20000/25169] Loss: 0.905211 Loss_avg: 1.224280 LR: 0.00079748 Loss Fine: 0.905211 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:11:37,353 - trainer - INFO] - Train Epoch:[2/30] Step:[21000/25169] Loss: 0.987753 Loss_avg: 1.218218 LR: 0.00079729 Loss Fine: 0.987753 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:11:42,815 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[21000/25169] Word_acc: 0.651402 Word_acc_case_ins 0.651402 Edit_distance_acc: 0.835036
[2025-01-21 11:11:43,140 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.651402
[2025-01-21 11:15:03,343 - trainer - INFO] - Train Epoch:[2/30] Step:[22000/25169] Loss: 1.177021 Loss_avg: 1.212356 LR: 0.00079709 Loss Fine: 1.177021 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:18:23,403 - trainer - INFO] - Train Epoch:[2/30] Step:[23000/25169] Loss: 0.983681 Loss_avg: 1.206186 LR: 0.00079688 Loss Fine: 0.983681 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:21:43,537 - trainer - INFO] - Train Epoch:[2/30] Step:[24000/25169] Loss: 1.111341 Loss_avg: 1.200101 LR: 0.00079666 Loss Fine: 1.111341 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:21:48,990 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[24000/25169] Word_acc: 0.662100 Word_acc_case_ins 0.662100 Edit_distance_acc: 0.844491
[2025-01-21 11:21:49,305 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.662100
[2025-01-21 11:25:09,553 - trainer - INFO] - Train Epoch:[2/30] Step:[25000/25169] Loss: 1.116134 Loss_avg: 1.193621 LR: 0.00079644 Loss Fine: 1.116134 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:25:49,044 - trainer - INFO] - [Epoch End] Epoch:[2/30] Loss: 1.192747 LR: 0.00079640
 Validation result after 2 epoch: Word_acc: 0.670320 Word_acc_case_ins: 0.670320 Edit_distance_acc: 0.848666
[2025-01-21 11:25:49,374 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.670320
[2025-01-21 11:25:50,855 - trainer - INFO] - Train Epoch:[3/30] Step:[1/25169] Loss: 0.975459 Loss_avg: 0.975459 LR: 0.00079640 Loss Fine: 0.975459 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:29:10,980 - trainer - INFO] - Train Epoch:[3/30] Step:[1000/25169] Loss: 0.953545 Loss_avg: 1.113186 LR: 0.00079617 Loss Fine: 0.953545 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:32:31,834 - trainer - INFO] - Train Epoch:[3/30] Step:[2000/25169] Loss: 0.999575 Loss_avg: 1.065777 LR: 0.00079593 Loss Fine: 0.999575 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:35:52,015 - trainer - INFO] - Train Epoch:[3/30] Step:[3000/25169] Loss: 0.964545 Loss_avg: 1.043307 LR: 0.00079568 Loss Fine: 0.964545 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:35:57,437 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[3000/25169] Word_acc: 0.696151 Word_acc_case_ins 0.696151 Edit_distance_acc: 0.864581
[2025-01-21 11:35:57,775 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.696151
[2025-01-21 11:39:18,034 - trainer - INFO] - Train Epoch:[3/30] Step:[4000/25169] Loss: 0.957504 Loss_avg: 1.029208 LR: 0.00079543 Loss Fine: 0.957504 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:42:38,304 - trainer - INFO] - Train Epoch:[3/30] Step:[5000/25169] Loss: 1.021448 Loss_avg: 1.018922 LR: 0.00079517 Loss Fine: 1.021448 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:45:58,491 - trainer - INFO] - Train Epoch:[3/30] Step:[6000/25169] Loss: 0.999613 Loss_avg: 1.014862 LR: 0.00079490 Loss Fine: 0.999613 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:46:03,922 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[6000/25169] Word_acc: 0.696934 Word_acc_case_ins 0.696934 Edit_distance_acc: 0.861486
[2025-01-21 11:46:04,260 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.696934
[2025-01-21 11:49:24,525 - trainer - INFO] - Train Epoch:[3/30] Step:[7000/25169] Loss: 1.123823 Loss_avg: 1.006157 LR: 0.00079462 Loss Fine: 1.123823 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:52:44,705 - trainer - INFO] - Train Epoch:[3/30] Step:[8000/25169] Loss: 0.821285 Loss_avg: 0.997676 LR: 0.00079434 Loss Fine: 0.821285 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:56:04,904 - trainer - INFO] - Train Epoch:[3/30] Step:[9000/25169] Loss: 0.826353 Loss_avg: 0.990803 LR: 0.00079405 Loss Fine: 0.826353 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 11:56:10,346 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[9000/25169] Word_acc: 0.719765 Word_acc_case_ins 0.719765 Edit_distance_acc: 0.872047
[2025-01-21 11:56:10,654 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.719765
[2025-01-21 11:59:30,902 - trainer - INFO] - Train Epoch:[3/30] Step:[10000/25169] Loss: 1.016523 Loss_avg: 0.983892 LR: 0.00079376 Loss Fine: 1.016523 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:02:51,648 - trainer - INFO] - Train Epoch:[3/30] Step:[11000/25169] Loss: 0.955692 Loss_avg: 0.978375 LR: 0.00079345 Loss Fine: 0.955692 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:06:11,848 - trainer - INFO] - Train Epoch:[3/30] Step:[12000/25169] Loss: 0.801113 Loss_avg: 0.972956 LR: 0.00079314 Loss Fine: 0.801113 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:06:17,289 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[12000/25169] Word_acc: 0.711285 Word_acc_case_ins 0.711285 Edit_distance_acc: 0.870500
[2025-01-21 12:09:37,671 - trainer - INFO] - Train Epoch:[3/30] Step:[13000/25169] Loss: 0.815772 Loss_avg: 0.967612 LR: 0.00079282 Loss Fine: 0.815772 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:12:57,989 - trainer - INFO] - Train Epoch:[3/30] Step:[14000/25169] Loss: 0.690420 Loss_avg: 0.962448 LR: 0.00079250 Loss Fine: 0.690420 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:16:18,303 - trainer - INFO] - Train Epoch:[3/30] Step:[15000/25169] Loss: 0.929415 Loss_avg: 0.957654 LR: 0.00079216 Loss Fine: 0.929415 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:16:23,797 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[15000/25169] Word_acc: 0.540378 Word_acc_case_ins 0.540378 Edit_distance_acc: 0.835797
[2025-01-21 12:19:43,989 - trainer - INFO] - Train Epoch:[3/30] Step:[16000/25169] Loss: 0.918876 Loss_avg: 0.952601 LR: 0.00079182 Loss Fine: 0.918876 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:23:04,167 - trainer - INFO] - Train Epoch:[3/30] Step:[17000/25169] Loss: 0.965682 Loss_avg: 0.947731 LR: 0.00079148 Loss Fine: 0.965682 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:26:24,403 - trainer - INFO] - Train Epoch:[3/30] Step:[18000/25169] Loss: 0.761468 Loss_avg: 0.943383 LR: 0.00079112 Loss Fine: 0.761468 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:26:29,863 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[18000/25169] Word_acc: 0.752642 Word_acc_case_ins 0.752642 Edit_distance_acc: 0.892062
[2025-01-21 12:26:30,176 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.752642
[2025-01-21 12:29:50,380 - trainer - INFO] - Train Epoch:[3/30] Step:[19000/25169] Loss: 1.024854 Loss_avg: 0.939115 LR: 0.00079076 Loss Fine: 1.024854 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:33:11,231 - trainer - INFO] - Train Epoch:[3/30] Step:[20000/25169] Loss: 0.843885 Loss_avg: 0.935498 LR: 0.00079039 Loss Fine: 0.843885 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:36:31,363 - trainer - INFO] - Train Epoch:[3/30] Step:[21000/25169] Loss: 0.909329 Loss_avg: 0.931598 LR: 0.00079002 Loss Fine: 0.909329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:36:36,824 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[21000/25169] Word_acc: 0.759948 Word_acc_case_ins 0.759948 Edit_distance_acc: 0.895108
[2025-01-21 12:36:37,129 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.759948
[2025-01-21 12:39:57,349 - trainer - INFO] - Train Epoch:[3/30] Step:[22000/25169] Loss: 0.828435 Loss_avg: 0.927758 LR: 0.00078964 Loss Fine: 0.828435 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:43:17,521 - trainer - INFO] - Train Epoch:[3/30] Step:[23000/25169] Loss: 0.766986 Loss_avg: 0.923743 LR: 0.00078925 Loss Fine: 0.766986 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:46:37,689 - trainer - INFO] - Train Epoch:[3/30] Step:[24000/25169] Loss: 0.964490 Loss_avg: 0.920148 LR: 0.00078885 Loss Fine: 0.964490 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:46:43,141 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[24000/25169] Word_acc: 0.748337 Word_acc_case_ins 0.748337 Edit_distance_acc: 0.890712
[2025-01-21 12:50:03,380 - trainer - INFO] - Train Epoch:[3/30] Step:[25000/25169] Loss: 0.743499 Loss_avg: 0.916564 LR: 0.00078845 Loss Fine: 0.743499 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:50:42,844 - trainer - INFO] - [Epoch End] Epoch:[3/30] Loss: 0.915926 LR: 0.00078838
 Validation result after 3 epoch: Word_acc: 0.770907 Word_acc_case_ins: 0.770907 Edit_distance_acc: 0.898767
[2025-01-21 12:50:43,172 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.770907
[2025-01-21 12:50:44,702 - trainer - INFO] - Train Epoch:[4/30] Step:[1/25169] Loss: 0.891784 Loss_avg: 0.891784 LR: 0.00078838 Loss Fine: 0.891784 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:54:04,743 - trainer - INFO] - Train Epoch:[4/30] Step:[1000/25169] Loss: 0.709571 Loss_avg: 0.825521 LR: 0.00078796 Loss Fine: 0.709571 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 12:57:24,979 - trainer - INFO] - Train Epoch:[4/30] Step:[2000/25169] Loss: 0.574341 Loss_avg: 0.822673 LR: 0.00078755 Loss Fine: 0.574341 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:00:45,183 - trainer - INFO] - Train Epoch:[4/30] Step:[3000/25169] Loss: 0.617590 Loss_avg: 0.817156 LR: 0.00078712 Loss Fine: 0.617590 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:00:50,583 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[3000/25169] Word_acc: 0.770385 Word_acc_case_ins 0.770385 Edit_distance_acc: 0.897760
[2025-01-21 13:04:10,834 - trainer - INFO] - Train Epoch:[4/30] Step:[4000/25169] Loss: 0.796442 Loss_avg: 0.817865 LR: 0.00078669 Loss Fine: 0.796442 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:07:31,021 - trainer - INFO] - Train Epoch:[4/30] Step:[5000/25169] Loss: 0.857003 Loss_avg: 0.814954 LR: 0.00078625 Loss Fine: 0.857003 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:10:52,196 - trainer - INFO] - Train Epoch:[4/30] Step:[6000/25169] Loss: 0.756368 Loss_avg: 0.813006 LR: 0.00078580 Loss Fine: 0.756368 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:10:57,655 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[6000/25169] Word_acc: 0.781474 Word_acc_case_ins 0.781474 Edit_distance_acc: 0.908836
[2025-01-21 13:10:57,954 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.781474
[2025-01-21 13:14:18,221 - trainer - INFO] - Train Epoch:[4/30] Step:[7000/25169] Loss: 1.079679 Loss_avg: 0.810864 LR: 0.00078534 Loss Fine: 1.079679 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:17:38,488 - trainer - INFO] - Train Epoch:[4/30] Step:[8000/25169] Loss: 0.762181 Loss_avg: 0.809290 LR: 0.00078488 Loss Fine: 0.762181 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:20:58,755 - trainer - INFO] - Train Epoch:[4/30] Step:[9000/25169] Loss: 0.803324 Loss_avg: 0.807009 LR: 0.00078441 Loss Fine: 0.803324 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:21:04,216 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[9000/25169] Word_acc: 0.783431 Word_acc_case_ins 0.783431 Edit_distance_acc: 0.907240
[2025-01-21 13:21:04,540 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.783431
[2025-01-21 13:24:24,847 - trainer - INFO] - Train Epoch:[4/30] Step:[10000/25169] Loss: 0.682388 Loss_avg: 0.805288 LR: 0.00078394 Loss Fine: 0.682388 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:27:45,069 - trainer - INFO] - Train Epoch:[4/30] Step:[11000/25169] Loss: 0.830259 Loss_avg: 0.803593 LR: 0.00078346 Loss Fine: 0.830259 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:31:05,285 - trainer - INFO] - Train Epoch:[4/30] Step:[12000/25169] Loss: 1.054329 Loss_avg: 0.802334 LR: 0.00078297 Loss Fine: 1.054329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:31:10,725 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[12000/25169] Word_acc: 0.778474 Word_acc_case_ins 0.778474 Edit_distance_acc: 0.902328
[2025-01-21 13:34:30,952 - trainer - INFO] - Train Epoch:[4/30] Step:[13000/25169] Loss: 0.724829 Loss_avg: 0.800511 LR: 0.00078247 Loss Fine: 0.724829 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:37:51,180 - trainer - INFO] - Train Epoch:[4/30] Step:[14000/25169] Loss: 0.825134 Loss_avg: 0.798872 LR: 0.00078197 Loss Fine: 0.825134 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:41:11,367 - trainer - INFO] - Train Epoch:[4/30] Step:[15000/25169] Loss: 0.817638 Loss_avg: 0.797218 LR: 0.00078146 Loss Fine: 0.817638 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:41:16,827 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[15000/25169] Word_acc: 0.785910 Word_acc_case_ins 0.785910 Edit_distance_acc: 0.909499
[2025-01-21 13:41:17,133 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.785910
[2025-01-21 13:44:37,466 - trainer - INFO] - Train Epoch:[4/30] Step:[16000/25169] Loss: 0.624451 Loss_avg: 0.795571 LR: 0.00078094 Loss Fine: 0.624451 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:47:57,783 - trainer - INFO] - Train Epoch:[4/30] Step:[17000/25169] Loss: 0.756485 Loss_avg: 0.794303 LR: 0.00078042 Loss Fine: 0.756485 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:51:18,995 - trainer - INFO] - Train Epoch:[4/30] Step:[18000/25169] Loss: 0.764926 Loss_avg: 0.792715 LR: 0.00077989 Loss Fine: 0.764926 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:51:24,432 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[18000/25169] Word_acc: 0.790868 Word_acc_case_ins 0.790868 Edit_distance_acc: 0.907879
[2025-01-21 13:51:24,770 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.790868
[2025-01-21 13:54:45,011 - trainer - INFO] - Train Epoch:[4/30] Step:[19000/25169] Loss: 0.705056 Loss_avg: 0.790545 LR: 0.00077935 Loss Fine: 0.705056 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 13:58:05,235 - trainer - INFO] - Train Epoch:[4/30] Step:[20000/25169] Loss: 0.741378 Loss_avg: 0.788963 LR: 0.00077880 Loss Fine: 0.741378 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:01:25,540 - trainer - INFO] - Train Epoch:[4/30] Step:[21000/25169] Loss: 0.763256 Loss_avg: 0.787669 LR: 0.00077825 Loss Fine: 0.763256 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:01:30,981 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[21000/25169] Word_acc: 0.796086 Word_acc_case_ins 0.796086 Edit_distance_acc: 0.913675
[2025-01-21 14:01:31,297 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.796086
[2025-01-21 14:04:51,565 - trainer - INFO] - Train Epoch:[4/30] Step:[22000/25169] Loss: 0.759896 Loss_avg: 0.786479 LR: 0.00077769 Loss Fine: 0.759896 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:08:11,840 - trainer - INFO] - Train Epoch:[4/30] Step:[23000/25169] Loss: 0.805461 Loss_avg: 0.784884 LR: 0.00077713 Loss Fine: 0.805461 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:11:32,103 - trainer - INFO] - Train Epoch:[4/30] Step:[24000/25169] Loss: 0.546679 Loss_avg: 0.782936 LR: 0.00077655 Loss Fine: 0.546679 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:11:37,606 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[24000/25169] Word_acc: 0.798695 Word_acc_case_ins 0.798695 Edit_distance_acc: 0.915615
[2025-01-21 14:11:37,905 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.798695
[2025-01-21 14:14:58,300 - trainer - INFO] - Train Epoch:[4/30] Step:[25000/25169] Loss: 1.018197 Loss_avg: 0.781114 LR: 0.00077598 Loss Fine: 1.018197 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:15:37,757 - trainer - INFO] - [Epoch End] Epoch:[4/30] Loss: 0.780880 LR: 0.00077588
 Validation result after 4 epoch: Word_acc: 0.803392 Word_acc_case_ins: 0.803392 Edit_distance_acc: 0.918635
[2025-01-21 14:15:38,107 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.803392
[2025-01-21 14:15:39,806 - trainer - INFO] - Train Epoch:[5/30] Step:[1/25169] Loss: 0.939148 Loss_avg: 0.939148 LR: 0.00077588 Loss Fine: 0.939148 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:18:59,774 - trainer - INFO] - Train Epoch:[5/30] Step:[1000/25169] Loss: 0.676914 Loss_avg: 0.748946 LR: 0.00077529 Loss Fine: 0.676914 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:22:19,898 - trainer - INFO] - Train Epoch:[5/30] Step:[2000/25169] Loss: 0.558624 Loss_avg: 0.741020 LR: 0.00077470 Loss Fine: 0.558624 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:25:40,079 - trainer - INFO] - Train Epoch:[5/30] Step:[3000/25169] Loss: 0.644882 Loss_avg: 0.739684 LR: 0.00077409 Loss Fine: 0.644882 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:25:45,527 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[3000/25169] Word_acc: 0.803914 Word_acc_case_ins 0.803914 Edit_distance_acc: 0.917309
[2025-01-21 14:25:45,840 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.803914
[2025-01-21 14:29:06,045 - trainer - INFO] - Train Epoch:[5/30] Step:[4000/25169] Loss: 0.882341 Loss_avg: 0.739159 LR: 0.00077349 Loss Fine: 0.882341 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:32:26,211 - trainer - INFO] - Train Epoch:[5/30] Step:[5000/25169] Loss: 0.746764 Loss_avg: 0.737843 LR: 0.00077287 Loss Fine: 0.746764 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:35:46,401 - trainer - INFO] - Train Epoch:[5/30] Step:[6000/25169] Loss: 0.756850 Loss_avg: 0.736784 LR: 0.00077225 Loss Fine: 0.756850 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:35:51,843 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[6000/25169] Word_acc: 0.803131 Word_acc_case_ins 0.803131 Edit_distance_acc: 0.916941
[2025-01-21 14:39:13,124 - trainer - INFO] - Train Epoch:[5/30] Step:[7000/25169] Loss: 0.573137 Loss_avg: 0.738550 LR: 0.00077162 Loss Fine: 0.573137 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:42:33,459 - trainer - INFO] - Train Epoch:[5/30] Step:[8000/25169] Loss: 0.561190 Loss_avg: 0.736874 LR: 0.00077099 Loss Fine: 0.561190 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:45:53,740 - trainer - INFO] - Train Epoch:[5/30] Step:[9000/25169] Loss: 0.599401 Loss_avg: 0.735614 LR: 0.00077035 Loss Fine: 0.599401 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:45:59,180 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[9000/25169] Word_acc: 0.808219 Word_acc_case_ins 0.808219 Edit_distance_acc: 0.916081
[2025-01-21 14:45:59,491 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.808219
[2025-01-21 14:49:19,744 - trainer - INFO] - Train Epoch:[5/30] Step:[10000/25169] Loss: 0.764991 Loss_avg: 0.735412 LR: 0.00076970 Loss Fine: 0.764991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:52:39,962 - trainer - INFO] - Train Epoch:[5/30] Step:[11000/25169] Loss: 0.653564 Loss_avg: 0.733675 LR: 0.00076904 Loss Fine: 0.653564 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:56:00,140 - trainer - INFO] - Train Epoch:[5/30] Step:[12000/25169] Loss: 0.899445 Loss_avg: 0.732574 LR: 0.00076838 Loss Fine: 0.899445 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 14:56:05,603 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[12000/25169] Word_acc: 0.807828 Word_acc_case_ins 0.807828 Edit_distance_acc: 0.918930
[2025-01-21 14:59:25,759 - trainer - INFO] - Train Epoch:[5/30] Step:[13000/25169] Loss: 0.509538 Loss_avg: 0.731576 LR: 0.00076771 Loss Fine: 0.509538 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:02:45,952 - trainer - INFO] - Train Epoch:[5/30] Step:[14000/25169] Loss: 0.722480 Loss_avg: 0.730790 LR: 0.00076704 Loss Fine: 0.722480 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:06:06,119 - trainer - INFO] - Train Epoch:[5/30] Step:[15000/25169] Loss: 0.772140 Loss_avg: 0.730131 LR: 0.00076636 Loss Fine: 0.772140 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:06:11,604 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[15000/25169] Word_acc: 0.812524 Word_acc_case_ins 0.812524 Edit_distance_acc: 0.920625
[2025-01-21 15:06:11,909 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.812524
[2025-01-21 15:09:32,149 - trainer - INFO] - Train Epoch:[5/30] Step:[16000/25169] Loss: 0.741343 Loss_avg: 0.728652 LR: 0.00076567 Loss Fine: 0.741343 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:12:52,349 - trainer - INFO] - Train Epoch:[5/30] Step:[17000/25169] Loss: 0.740750 Loss_avg: 0.727737 LR: 0.00076497 Loss Fine: 0.740750 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:16:12,526 - trainer - INFO] - Train Epoch:[5/30] Step:[18000/25169] Loss: 0.669166 Loss_avg: 0.726695 LR: 0.00076427 Loss Fine: 0.669166 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:16:17,977 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[18000/25169] Word_acc: 0.826093 Word_acc_case_ins 0.826093 Edit_distance_acc: 0.926494
[2025-01-21 15:16:18,291 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.826093
[2025-01-21 15:19:38,453 - trainer - INFO] - Train Epoch:[5/30] Step:[19000/25169] Loss: 0.663076 Loss_avg: 0.725583 LR: 0.00076356 Loss Fine: 0.663076 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:22:58,687 - trainer - INFO] - Train Epoch:[5/30] Step:[20000/25169] Loss: 0.549434 Loss_avg: 0.724461 LR: 0.00076285 Loss Fine: 0.549434 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:26:18,923 - trainer - INFO] - Train Epoch:[5/30] Step:[21000/25169] Loss: 0.597697 Loss_avg: 0.723766 LR: 0.00076212 Loss Fine: 0.597697 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:26:24,371 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[21000/25169] Word_acc: 0.808219 Word_acc_case_ins 0.808219 Edit_distance_acc: 0.919495
[2025-01-21 15:29:44,629 - trainer - INFO] - Train Epoch:[5/30] Step:[22000/25169] Loss: 0.787559 Loss_avg: 0.722813 LR: 0.00076140 Loss Fine: 0.787559 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:33:06,033 - trainer - INFO] - Train Epoch:[5/30] Step:[23000/25169] Loss: 0.616452 Loss_avg: 0.721722 LR: 0.00076066 Loss Fine: 0.616452 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:36:26,376 - trainer - INFO] - Train Epoch:[5/30] Step:[24000/25169] Loss: 0.573466 Loss_avg: 0.720996 LR: 0.00075992 Loss Fine: 0.573466 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:36:31,827 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[24000/25169] Word_acc: 0.821396 Word_acc_case_ins 0.821396 Edit_distance_acc: 0.927305
[2025-01-21 15:39:52,043 - trainer - INFO] - Train Epoch:[5/30] Step:[25000/25169] Loss: 0.553290 Loss_avg: 0.720327 LR: 0.00075917 Loss Fine: 0.553290 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:40:31,515 - trainer - INFO] - [Epoch End] Epoch:[5/30] Loss: 0.720251 LR: 0.00075904
 Validation result after 5 epoch: Word_acc: 0.807175 Word_acc_case_ins: 0.807175 Edit_distance_acc: 0.920355
[2025-01-21 15:40:33,221 - trainer - INFO] - Train Epoch:[6/30] Step:[1/25169] Loss: 0.720304 Loss_avg: 0.720304 LR: 0.00075904 Loss Fine: 0.720304 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:43:53,314 - trainer - INFO] - Train Epoch:[6/30] Step:[1000/25169] Loss: 0.668121 Loss_avg: 0.693430 LR: 0.00075829 Loss Fine: 0.668121 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:47:13,539 - trainer - INFO] - Train Epoch:[6/30] Step:[2000/25169] Loss: 0.650009 Loss_avg: 0.692775 LR: 0.00075753 Loss Fine: 0.650009 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:50:33,871 - trainer - INFO] - Train Epoch:[6/30] Step:[3000/25169] Loss: 0.519537 Loss_avg: 0.692963 LR: 0.00075676 Loss Fine: 0.519537 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:50:39,349 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[3000/25169] Word_acc: 0.828832 Word_acc_case_ins 0.828832 Edit_distance_acc: 0.926986
[2025-01-21 15:50:39,678 - trainer - INFO] - Saving current best (at 6 epoch): model_best.pth Best word_acc: 0.828832
[2025-01-21 15:53:59,991 - trainer - INFO] - Train Epoch:[6/30] Step:[4000/25169] Loss: 0.880802 Loss_avg: 0.693125 LR: 0.00075598 Loss Fine: 0.880802 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 15:57:20,352 - trainer - INFO] - Train Epoch:[6/30] Step:[5000/25169] Loss: 0.489483 Loss_avg: 0.692715 LR: 0.00075520 Loss Fine: 0.489483 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:00:40,633 - trainer - INFO] - Train Epoch:[6/30] Step:[6000/25169] Loss: 0.746967 Loss_avg: 0.692273 LR: 0.00075441 Loss Fine: 0.746967 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:00:46,104 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[6000/25169] Word_acc: 0.819700 Word_acc_case_ins 0.819700 Edit_distance_acc: 0.925045
[2025-01-21 16:04:06,363 - trainer - INFO] - Train Epoch:[6/30] Step:[7000/25169] Loss: 0.446705 Loss_avg: 0.691450 LR: 0.00075362 Loss Fine: 0.446705 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:07:26,636 - trainer - INFO] - Train Epoch:[6/30] Step:[8000/25169] Loss: 0.777994 Loss_avg: 0.691298 LR: 0.00075282 Loss Fine: 0.777994 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:10:46,836 - trainer - INFO] - Train Epoch:[6/30] Step:[9000/25169] Loss: 0.792653 Loss_avg: 0.690286 LR: 0.00075201 Loss Fine: 0.792653 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:10:52,313 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[9000/25169] Word_acc: 0.816699 Word_acc_case_ins 0.816699 Edit_distance_acc: 0.924874
[2025-01-21 16:14:12,521 - trainer - INFO] - Train Epoch:[6/30] Step:[10000/25169] Loss: 0.615752 Loss_avg: 0.688906 LR: 0.00075120 Loss Fine: 0.615752 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:17:32,747 - trainer - INFO] - Train Epoch:[6/30] Step:[11000/25169] Loss: 0.602446 Loss_avg: 0.687838 LR: 0.00075038 Loss Fine: 0.602446 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:20:53,002 - trainer - INFO] - Train Epoch:[6/30] Step:[12000/25169] Loss: 0.691901 Loss_avg: 0.687555 LR: 0.00074955 Loss Fine: 0.691901 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:20:58,484 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[12000/25169] Word_acc: 0.836138 Word_acc_case_ins 0.836138 Edit_distance_acc: 0.932511
[2025-01-21 16:20:58,816 - trainer - INFO] - Saving current best (at 6 epoch): model_best.pth Best word_acc: 0.836138
[2025-01-21 16:24:19,083 - trainer - INFO] - Train Epoch:[6/30] Step:[13000/25169] Loss: 0.684964 Loss_avg: 0.686841 LR: 0.00074872 Loss Fine: 0.684964 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:27:39,428 - trainer - INFO] - Train Epoch:[6/30] Step:[14000/25169] Loss: 0.620563 Loss_avg: 0.685865 LR: 0.00074788 Loss Fine: 0.620563 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:30:59,723 - trainer - INFO] - Train Epoch:[6/30] Step:[15000/25169] Loss: 0.799710 Loss_avg: 0.684530 LR: 0.00074703 Loss Fine: 0.799710 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:31:05,199 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[15000/25169] Word_acc: 0.822179 Word_acc_case_ins 0.822179 Edit_distance_acc: 0.925880
[2025-01-21 16:34:25,439 - trainer - INFO] - Train Epoch:[6/30] Step:[16000/25169] Loss: 0.628363 Loss_avg: 0.684097 LR: 0.00074618 Loss Fine: 0.628363 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:37:46,943 - trainer - INFO] - Train Epoch:[6/30] Step:[17000/25169] Loss: 0.804424 Loss_avg: 0.682968 LR: 0.00074532 Loss Fine: 0.804424 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:41:07,125 - trainer - INFO] - Train Epoch:[6/30] Step:[18000/25169] Loss: 0.910958 Loss_avg: 0.682803 LR: 0.00074446 Loss Fine: 0.910958 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:41:12,597 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[18000/25169] Word_acc: 0.830920 Word_acc_case_ins 0.830920 Edit_distance_acc: 0.929638
[2025-01-21 16:44:32,818 - trainer - INFO] - Train Epoch:[6/30] Step:[19000/25169] Loss: 0.840831 Loss_avg: 0.682337 LR: 0.00074359 Loss Fine: 0.840831 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:47:53,014 - trainer - INFO] - Train Epoch:[6/30] Step:[20000/25169] Loss: 0.691500 Loss_avg: 0.681723 LR: 0.00074271 Loss Fine: 0.691500 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:51:13,256 - trainer - INFO] - Train Epoch:[6/30] Step:[21000/25169] Loss: 0.697532 Loss_avg: 0.681009 LR: 0.00074183 Loss Fine: 0.697532 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:51:18,719 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[21000/25169] Word_acc: 0.838878 Word_acc_case_ins 0.838878 Edit_distance_acc: 0.931112
[2025-01-21 16:51:19,037 - trainer - INFO] - Saving current best (at 6 epoch): model_best.pth Best word_acc: 0.838878
[2025-01-21 16:54:39,223 - trainer - INFO] - Train Epoch:[6/30] Step:[22000/25169] Loss: 0.805126 Loss_avg: 0.680385 LR: 0.00074094 Loss Fine: 0.805126 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 16:57:59,422 - trainer - INFO] - Train Epoch:[6/30] Step:[23000/25169] Loss: 0.549043 Loss_avg: 0.679202 LR: 0.00074004 Loss Fine: 0.549043 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:01:19,601 - trainer - INFO] - Train Epoch:[6/30] Step:[24000/25169] Loss: 0.615478 Loss_avg: 0.678513 LR: 0.00073914 Loss Fine: 0.615478 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:01:25,134 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[24000/25169] Word_acc: 0.831703 Word_acc_case_ins 0.831703 Edit_distance_acc: 0.927747
[2025-01-21 17:04:45,340 - trainer - INFO] - Train Epoch:[6/30] Step:[25000/25169] Loss: 0.669247 Loss_avg: 0.677741 LR: 0.00073823 Loss Fine: 0.669247 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:05:24,783 - trainer - INFO] - [Epoch End] Epoch:[6/30] Loss: 0.677642 LR: 0.00073808
 Validation result after 6 epoch: Word_acc: 0.826354 Word_acc_case_ins: 0.826354 Edit_distance_acc: 0.929859
[2025-01-21 17:05:26,590 - trainer - INFO] - Train Epoch:[7/30] Step:[1/25169] Loss: 0.685970 Loss_avg: 0.685970 LR: 0.00073807 Loss Fine: 0.685970 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:08:46,644 - trainer - INFO] - Train Epoch:[7/30] Step:[1000/25169] Loss: 0.548635 Loss_avg: 0.655603 LR: 0.00073716 Loss Fine: 0.548635 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:12:06,854 - trainer - INFO] - Train Epoch:[7/30] Step:[2000/25169] Loss: 0.560090 Loss_avg: 0.652862 LR: 0.00073624 Loss Fine: 0.560090 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:15:27,089 - trainer - INFO] - Train Epoch:[7/30] Step:[3000/25169] Loss: 0.578950 Loss_avg: 0.653088 LR: 0.00073531 Loss Fine: 0.578950 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:15:32,570 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[3000/25169] Word_acc: 0.841226 Word_acc_case_ins 0.841226 Edit_distance_acc: 0.936122
[2025-01-21 17:15:32,894 - trainer - INFO] - Saving current best (at 7 epoch): model_best.pth Best word_acc: 0.841226
[2025-01-21 17:18:53,156 - trainer - INFO] - Train Epoch:[7/30] Step:[4000/25169] Loss: 0.845744 Loss_avg: 0.653389 LR: 0.00073438 Loss Fine: 0.845744 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:22:13,375 - trainer - INFO] - Train Epoch:[7/30] Step:[5000/25169] Loss: 0.670037 Loss_avg: 0.653174 LR: 0.00073344 Loss Fine: 0.670037 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:25:33,642 - trainer - INFO] - Train Epoch:[7/30] Step:[6000/25169] Loss: 0.577050 Loss_avg: 0.654068 LR: 0.00073249 Loss Fine: 0.577050 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:25:39,111 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[6000/25169] Word_acc: 0.834312 Word_acc_case_ins 0.834312 Edit_distance_acc: 0.931652
[2025-01-21 17:28:59,360 - trainer - INFO] - Train Epoch:[7/30] Step:[7000/25169] Loss: 0.448662 Loss_avg: 0.653938 LR: 0.00073154 Loss Fine: 0.448662 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:32:19,585 - trainer - INFO] - Train Epoch:[7/30] Step:[8000/25169] Loss: 0.771467 Loss_avg: 0.654000 LR: 0.00073058 Loss Fine: 0.771467 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:35:39,825 - trainer - INFO] - Train Epoch:[7/30] Step:[9000/25169] Loss: 0.635159 Loss_avg: 0.654702 LR: 0.00072962 Loss Fine: 0.635159 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:35:45,257 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[9000/25169] Word_acc: 0.834964 Word_acc_case_ins 0.834964 Edit_distance_acc: 0.932364
[2025-01-21 17:39:05,542 - trainer - INFO] - Train Epoch:[7/30] Step:[10000/25169] Loss: 0.590584 Loss_avg: 0.653696 LR: 0.00072865 Loss Fine: 0.590584 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:42:25,927 - trainer - INFO] - Train Epoch:[7/30] Step:[11000/25169] Loss: 0.700056 Loss_avg: 0.653443 LR: 0.00072767 Loss Fine: 0.700056 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:45:48,063 - trainer - INFO] - Train Epoch:[7/30] Step:[12000/25169] Loss: 0.728707 Loss_avg: 0.652856 LR: 0.00072669 Loss Fine: 0.728707 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:45:53,543 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[12000/25169] Word_acc: 0.836660 Word_acc_case_ins 0.836660 Edit_distance_acc: 0.929810
[2025-01-21 17:49:13,682 - trainer - INFO] - Train Epoch:[7/30] Step:[13000/25169] Loss: 0.549294 Loss_avg: 0.651785 LR: 0.00072570 Loss Fine: 0.549294 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:52:33,893 - trainer - INFO] - Train Epoch:[7/30] Step:[14000/25169] Loss: 0.686789 Loss_avg: 0.650850 LR: 0.00072471 Loss Fine: 0.686789 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:55:54,000 - trainer - INFO] - Train Epoch:[7/30] Step:[15000/25169] Loss: 0.938383 Loss_avg: 0.650471 LR: 0.00072371 Loss Fine: 0.938383 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 17:55:59,488 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[15000/25169] Word_acc: 0.840574 Word_acc_case_ins 0.840574 Edit_distance_acc: 0.936441
[2025-01-21 17:59:19,834 - trainer - INFO] - Train Epoch:[7/30] Step:[16000/25169] Loss: 0.623212 Loss_avg: 0.650432 LR: 0.00072270 Loss Fine: 0.623212 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:02:40,192 - trainer - INFO] - Train Epoch:[7/30] Step:[17000/25169] Loss: 0.836460 Loss_avg: 0.650148 LR: 0.00072169 Loss Fine: 0.836460 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:06:00,504 - trainer - INFO] - Train Epoch:[7/30] Step:[18000/25169] Loss: 0.736240 Loss_avg: 0.649563 LR: 0.00072067 Loss Fine: 0.736240 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:06:05,973 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[18000/25169] Word_acc: 0.840705 Word_acc_case_ins 0.840705 Edit_distance_acc: 0.934034
[2025-01-21 18:09:26,325 - trainer - INFO] - Train Epoch:[7/30] Step:[19000/25169] Loss: 0.615334 Loss_avg: 0.649474 LR: 0.00071965 Loss Fine: 0.615334 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:12:46,650 - trainer - INFO] - Train Epoch:[7/30] Step:[20000/25169] Loss: 0.625577 Loss_avg: 0.649016 LR: 0.00071862 Loss Fine: 0.625577 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:16:06,924 - trainer - INFO] - Train Epoch:[7/30] Step:[21000/25169] Loss: 0.545713 Loss_avg: 0.648562 LR: 0.00071759 Loss Fine: 0.545713 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:16:12,368 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[21000/25169] Word_acc: 0.854403 Word_acc_case_ins 0.854403 Edit_distance_acc: 0.940174
[2025-01-21 18:16:12,683 - trainer - INFO] - Saving current best (at 7 epoch): model_best.pth Best word_acc: 0.854403
[2025-01-21 18:19:32,965 - trainer - INFO] - Train Epoch:[7/30] Step:[22000/25169] Loss: 0.587973 Loss_avg: 0.648266 LR: 0.00071655 Loss Fine: 0.587973 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:22:53,265 - trainer - INFO] - Train Epoch:[7/30] Step:[23000/25169] Loss: 0.743542 Loss_avg: 0.647548 LR: 0.00071550 Loss Fine: 0.743542 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:26:13,503 - trainer - INFO] - Train Epoch:[7/30] Step:[24000/25169] Loss: 0.653824 Loss_avg: 0.647283 LR: 0.00071445 Loss Fine: 0.653824 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:26:18,989 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[24000/25169] Word_acc: 0.836008 Word_acc_case_ins 0.836008 Edit_distance_acc: 0.932953
[2025-01-21 18:29:39,395 - trainer - INFO] - Train Epoch:[7/30] Step:[25000/25169] Loss: 0.768204 Loss_avg: 0.646802 LR: 0.00071339 Loss Fine: 0.768204 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:30:18,878 - trainer - INFO] - [Epoch End] Epoch:[7/30] Loss: 0.646708 LR: 0.00071321
 Validation result after 7 epoch: Word_acc: 0.838487 Word_acc_case_ins: 0.838487 Edit_distance_acc: 0.937030
[2025-01-21 18:30:20,408 - trainer - INFO] - Train Epoch:[8/30] Step:[1/25169] Loss: 1.064343 Loss_avg: 1.064343 LR: 0.00071321 Loss Fine: 1.064343 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:33:40,526 - trainer - INFO] - Train Epoch:[8/30] Step:[1000/25169] Loss: 0.817559 Loss_avg: 0.630420 LR: 0.00071215 Loss Fine: 0.817559 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:37:00,707 - trainer - INFO] - Train Epoch:[8/30] Step:[2000/25169] Loss: 0.409666 Loss_avg: 0.633320 LR: 0.00071107 Loss Fine: 0.409666 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:40:20,922 - trainer - INFO] - Train Epoch:[8/30] Step:[3000/25169] Loss: 0.461625 Loss_avg: 0.633680 LR: 0.00071000 Loss Fine: 0.461625 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:40:26,433 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[3000/25169] Word_acc: 0.848010 Word_acc_case_ins 0.848010 Edit_distance_acc: 0.937792
[2025-01-21 18:43:46,646 - trainer - INFO] - Train Epoch:[8/30] Step:[4000/25169] Loss: 0.722894 Loss_avg: 0.633201 LR: 0.00070892 Loss Fine: 0.722894 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:47:06,884 - trainer - INFO] - Train Epoch:[8/30] Step:[5000/25169] Loss: 0.721852 Loss_avg: 0.632083 LR: 0.00070783 Loss Fine: 0.721852 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:50:27,175 - trainer - INFO] - Train Epoch:[8/30] Step:[6000/25169] Loss: 0.548705 Loss_avg: 0.632097 LR: 0.00070674 Loss Fine: 0.548705 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:50:32,622 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[6000/25169] Word_acc: 0.850620 Word_acc_case_ins 0.850620 Edit_distance_acc: 0.938406
[2025-01-21 18:53:52,910 - trainer - INFO] - Train Epoch:[8/30] Step:[7000/25169] Loss: 0.578859 Loss_avg: 0.630843 LR: 0.00070564 Loss Fine: 0.578859 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 18:57:13,107 - trainer - INFO] - Train Epoch:[8/30] Step:[8000/25169] Loss: 0.631251 Loss_avg: 0.629950 LR: 0.00070454 Loss Fine: 0.631251 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:00:33,331 - trainer - INFO] - Train Epoch:[8/30] Step:[9000/25169] Loss: 0.611618 Loss_avg: 0.629522 LR: 0.00070343 Loss Fine: 0.611618 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:00:38,824 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[9000/25169] Word_acc: 0.848793 Word_acc_case_ins 0.848793 Edit_distance_acc: 0.938381
[2025-01-21 19:03:59,046 - trainer - INFO] - Train Epoch:[8/30] Step:[10000/25169] Loss: 0.806639 Loss_avg: 0.629294 LR: 0.00070231 Loss Fine: 0.806639 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:07:21,323 - trainer - INFO] - Train Epoch:[8/30] Step:[11000/25169] Loss: 0.759569 Loss_avg: 0.629551 LR: 0.00070119 Loss Fine: 0.759569 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:10:41,575 - trainer - INFO] - Train Epoch:[8/30] Step:[12000/25169] Loss: 0.704696 Loss_avg: 0.629772 LR: 0.00070006 Loss Fine: 0.704696 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:10:47,058 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[12000/25169] Word_acc: 0.855055 Word_acc_case_ins 0.855055 Edit_distance_acc: 0.941525
[2025-01-21 19:10:47,372 - trainer - INFO] - Saving current best (at 8 epoch): model_best.pth Best word_acc: 0.855055
[2025-01-21 19:14:07,610 - trainer - INFO] - Train Epoch:[8/30] Step:[13000/25169] Loss: 0.552920 Loss_avg: 0.629277 LR: 0.00069893 Loss Fine: 0.552920 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:17:27,835 - trainer - INFO] - Train Epoch:[8/30] Step:[14000/25169] Loss: 0.680010 Loss_avg: 0.628902 LR: 0.00069780 Loss Fine: 0.680010 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:20:48,083 - trainer - INFO] - Train Epoch:[8/30] Step:[15000/25169] Loss: 0.429762 Loss_avg: 0.628442 LR: 0.00069665 Loss Fine: 0.429762 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:20:53,545 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[15000/25169] Word_acc: 0.856360 Word_acc_case_ins 0.856360 Edit_distance_acc: 0.942016
[2025-01-21 19:20:53,842 - trainer - INFO] - Saving current best (at 8 epoch): model_best.pth Best word_acc: 0.856360
[2025-01-21 19:24:14,146 - trainer - INFO] - Train Epoch:[8/30] Step:[16000/25169] Loss: 0.573036 Loss_avg: 0.628311 LR: 0.00069551 Loss Fine: 0.573036 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:27:34,513 - trainer - INFO] - Train Epoch:[8/30] Step:[17000/25169] Loss: 0.885810 Loss_avg: 0.627875 LR: 0.00069435 Loss Fine: 0.885810 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:30:54,827 - trainer - INFO] - Train Epoch:[8/30] Step:[18000/25169] Loss: 0.637720 Loss_avg: 0.627492 LR: 0.00069319 Loss Fine: 0.637720 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:31:00,282 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[18000/25169] Word_acc: 0.851794 Word_acc_case_ins 0.851794 Edit_distance_acc: 0.941721
[2025-01-21 19:34:20,550 - trainer - INFO] - Train Epoch:[8/30] Step:[19000/25169] Loss: 0.695668 Loss_avg: 0.627343 LR: 0.00069203 Loss Fine: 0.695668 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:37:40,867 - trainer - INFO] - Train Epoch:[8/30] Step:[20000/25169] Loss: 0.577439 Loss_avg: 0.626795 LR: 0.00069086 Loss Fine: 0.577439 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:41:01,060 - trainer - INFO] - Train Epoch:[8/30] Step:[21000/25169] Loss: 0.351884 Loss_avg: 0.626191 LR: 0.00068969 Loss Fine: 0.351884 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:41:06,582 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[21000/25169] Word_acc: 0.854795 Word_acc_case_ins 0.854795 Edit_distance_acc: 0.944226
[2025-01-21 19:44:26,783 - trainer - INFO] - Train Epoch:[8/30] Step:[22000/25169] Loss: 0.750695 Loss_avg: 0.625905 LR: 0.00068851 Loss Fine: 0.750695 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:47:46,961 - trainer - INFO] - Train Epoch:[8/30] Step:[23000/25169] Loss: 0.441162 Loss_avg: 0.625881 LR: 0.00068732 Loss Fine: 0.441162 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:51:07,230 - trainer - INFO] - Train Epoch:[8/30] Step:[24000/25169] Loss: 0.794586 Loss_avg: 0.625463 LR: 0.00068613 Loss Fine: 0.794586 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:51:12,688 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[24000/25169] Word_acc: 0.845140 Word_acc_case_ins 0.845140 Edit_distance_acc: 0.936171
[2025-01-21 19:54:32,917 - trainer - INFO] - Train Epoch:[8/30] Step:[25000/25169] Loss: 0.668501 Loss_avg: 0.625173 LR: 0.00068494 Loss Fine: 0.668501 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:55:12,444 - trainer - INFO] - [Epoch End] Epoch:[8/30] Loss: 0.625100 LR: 0.00068473
 Validation result after 8 epoch: Word_acc: 0.859622 Word_acc_case_ins: 0.859622 Edit_distance_acc: 0.943637
[2025-01-21 19:55:12,752 - trainer - INFO] - Saving current best (at 8 epoch): model_best.pth Best word_acc: 0.859622
[2025-01-21 19:55:14,460 - trainer - INFO] - Train Epoch:[9/30] Step:[1/25169] Loss: 0.631696 Loss_avg: 0.631696 LR: 0.00068473 Loss Fine: 0.631696 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 19:58:34,461 - trainer - INFO] - Train Epoch:[9/30] Step:[1000/25169] Loss: 0.602492 Loss_avg: 0.618059 LR: 0.00068353 Loss Fine: 0.602492 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:01:54,587 - trainer - INFO] - Train Epoch:[9/30] Step:[2000/25169] Loss: 0.788327 Loss_avg: 0.612617 LR: 0.00068233 Loss Fine: 0.788327 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:05:14,724 - trainer - INFO] - Train Epoch:[9/30] Step:[3000/25169] Loss: 0.504710 Loss_avg: 0.612712 LR: 0.00068111 Loss Fine: 0.504710 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:05:20,167 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[3000/25169] Word_acc: 0.849706 Word_acc_case_ins 0.849706 Edit_distance_acc: 0.940419
[2025-01-21 20:08:40,446 - trainer - INFO] - Train Epoch:[9/30] Step:[4000/25169] Loss: 0.658706 Loss_avg: 0.612128 LR: 0.00067990 Loss Fine: 0.658706 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:12:00,736 - trainer - INFO] - Train Epoch:[9/30] Step:[5000/25169] Loss: 0.655327 Loss_avg: 0.612174 LR: 0.00067868 Loss Fine: 0.655327 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:15:21,060 - trainer - INFO] - Train Epoch:[9/30] Step:[6000/25169] Loss: 0.729121 Loss_avg: 0.611839 LR: 0.00067745 Loss Fine: 0.729121 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:15:26,607 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[6000/25169] Word_acc: 0.851663 Word_acc_case_ins 0.851663 Edit_distance_acc: 0.940419
[2025-01-21 20:18:46,869 - trainer - INFO] - Train Epoch:[9/30] Step:[7000/25169] Loss: 0.686112 Loss_avg: 0.611916 LR: 0.00067622 Loss Fine: 0.686112 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:22:07,102 - trainer - INFO] - Train Epoch:[9/30] Step:[8000/25169] Loss: 0.665473 Loss_avg: 0.612168 LR: 0.00067498 Loss Fine: 0.665473 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:25:27,373 - trainer - INFO] - Train Epoch:[9/30] Step:[9000/25169] Loss: 0.844662 Loss_avg: 0.611908 LR: 0.00067374 Loss Fine: 0.844662 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:25:32,868 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[9000/25169] Word_acc: 0.855577 Word_acc_case_ins 0.855577 Edit_distance_acc: 0.941353
[2025-01-21 20:28:53,093 - trainer - INFO] - Train Epoch:[9/30] Step:[10000/25169] Loss: 0.605616 Loss_avg: 0.611307 LR: 0.00067249 Loss Fine: 0.605616 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:32:13,355 - trainer - INFO] - Train Epoch:[9/30] Step:[11000/25169] Loss: 0.692028 Loss_avg: 0.611241 LR: 0.00067124 Loss Fine: 0.692028 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:35:33,505 - trainer - INFO] - Train Epoch:[9/30] Step:[12000/25169] Loss: 0.784020 Loss_avg: 0.610914 LR: 0.00066998 Loss Fine: 0.784020 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:35:39,043 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[12000/25169] Word_acc: 0.848010 Word_acc_case_ins 0.848010 Edit_distance_acc: 0.939732
[2025-01-21 20:39:01,298 - trainer - INFO] - Train Epoch:[9/30] Step:[13000/25169] Loss: 0.536618 Loss_avg: 0.610364 LR: 0.00066872 Loss Fine: 0.536618 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:42:21,494 - trainer - INFO] - Train Epoch:[9/30] Step:[14000/25169] Loss: 0.732455 Loss_avg: 0.610181 LR: 0.00066745 Loss Fine: 0.732455 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:45:41,673 - trainer - INFO] - Train Epoch:[9/30] Step:[15000/25169] Loss: 0.568913 Loss_avg: 0.609978 LR: 0.00066618 Loss Fine: 0.568913 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:45:47,180 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[15000/25169] Word_acc: 0.851924 Word_acc_case_ins 0.851924 Edit_distance_acc: 0.936490
[2025-01-21 20:49:07,372 - trainer - INFO] - Train Epoch:[9/30] Step:[16000/25169] Loss: 0.605614 Loss_avg: 0.609579 LR: 0.00066490 Loss Fine: 0.605614 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:52:27,546 - trainer - INFO] - Train Epoch:[9/30] Step:[17000/25169] Loss: 0.697615 Loss_avg: 0.609530 LR: 0.00066362 Loss Fine: 0.697615 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:55:47,776 - trainer - INFO] - Train Epoch:[9/30] Step:[18000/25169] Loss: 0.815376 Loss_avg: 0.609003 LR: 0.00066234 Loss Fine: 0.815376 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 20:55:53,280 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[18000/25169] Word_acc: 0.863405 Word_acc_case_ins 0.863405 Edit_distance_acc: 0.945430
[2025-01-21 20:55:53,593 - trainer - INFO] - Saving current best (at 9 epoch): model_best.pth Best word_acc: 0.863405
[2025-01-21 20:59:13,794 - trainer - INFO] - Train Epoch:[9/30] Step:[19000/25169] Loss: 0.409907 Loss_avg: 0.608356 LR: 0.00066105 Loss Fine: 0.409907 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:02:33,996 - trainer - INFO] - Train Epoch:[9/30] Step:[20000/25169] Loss: 0.678136 Loss_avg: 0.608273 LR: 0.00065975 Loss Fine: 0.678136 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:05:54,107 - trainer - INFO] - Train Epoch:[9/30] Step:[21000/25169] Loss: 0.326278 Loss_avg: 0.608032 LR: 0.00065845 Loss Fine: 0.326278 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:05:59,591 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[21000/25169] Word_acc: 0.850620 Word_acc_case_ins 0.850620 Edit_distance_acc: 0.938209
[2025-01-21 21:09:19,886 - trainer - INFO] - Train Epoch:[9/30] Step:[22000/25169] Loss: 0.703200 Loss_avg: 0.607796 LR: 0.00065714 Loss Fine: 0.703200 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:12:40,163 - trainer - INFO] - Train Epoch:[9/30] Step:[23000/25169] Loss: 0.628603 Loss_avg: 0.607468 LR: 0.00065583 Loss Fine: 0.628603 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:16:00,456 - trainer - INFO] - Train Epoch:[9/30] Step:[24000/25169] Loss: 0.519201 Loss_avg: 0.607295 LR: 0.00065452 Loss Fine: 0.519201 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:16:05,943 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[24000/25169] Word_acc: 0.843444 Word_acc_case_ins 0.843444 Edit_distance_acc: 0.934845
[2025-01-21 21:19:26,161 - trainer - INFO] - Train Epoch:[9/30] Step:[25000/25169] Loss: 0.749762 Loss_avg: 0.607168 LR: 0.00065320 Loss Fine: 0.749762 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:20:05,638 - trainer - INFO] - [Epoch End] Epoch:[9/30] Loss: 0.607154 LR: 0.00065298
 Validation result after 9 epoch: Word_acc: 0.854012 Word_acc_case_ins: 0.854012 Edit_distance_acc: 0.941697
[2025-01-21 21:20:07,113 - trainer - INFO] - Train Epoch:[10/30] Step:[1/25169] Loss: 0.525633 Loss_avg: 0.525633 LR: 0.00065298 Loss Fine: 0.525633 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:23:27,199 - trainer - INFO] - Train Epoch:[10/30] Step:[1000/25169] Loss: 0.512636 Loss_avg: 0.595550 LR: 0.00065165 Loss Fine: 0.512636 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:26:47,421 - trainer - INFO] - Train Epoch:[10/30] Step:[2000/25169] Loss: 0.675652 Loss_avg: 0.596613 LR: 0.00065032 Loss Fine: 0.675652 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:30:07,682 - trainer - INFO] - Train Epoch:[10/30] Step:[3000/25169] Loss: 0.838771 Loss_avg: 0.596923 LR: 0.00064899 Loss Fine: 0.838771 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:30:13,196 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[3000/25169] Word_acc: 0.856882 Word_acc_case_ins 0.856882 Edit_distance_acc: 0.941721
[2025-01-21 21:33:33,486 - trainer - INFO] - Train Epoch:[10/30] Step:[4000/25169] Loss: 0.463107 Loss_avg: 0.596434 LR: 0.00064765 Loss Fine: 0.463107 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:36:53,661 - trainer - INFO] - Train Epoch:[10/30] Step:[5000/25169] Loss: 0.333203 Loss_avg: 0.595064 LR: 0.00064631 Loss Fine: 0.333203 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:40:13,888 - trainer - INFO] - Train Epoch:[10/30] Step:[6000/25169] Loss: 0.540267 Loss_avg: 0.594017 LR: 0.00064496 Loss Fine: 0.540267 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:40:19,369 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[6000/25169] Word_acc: 0.858969 Word_acc_case_ins 0.858969 Edit_distance_acc: 0.942826
[2025-01-21 21:43:39,639 - trainer - INFO] - Train Epoch:[10/30] Step:[7000/25169] Loss: 0.652542 Loss_avg: 0.594054 LR: 0.00064361 Loss Fine: 0.652542 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:46:59,872 - trainer - INFO] - Train Epoch:[10/30] Step:[8000/25169] Loss: 0.546738 Loss_avg: 0.594270 LR: 0.00064225 Loss Fine: 0.546738 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:50:19,971 - trainer - INFO] - Train Epoch:[10/30] Step:[9000/25169] Loss: 0.565878 Loss_avg: 0.594512 LR: 0.00064089 Loss Fine: 0.565878 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:50:25,478 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[9000/25169] Word_acc: 0.858969 Word_acc_case_ins 0.858969 Edit_distance_acc: 0.943514
[2025-01-21 21:53:45,739 - trainer - INFO] - Train Epoch:[10/30] Step:[10000/25169] Loss: 0.530097 Loss_avg: 0.594356 LR: 0.00063953 Loss Fine: 0.530097 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 21:57:05,997 - trainer - INFO] - Train Epoch:[10/30] Step:[11000/25169] Loss: 0.691798 Loss_avg: 0.593701 LR: 0.00063816 Loss Fine: 0.691798 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:00:26,222 - trainer - INFO] - Train Epoch:[10/30] Step:[12000/25169] Loss: 0.455195 Loss_avg: 0.593640 LR: 0.00063679 Loss Fine: 0.455195 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:00:31,736 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[12000/25169] Word_acc: 0.865362 Word_acc_case_ins 0.865362 Edit_distance_acc: 0.947222
[2025-01-21 22:00:32,067 - trainer - INFO] - Saving current best (at 10 epoch): model_best.pth Best word_acc: 0.865362
[2025-01-21 22:03:52,305 - trainer - INFO] - Train Epoch:[10/30] Step:[13000/25169] Loss: 0.425241 Loss_avg: 0.593821 LR: 0.00063541 Loss Fine: 0.425241 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:07:12,440 - trainer - INFO] - Train Epoch:[10/30] Step:[14000/25169] Loss: 0.747599 Loss_avg: 0.593365 LR: 0.00063403 Loss Fine: 0.747599 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:10:32,623 - trainer - INFO] - Train Epoch:[10/30] Step:[15000/25169] Loss: 0.634463 Loss_avg: 0.592724 LR: 0.00063264 Loss Fine: 0.634463 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:10:38,115 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[15000/25169] Word_acc: 0.866275 Word_acc_case_ins 0.866275 Edit_distance_acc: 0.946805
[2025-01-21 22:10:38,414 - trainer - INFO] - Saving current best (at 10 epoch): model_best.pth Best word_acc: 0.866275
[2025-01-21 22:13:58,633 - trainer - INFO] - Train Epoch:[10/30] Step:[16000/25169] Loss: 0.635828 Loss_avg: 0.592419 LR: 0.00063125 Loss Fine: 0.635828 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:17:18,808 - trainer - INFO] - Train Epoch:[10/30] Step:[17000/25169] Loss: 0.554139 Loss_avg: 0.591869 LR: 0.00062985 Loss Fine: 0.554139 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:20:39,038 - trainer - INFO] - Train Epoch:[10/30] Step:[18000/25169] Loss: 0.613551 Loss_avg: 0.591497 LR: 0.00062846 Loss Fine: 0.613551 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:20:44,448 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[18000/25169] Word_acc: 0.868754 Word_acc_case_ins 0.868754 Edit_distance_acc: 0.948328
[2025-01-21 22:20:44,780 - trainer - INFO] - Saving current best (at 10 epoch): model_best.pth Best word_acc: 0.868754
[2025-01-21 22:24:07,605 - trainer - INFO] - Train Epoch:[10/30] Step:[19000/25169] Loss: 0.541991 Loss_avg: 0.591017 LR: 0.00062705 Loss Fine: 0.541991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:27:27,775 - trainer - INFO] - Train Epoch:[10/30] Step:[20000/25169] Loss: 0.409115 Loss_avg: 0.590573 LR: 0.00062564 Loss Fine: 0.409115 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:30:48,023 - trainer - INFO] - Train Epoch:[10/30] Step:[21000/25169] Loss: 0.508158 Loss_avg: 0.590479 LR: 0.00062423 Loss Fine: 0.508158 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:30:53,554 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[21000/25169] Word_acc: 0.869667 Word_acc_case_ins 0.869667 Edit_distance_acc: 0.949040
[2025-01-21 22:30:53,897 - trainer - INFO] - Saving current best (at 10 epoch): model_best.pth Best word_acc: 0.869667
[2025-01-21 22:34:14,162 - trainer - INFO] - Train Epoch:[10/30] Step:[22000/25169] Loss: 0.455741 Loss_avg: 0.590108 LR: 0.00062282 Loss Fine: 0.455741 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:37:34,360 - trainer - INFO] - Train Epoch:[10/30] Step:[23000/25169] Loss: 0.436869 Loss_avg: 0.589959 LR: 0.00062140 Loss Fine: 0.436869 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:40:54,605 - trainer - INFO] - Train Epoch:[10/30] Step:[24000/25169] Loss: 0.509827 Loss_avg: 0.589608 LR: 0.00061997 Loss Fine: 0.509827 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:41:00,168 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[24000/25169] Word_acc: 0.866928 Word_acc_case_ins 0.866928 Edit_distance_acc: 0.948254
[2025-01-21 22:44:20,411 - trainer - INFO] - Train Epoch:[10/30] Step:[25000/25169] Loss: 0.645094 Loss_avg: 0.589490 LR: 0.00061855 Loss Fine: 0.645094 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:44:59,902 - trainer - INFO] - [Epoch End] Epoch:[10/30] Loss: 0.589412 LR: 0.00061831
 Validation result after 10 epoch: Word_acc: 0.860144 Word_acc_case_ins: 0.860144 Edit_distance_acc: 0.942212
[2025-01-21 22:45:01,350 - trainer - INFO] - Train Epoch:[11/30] Step:[1/25169] Loss: 0.537211 Loss_avg: 0.537211 LR: 0.00061830 Loss Fine: 0.537211 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:48:21,562 - trainer - INFO] - Train Epoch:[11/30] Step:[1000/25169] Loss: 0.530574 Loss_avg: 0.580311 LR: 0.00061687 Loss Fine: 0.530574 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:51:41,778 - trainer - INFO] - Train Epoch:[11/30] Step:[2000/25169] Loss: 0.501637 Loss_avg: 0.577952 LR: 0.00061544 Loss Fine: 0.501637 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:55:01,964 - trainer - INFO] - Train Epoch:[11/30] Step:[3000/25169] Loss: 0.583756 Loss_avg: 0.577316 LR: 0.00061400 Loss Fine: 0.583756 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 22:55:07,420 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[3000/25169] Word_acc: 0.858447 Word_acc_case_ins 0.858447 Edit_distance_acc: 0.945773
[2025-01-21 22:58:27,612 - trainer - INFO] - Train Epoch:[11/30] Step:[4000/25169] Loss: 0.611043 Loss_avg: 0.577577 LR: 0.00061255 Loss Fine: 0.611043 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:01:47,836 - trainer - INFO] - Train Epoch:[11/30] Step:[5000/25169] Loss: 0.785072 Loss_avg: 0.578077 LR: 0.00061110 Loss Fine: 0.785072 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:05:08,012 - trainer - INFO] - Train Epoch:[11/30] Step:[6000/25169] Loss: 0.812763 Loss_avg: 0.578900 LR: 0.00060965 Loss Fine: 0.812763 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:05:13,545 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[6000/25169] Word_acc: 0.868232 Word_acc_case_ins 0.868232 Edit_distance_acc: 0.947935
[2025-01-21 23:08:33,763 - trainer - INFO] - Train Epoch:[11/30] Step:[7000/25169] Loss: 0.357551 Loss_avg: 0.577824 LR: 0.00060820 Loss Fine: 0.357551 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:11:53,894 - trainer - INFO] - Train Epoch:[11/30] Step:[8000/25169] Loss: 0.487737 Loss_avg: 0.577345 LR: 0.00060674 Loss Fine: 0.487737 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:15:14,118 - trainer - INFO] - Train Epoch:[11/30] Step:[9000/25169] Loss: 0.462453 Loss_avg: 0.577791 LR: 0.00060527 Loss Fine: 0.462453 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:15:19,638 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[9000/25169] Word_acc: 0.861318 Word_acc_case_ins 0.861318 Edit_distance_acc: 0.946657
[2025-01-21 23:18:39,852 - trainer - INFO] - Train Epoch:[11/30] Step:[10000/25169] Loss: 0.480594 Loss_avg: 0.577200 LR: 0.00060381 Loss Fine: 0.480594 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:22:00,049 - trainer - INFO] - Train Epoch:[11/30] Step:[11000/25169] Loss: 0.517550 Loss_avg: 0.577282 LR: 0.00060234 Loss Fine: 0.517550 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:25:20,243 - trainer - INFO] - Train Epoch:[11/30] Step:[12000/25169] Loss: 0.487793 Loss_avg: 0.576669 LR: 0.00060086 Loss Fine: 0.487793 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:25:25,732 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[12000/25169] Word_acc: 0.866928 Word_acc_case_ins 0.866928 Edit_distance_acc: 0.947468
[2025-01-21 23:28:46,081 - trainer - INFO] - Train Epoch:[11/30] Step:[13000/25169] Loss: 0.749816 Loss_avg: 0.576633 LR: 0.00059938 Loss Fine: 0.749816 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:32:06,497 - trainer - INFO] - Train Epoch:[11/30] Step:[14000/25169] Loss: 0.498932 Loss_avg: 0.576490 LR: 0.00059790 Loss Fine: 0.498932 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:35:26,775 - trainer - INFO] - Train Epoch:[11/30] Step:[15000/25169] Loss: 0.452626 Loss_avg: 0.575808 LR: 0.00059642 Loss Fine: 0.452626 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:35:32,318 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[15000/25169] Word_acc: 0.867189 Word_acc_case_ins 0.867189 Edit_distance_acc: 0.946387
[2025-01-21 23:38:52,565 - trainer - INFO] - Train Epoch:[11/30] Step:[16000/25169] Loss: 0.620309 Loss_avg: 0.575843 LR: 0.00059493 Loss Fine: 0.620309 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:42:12,800 - trainer - INFO] - Train Epoch:[11/30] Step:[17000/25169] Loss: 0.683225 Loss_avg: 0.575448 LR: 0.00059344 Loss Fine: 0.683225 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:45:33,042 - trainer - INFO] - Train Epoch:[11/30] Step:[18000/25169] Loss: 0.525251 Loss_avg: 0.575255 LR: 0.00059194 Loss Fine: 0.525251 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:45:38,556 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[18000/25169] Word_acc: 0.860274 Word_acc_case_ins 0.860274 Edit_distance_acc: 0.943760
[2025-01-21 23:48:58,762 - trainer - INFO] - Train Epoch:[11/30] Step:[19000/25169] Loss: 0.531679 Loss_avg: 0.575303 LR: 0.00059044 Loss Fine: 0.531679 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:52:18,982 - trainer - INFO] - Train Epoch:[11/30] Step:[20000/25169] Loss: 0.569295 Loss_avg: 0.575016 LR: 0.00058894 Loss Fine: 0.569295 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:55:39,197 - trainer - INFO] - Train Epoch:[11/30] Step:[21000/25169] Loss: 0.420691 Loss_avg: 0.574749 LR: 0.00058743 Loss Fine: 0.420691 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-21 23:55:44,708 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[21000/25169] Word_acc: 0.862753 Word_acc_case_ins 0.862753 Edit_distance_acc: 0.946584
[2025-01-21 23:59:04,976 - trainer - INFO] - Train Epoch:[11/30] Step:[22000/25169] Loss: 0.502970 Loss_avg: 0.574523 LR: 0.00058592 Loss Fine: 0.502970 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:02:25,201 - trainer - INFO] - Train Epoch:[11/30] Step:[23000/25169] Loss: 0.957665 Loss_avg: 0.574357 LR: 0.00058441 Loss Fine: 0.957665 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:05:45,357 - trainer - INFO] - Train Epoch:[11/30] Step:[24000/25169] Loss: 0.703503 Loss_avg: 0.574104 LR: 0.00058289 Loss Fine: 0.703503 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:05:50,869 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[24000/25169] Word_acc: 0.866406 Word_acc_case_ins 0.866406 Edit_distance_acc: 0.946314
[2025-01-22 00:09:11,091 - trainer - INFO] - Train Epoch:[11/30] Step:[25000/25169] Loss: 0.436644 Loss_avg: 0.573935 LR: 0.00058137 Loss Fine: 0.436644 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:09:50,629 - trainer - INFO] - [Epoch End] Epoch:[11/30] Loss: 0.573923 LR: 0.00058112
 Validation result after 11 epoch: Word_acc: 0.872407 Word_acc_case_ins: 0.872407 Edit_distance_acc: 0.948229
[2025-01-22 00:09:50,955 - trainer - INFO] - Saving current best (at 11 epoch): model_best.pth Best word_acc: 0.872407
[2025-01-22 00:09:52,634 - trainer - INFO] - Train Epoch:[12/30] Step:[1/25169] Loss: 0.748291 Loss_avg: 0.748291 LR: 0.00058112 Loss Fine: 0.748291 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:13:12,828 - trainer - INFO] - Train Epoch:[12/30] Step:[1000/25169] Loss: 0.599733 Loss_avg: 0.557541 LR: 0.00057959 Loss Fine: 0.599733 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:16:33,105 - trainer - INFO] - Train Epoch:[12/30] Step:[2000/25169] Loss: 0.702183 Loss_avg: 0.557831 LR: 0.00057807 Loss Fine: 0.702183 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:19:53,329 - trainer - INFO] - Train Epoch:[12/30] Step:[3000/25169] Loss: 0.368115 Loss_avg: 0.558773 LR: 0.00057654 Loss Fine: 0.368115 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:19:58,881 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[3000/25169] Word_acc: 0.868232 Word_acc_case_ins 0.868232 Edit_distance_acc: 0.946289
[2025-01-22 00:23:21,718 - trainer - INFO] - Train Epoch:[12/30] Step:[4000/25169] Loss: 0.623024 Loss_avg: 0.559713 LR: 0.00057500 Loss Fine: 0.623024 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:26:41,971 - trainer - INFO] - Train Epoch:[12/30] Step:[5000/25169] Loss: 0.387209 Loss_avg: 0.560419 LR: 0.00057347 Loss Fine: 0.387209 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:30:02,211 - trainer - INFO] - Train Epoch:[12/30] Step:[6000/25169] Loss: 0.713877 Loss_avg: 0.561693 LR: 0.00057193 Loss Fine: 0.713877 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:30:07,716 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[6000/25169] Word_acc: 0.867189 Word_acc_case_ins 0.867189 Edit_distance_acc: 0.947370
[2025-01-22 00:33:27,972 - trainer - INFO] - Train Epoch:[12/30] Step:[7000/25169] Loss: 0.626633 Loss_avg: 0.561891 LR: 0.00057038 Loss Fine: 0.626633 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:36:48,143 - trainer - INFO] - Train Epoch:[12/30] Step:[8000/25169] Loss: 0.687219 Loss_avg: 0.561298 LR: 0.00056884 Loss Fine: 0.687219 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:40:08,289 - trainer - INFO] - Train Epoch:[12/30] Step:[9000/25169] Loss: 0.389747 Loss_avg: 0.560926 LR: 0.00056729 Loss Fine: 0.389747 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:40:13,805 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[9000/25169] Word_acc: 0.869015 Word_acc_case_ins 0.869015 Edit_distance_acc: 0.948647
[2025-01-22 00:43:34,038 - trainer - INFO] - Train Epoch:[12/30] Step:[10000/25169] Loss: 0.560108 Loss_avg: 0.560915 LR: 0.00056574 Loss Fine: 0.560108 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:46:54,295 - trainer - INFO] - Train Epoch:[12/30] Step:[11000/25169] Loss: 0.684796 Loss_avg: 0.560526 LR: 0.00056418 Loss Fine: 0.684796 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:50:14,482 - trainer - INFO] - Train Epoch:[12/30] Step:[12000/25169] Loss: 0.506410 Loss_avg: 0.560124 LR: 0.00056262 Loss Fine: 0.506410 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:50:20,022 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[12000/25169] Word_acc: 0.867319 Word_acc_case_ins 0.867319 Edit_distance_acc: 0.946363
[2025-01-22 00:53:40,282 - trainer - INFO] - Train Epoch:[12/30] Step:[13000/25169] Loss: 0.414856 Loss_avg: 0.559642 LR: 0.00056106 Loss Fine: 0.414856 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 00:57:00,586 - trainer - INFO] - Train Epoch:[12/30] Step:[14000/25169] Loss: 0.508330 Loss_avg: 0.560135 LR: 0.00055950 Loss Fine: 0.508330 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:00:20,759 - trainer - INFO] - Train Epoch:[12/30] Step:[15000/25169] Loss: 0.446371 Loss_avg: 0.560254 LR: 0.00055793 Loss Fine: 0.446371 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:00:26,293 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[15000/25169] Word_acc: 0.872277 Word_acc_case_ins 0.872277 Edit_distance_acc: 0.950562
[2025-01-22 01:03:46,483 - trainer - INFO] - Train Epoch:[12/30] Step:[16000/25169] Loss: 0.373867 Loss_avg: 0.559777 LR: 0.00055636 Loss Fine: 0.373867 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:07:06,678 - trainer - INFO] - Train Epoch:[12/30] Step:[17000/25169] Loss: 0.682563 Loss_avg: 0.559353 LR: 0.00055479 Loss Fine: 0.682563 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:10:26,874 - trainer - INFO] - Train Epoch:[12/30] Step:[18000/25169] Loss: 0.485186 Loss_avg: 0.559183 LR: 0.00055322 Loss Fine: 0.485186 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:10:32,384 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[18000/25169] Word_acc: 0.876973 Word_acc_case_ins 0.876973 Edit_distance_acc: 0.951471
[2025-01-22 01:10:32,714 - trainer - INFO] - Saving current best (at 12 epoch): model_best.pth Best word_acc: 0.876973
[2025-01-22 01:13:52,931 - trainer - INFO] - Train Epoch:[12/30] Step:[19000/25169] Loss: 0.522468 Loss_avg: 0.558831 LR: 0.00055164 Loss Fine: 0.522468 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:17:13,153 - trainer - INFO] - Train Epoch:[12/30] Step:[20000/25169] Loss: 0.585444 Loss_avg: 0.558681 LR: 0.00055006 Loss Fine: 0.585444 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:20:33,378 - trainer - INFO] - Train Epoch:[12/30] Step:[21000/25169] Loss: 0.785449 Loss_avg: 0.558846 LR: 0.00054847 Loss Fine: 0.785449 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:20:38,866 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[21000/25169] Word_acc: 0.870581 Word_acc_case_ins 0.870581 Edit_distance_acc: 0.950317
[2025-01-22 01:23:59,104 - trainer - INFO] - Train Epoch:[12/30] Step:[22000/25169] Loss: 0.686970 Loss_avg: 0.558531 LR: 0.00054689 Loss Fine: 0.686970 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:27:19,466 - trainer - INFO] - Train Epoch:[12/30] Step:[23000/25169] Loss: 0.382960 Loss_avg: 0.558366 LR: 0.00054530 Loss Fine: 0.382960 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:30:39,773 - trainer - INFO] - Train Epoch:[12/30] Step:[24000/25169] Loss: 0.573962 Loss_avg: 0.558157 LR: 0.00054371 Loss Fine: 0.573962 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:30:45,306 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[24000/25169] Word_acc: 0.867710 Word_acc_case_ins 0.867710 Edit_distance_acc: 0.947984
[2025-01-22 01:34:05,548 - trainer - INFO] - Train Epoch:[12/30] Step:[25000/25169] Loss: 0.587242 Loss_avg: 0.558024 LR: 0.00054211 Loss Fine: 0.587242 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:34:45,103 - trainer - INFO] - [Epoch End] Epoch:[12/30] Loss: 0.557953 LR: 0.00054184
 Validation result after 12 epoch: Word_acc: 0.872277 Word_acc_case_ins: 0.872277 Edit_distance_acc: 0.950292
[2025-01-22 01:34:46,466 - trainer - INFO] - Train Epoch:[13/30] Step:[1/25169] Loss: 0.655808 Loss_avg: 0.655808 LR: 0.00054184 Loss Fine: 0.655808 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:38:06,849 - trainer - INFO] - Train Epoch:[13/30] Step:[1000/25169] Loss: 0.545069 Loss_avg: 0.550085 LR: 0.00054024 Loss Fine: 0.545069 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:41:27,053 - trainer - INFO] - Train Epoch:[13/30] Step:[2000/25169] Loss: 0.452783 Loss_avg: 0.546067 LR: 0.00053864 Loss Fine: 0.452783 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:44:47,255 - trainer - INFO] - Train Epoch:[13/30] Step:[3000/25169] Loss: 0.369991 Loss_avg: 0.544803 LR: 0.00053704 Loss Fine: 0.369991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:44:52,775 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[3000/25169] Word_acc: 0.880104 Word_acc_case_ins 0.880104 Edit_distance_acc: 0.953829
[2025-01-22 01:44:53,097 - trainer - INFO] - Saving current best (at 13 epoch): model_best.pth Best word_acc: 0.880104
[2025-01-22 01:48:13,326 - trainer - INFO] - Train Epoch:[13/30] Step:[4000/25169] Loss: 0.555384 Loss_avg: 0.545039 LR: 0.00053544 Loss Fine: 0.555384 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:51:33,536 - trainer - INFO] - Train Epoch:[13/30] Step:[5000/25169] Loss: 0.562015 Loss_avg: 0.546302 LR: 0.00053383 Loss Fine: 0.562015 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:54:53,767 - trainer - INFO] - Train Epoch:[13/30] Step:[6000/25169] Loss: 0.452199 Loss_avg: 0.546415 LR: 0.00053222 Loss Fine: 0.452199 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 01:54:59,298 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[6000/25169] Word_acc: 0.868493 Word_acc_case_ins 0.868493 Edit_distance_acc: 0.948892
[2025-01-22 01:58:19,637 - trainer - INFO] - Train Epoch:[13/30] Step:[7000/25169] Loss: 0.638408 Loss_avg: 0.547126 LR: 0.00053061 Loss Fine: 0.638408 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:01:39,928 - trainer - INFO] - Train Epoch:[13/30] Step:[8000/25169] Loss: 0.438207 Loss_avg: 0.546498 LR: 0.00052899 Loss Fine: 0.438207 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:05:00,190 - trainer - INFO] - Train Epoch:[13/30] Step:[9000/25169] Loss: 0.595271 Loss_avg: 0.545577 LR: 0.00052738 Loss Fine: 0.595271 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:05:05,708 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[9000/25169] Word_acc: 0.878017 Word_acc_case_ins 0.878017 Edit_distance_acc: 0.952797
[2025-01-22 02:08:25,940 - trainer - INFO] - Train Epoch:[13/30] Step:[10000/25169] Loss: 0.794083 Loss_avg: 0.546046 LR: 0.00052576 Loss Fine: 0.794083 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:11:46,126 - trainer - INFO] - Train Epoch:[13/30] Step:[11000/25169] Loss: 0.708154 Loss_avg: 0.546757 LR: 0.00052414 Loss Fine: 0.708154 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:15:06,330 - trainer - INFO] - Train Epoch:[13/30] Step:[12000/25169] Loss: 0.619683 Loss_avg: 0.546276 LR: 0.00052251 Loss Fine: 0.619683 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:15:11,882 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[12000/25169] Word_acc: 0.881279 Word_acc_case_ins 0.881279 Edit_distance_acc: 0.953829
[2025-01-22 02:15:12,229 - trainer - INFO] - Saving current best (at 13 epoch): model_best.pth Best word_acc: 0.881279
[2025-01-22 02:18:32,568 - trainer - INFO] - Train Epoch:[13/30] Step:[13000/25169] Loss: 0.587222 Loss_avg: 0.546092 LR: 0.00052089 Loss Fine: 0.587222 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:21:52,886 - trainer - INFO] - Train Epoch:[13/30] Step:[14000/25169] Loss: 0.656076 Loss_avg: 0.546553 LR: 0.00051926 Loss Fine: 0.656076 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:25:13,214 - trainer - INFO] - Train Epoch:[13/30] Step:[15000/25169] Loss: 0.562257 Loss_avg: 0.546235 LR: 0.00051763 Loss Fine: 0.562257 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:25:18,758 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[15000/25169] Word_acc: 0.871102 Word_acc_case_ins 0.871102 Edit_distance_acc: 0.948942
[2025-01-22 02:28:38,980 - trainer - INFO] - Train Epoch:[13/30] Step:[16000/25169] Loss: 0.492540 Loss_avg: 0.545705 LR: 0.00051599 Loss Fine: 0.492540 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:31:59,196 - trainer - INFO] - Train Epoch:[13/30] Step:[17000/25169] Loss: 0.464174 Loss_avg: 0.545345 LR: 0.00051436 Loss Fine: 0.464174 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:35:19,404 - trainer - INFO] - Train Epoch:[13/30] Step:[18000/25169] Loss: 0.485164 Loss_avg: 0.544877 LR: 0.00051272 Loss Fine: 0.485164 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:35:24,925 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[18000/25169] Word_acc: 0.880235 Word_acc_case_ins 0.880235 Edit_distance_acc: 0.953215
[2025-01-22 02:38:48,229 - trainer - INFO] - Train Epoch:[13/30] Step:[19000/25169] Loss: 0.526749 Loss_avg: 0.544565 LR: 0.00051108 Loss Fine: 0.526749 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:42:08,442 - trainer - INFO] - Train Epoch:[13/30] Step:[20000/25169] Loss: 0.787889 Loss_avg: 0.544327 LR: 0.00050944 Loss Fine: 0.787889 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:45:28,690 - trainer - INFO] - Train Epoch:[13/30] Step:[21000/25169] Loss: 0.542467 Loss_avg: 0.544201 LR: 0.00050780 Loss Fine: 0.542467 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:45:34,180 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[21000/25169] Word_acc: 0.876060 Word_acc_case_ins 0.876060 Edit_distance_acc: 0.952085
[2025-01-22 02:48:54,469 - trainer - INFO] - Train Epoch:[13/30] Step:[22000/25169] Loss: 0.554659 Loss_avg: 0.543824 LR: 0.00050616 Loss Fine: 0.554659 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:52:14,775 - trainer - INFO] - Train Epoch:[13/30] Step:[23000/25169] Loss: 0.589067 Loss_avg: 0.543288 LR: 0.00050451 Loss Fine: 0.589067 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:55:35,077 - trainer - INFO] - Train Epoch:[13/30] Step:[24000/25169] Loss: 0.605848 Loss_avg: 0.542957 LR: 0.00050286 Loss Fine: 0.605848 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:55:40,610 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[24000/25169] Word_acc: 0.877495 Word_acc_case_ins 0.877495 Edit_distance_acc: 0.950882
[2025-01-22 02:59:00,861 - trainer - INFO] - Train Epoch:[13/30] Step:[25000/25169] Loss: 0.650255 Loss_avg: 0.542779 LR: 0.00050121 Loss Fine: 0.650255 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 02:59:40,431 - trainer - INFO] - [Epoch End] Epoch:[13/30] Loss: 0.542691 LR: 0.00050093
 Validation result after 13 epoch: Word_acc: 0.868363 Word_acc_case_ins: 0.868363 Edit_distance_acc: 0.947591
[2025-01-22 02:59:41,816 - trainer - INFO] - Train Epoch:[14/30] Step:[1/25169] Loss: 0.542888 Loss_avg: 0.542888 LR: 0.00050093 Loss Fine: 0.542888 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:03:01,902 - trainer - INFO] - Train Epoch:[14/30] Step:[1000/25169] Loss: 0.807523 Loss_avg: 0.525492 LR: 0.00049928 Loss Fine: 0.807523 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:06:22,121 - trainer - INFO] - Train Epoch:[14/30] Step:[2000/25169] Loss: 0.465171 Loss_avg: 0.533957 LR: 0.00049762 Loss Fine: 0.465171 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:09:42,455 - trainer - INFO] - Train Epoch:[14/30] Step:[3000/25169] Loss: 0.507176 Loss_avg: 0.534027 LR: 0.00049597 Loss Fine: 0.507176 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:09:47,924 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[3000/25169] Word_acc: 0.880887 Word_acc_case_ins 0.880887 Edit_distance_acc: 0.953067
[2025-01-22 03:13:08,125 - trainer - INFO] - Train Epoch:[14/30] Step:[4000/25169] Loss: 0.557907 Loss_avg: 0.532953 LR: 0.00049431 Loss Fine: 0.557907 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:16:28,363 - trainer - INFO] - Train Epoch:[14/30] Step:[5000/25169] Loss: 0.590099 Loss_avg: 0.532063 LR: 0.00049265 Loss Fine: 0.590099 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:19:48,619 - trainer - INFO] - Train Epoch:[14/30] Step:[6000/25169] Loss: 0.469833 Loss_avg: 0.532021 LR: 0.00049099 Loss Fine: 0.469833 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:19:54,117 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[6000/25169] Word_acc: 0.881931 Word_acc_case_ins 0.881931 Edit_distance_acc: 0.954713
[2025-01-22 03:19:54,418 - trainer - INFO] - Saving current best (at 14 epoch): model_best.pth Best word_acc: 0.881931
[2025-01-22 03:23:14,721 - trainer - INFO] - Train Epoch:[14/30] Step:[7000/25169] Loss: 0.582942 Loss_avg: 0.532260 LR: 0.00048933 Loss Fine: 0.582942 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:26:34,900 - trainer - INFO] - Train Epoch:[14/30] Step:[8000/25169] Loss: 0.666990 Loss_avg: 0.531906 LR: 0.00048766 Loss Fine: 0.666990 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:29:55,073 - trainer - INFO] - Train Epoch:[14/30] Step:[9000/25169] Loss: 0.497626 Loss_avg: 0.531349 LR: 0.00048600 Loss Fine: 0.497626 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:30:00,570 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[9000/25169] Word_acc: 0.880887 Word_acc_case_ins 0.880887 Edit_distance_acc: 0.953338
[2025-01-22 03:33:20,800 - trainer - INFO] - Train Epoch:[14/30] Step:[10000/25169] Loss: 0.537556 Loss_avg: 0.530926 LR: 0.00048433 Loss Fine: 0.537556 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:36:40,918 - trainer - INFO] - Train Epoch:[14/30] Step:[11000/25169] Loss: 0.661122 Loss_avg: 0.530621 LR: 0.00048266 Loss Fine: 0.661122 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:40:01,222 - trainer - INFO] - Train Epoch:[14/30] Step:[12000/25169] Loss: 0.487438 Loss_avg: 0.530455 LR: 0.00048099 Loss Fine: 0.487438 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:40:06,776 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[12000/25169] Word_acc: 0.888193 Word_acc_case_ins 0.888193 Edit_distance_acc: 0.956997
[2025-01-22 03:40:07,100 - trainer - INFO] - Saving current best (at 14 epoch): model_best.pth Best word_acc: 0.888193
[2025-01-22 03:43:27,467 - trainer - INFO] - Train Epoch:[14/30] Step:[13000/25169] Loss: 0.641765 Loss_avg: 0.530149 LR: 0.00047931 Loss Fine: 0.641765 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:46:47,707 - trainer - INFO] - Train Epoch:[14/30] Step:[14000/25169] Loss: 0.541717 Loss_avg: 0.529978 LR: 0.00047764 Loss Fine: 0.541717 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:50:07,957 - trainer - INFO] - Train Epoch:[14/30] Step:[15000/25169] Loss: 0.463712 Loss_avg: 0.529799 LR: 0.00047597 Loss Fine: 0.463712 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:50:13,501 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[15000/25169] Word_acc: 0.883888 Word_acc_case_ins 0.883888 Edit_distance_acc: 0.954664
[2025-01-22 03:53:33,712 - trainer - INFO] - Train Epoch:[14/30] Step:[16000/25169] Loss: 0.444343 Loss_avg: 0.529865 LR: 0.00047429 Loss Fine: 0.444343 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 03:56:53,917 - trainer - INFO] - Train Epoch:[14/30] Step:[17000/25169] Loss: 0.637708 Loss_avg: 0.529520 LR: 0.00047261 Loss Fine: 0.637708 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:00:14,114 - trainer - INFO] - Train Epoch:[14/30] Step:[18000/25169] Loss: 0.387043 Loss_avg: 0.529202 LR: 0.00047093 Loss Fine: 0.387043 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:00:19,611 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[18000/25169] Word_acc: 0.870711 Word_acc_case_ins 0.870711 Edit_distance_acc: 0.951397
[2025-01-22 04:03:39,964 - trainer - INFO] - Train Epoch:[14/30] Step:[19000/25169] Loss: 0.387467 Loss_avg: 0.529200 LR: 0.00046925 Loss Fine: 0.387467 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:07:00,265 - trainer - INFO] - Train Epoch:[14/30] Step:[20000/25169] Loss: 0.501950 Loss_avg: 0.528504 LR: 0.00046757 Loss Fine: 0.501950 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:10:20,579 - trainer - INFO] - Train Epoch:[14/30] Step:[21000/25169] Loss: 0.504700 Loss_avg: 0.528036 LR: 0.00046589 Loss Fine: 0.504700 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:10:26,084 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[21000/25169] Word_acc: 0.889106 Word_acc_case_ins 0.889106 Edit_distance_acc: 0.955867
[2025-01-22 04:10:26,424 - trainer - INFO] - Saving current best (at 14 epoch): model_best.pth Best word_acc: 0.889106
[2025-01-22 04:13:46,614 - trainer - INFO] - Train Epoch:[14/30] Step:[22000/25169] Loss: 0.614815 Loss_avg: 0.527809 LR: 0.00046420 Loss Fine: 0.614815 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:17:06,878 - trainer - INFO] - Train Epoch:[14/30] Step:[23000/25169] Loss: 0.527103 Loss_avg: 0.527552 LR: 0.00046252 Loss Fine: 0.527103 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:20:27,080 - trainer - INFO] - Train Epoch:[14/30] Step:[24000/25169] Loss: 0.375950 Loss_avg: 0.527255 LR: 0.00046083 Loss Fine: 0.375950 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:20:32,653 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[24000/25169] Word_acc: 0.882844 Word_acc_case_ins 0.882844 Edit_distance_acc: 0.953190
[2025-01-22 04:23:52,838 - trainer - INFO] - Train Epoch:[14/30] Step:[25000/25169] Loss: 0.670268 Loss_avg: 0.526903 LR: 0.00045914 Loss Fine: 0.670268 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:24:32,379 - trainer - INFO] - [Epoch End] Epoch:[14/30] Loss: 0.526955 LR: 0.00045886
 Validation result after 14 epoch: Word_acc: 0.883366 Word_acc_case_ins: 0.883366 Edit_distance_acc: 0.954615
[2025-01-22 04:24:34,039 - trainer - INFO] - Train Epoch:[15/30] Step:[1/25169] Loss: 0.534279 Loss_avg: 0.534279 LR: 0.00045886 Loss Fine: 0.534279 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:27:54,051 - trainer - INFO] - Train Epoch:[15/30] Step:[1000/25169] Loss: 0.470941 Loss_avg: 0.515570 LR: 0.00045717 Loss Fine: 0.470941 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:31:14,268 - trainer - INFO] - Train Epoch:[15/30] Step:[2000/25169] Loss: 0.575278 Loss_avg: 0.515304 LR: 0.00045548 Loss Fine: 0.575278 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:34:34,438 - trainer - INFO] - Train Epoch:[15/30] Step:[3000/25169] Loss: 0.589780 Loss_avg: 0.516045 LR: 0.00045379 Loss Fine: 0.589780 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:34:39,955 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[3000/25169] Word_acc: 0.880887 Word_acc_case_ins 0.880887 Edit_distance_acc: 0.955180
[2025-01-22 04:38:00,184 - trainer - INFO] - Train Epoch:[15/30] Step:[4000/25169] Loss: 0.621793 Loss_avg: 0.516837 LR: 0.00045210 Loss Fine: 0.621793 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:41:20,362 - trainer - INFO] - Train Epoch:[15/30] Step:[5000/25169] Loss: 0.474026 Loss_avg: 0.516168 LR: 0.00045040 Loss Fine: 0.474026 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:44:40,562 - trainer - INFO] - Train Epoch:[15/30] Step:[6000/25169] Loss: 0.661782 Loss_avg: 0.516300 LR: 0.00044871 Loss Fine: 0.661782 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:44:46,084 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[6000/25169] Word_acc: 0.888584 Word_acc_case_ins 0.888584 Edit_distance_acc: 0.956186
[2025-01-22 04:48:06,348 - trainer - INFO] - Train Epoch:[15/30] Step:[7000/25169] Loss: 0.583268 Loss_avg: 0.516349 LR: 0.00044701 Loss Fine: 0.583268 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:51:26,587 - trainer - INFO] - Train Epoch:[15/30] Step:[8000/25169] Loss: 0.568049 Loss_avg: 0.516040 LR: 0.00044532 Loss Fine: 0.568049 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:54:46,834 - trainer - INFO] - Train Epoch:[15/30] Step:[9000/25169] Loss: 0.472188 Loss_avg: 0.515705 LR: 0.00044362 Loss Fine: 0.472188 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 04:54:52,345 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[9000/25169] Word_acc: 0.875277 Word_acc_case_ins 0.875277 Edit_distance_acc: 0.951766
[2025-01-22 04:58:12,534 - trainer - INFO] - Train Epoch:[15/30] Step:[10000/25169] Loss: 0.463615 Loss_avg: 0.515399 LR: 0.00044193 Loss Fine: 0.463615 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:01:32,708 - trainer - INFO] - Train Epoch:[15/30] Step:[11000/25169] Loss: 0.427723 Loss_avg: 0.514899 LR: 0.00044023 Loss Fine: 0.427723 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:04:52,983 - trainer - INFO] - Train Epoch:[15/30] Step:[12000/25169] Loss: 0.605463 Loss_avg: 0.514944 LR: 0.00043853 Loss Fine: 0.605463 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:04:58,506 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[12000/25169] Word_acc: 0.882583 Word_acc_case_ins 0.882583 Edit_distance_acc: 0.955180
[2025-01-22 05:08:18,714 - trainer - INFO] - Train Epoch:[15/30] Step:[13000/25169] Loss: 0.440243 Loss_avg: 0.515118 LR: 0.00043683 Loss Fine: 0.440243 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:11:38,972 - trainer - INFO] - Train Epoch:[15/30] Step:[14000/25169] Loss: 0.463931 Loss_avg: 0.514775 LR: 0.00043513 Loss Fine: 0.463931 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:15:03,185 - trainer - INFO] - Train Epoch:[15/30] Step:[15000/25169] Loss: 0.393226 Loss_avg: 0.513780 LR: 0.00043343 Loss Fine: 0.393226 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:15:08,740 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[15000/25169] Word_acc: 0.883366 Word_acc_case_ins 0.883366 Edit_distance_acc: 0.955474
[2025-01-22 05:18:28,928 - trainer - INFO] - Train Epoch:[15/30] Step:[16000/25169] Loss: 0.382771 Loss_avg: 0.513951 LR: 0.00043173 Loss Fine: 0.382771 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:21:49,105 - trainer - INFO] - Train Epoch:[15/30] Step:[17000/25169] Loss: 0.589193 Loss_avg: 0.513643 LR: 0.00043003 Loss Fine: 0.589193 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:25:09,286 - trainer - INFO] - Train Epoch:[15/30] Step:[18000/25169] Loss: 0.448744 Loss_avg: 0.513127 LR: 0.00042832 Loss Fine: 0.448744 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:25:14,813 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[18000/25169] Word_acc: 0.890933 Word_acc_case_ins 0.890933 Edit_distance_acc: 0.957709
[2025-01-22 05:25:15,115 - trainer - INFO] - Saving current best (at 15 epoch): model_best.pth Best word_acc: 0.890933
[2025-01-22 05:28:35,261 - trainer - INFO] - Train Epoch:[15/30] Step:[19000/25169] Loss: 0.513830 Loss_avg: 0.512970 LR: 0.00042662 Loss Fine: 0.513830 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:31:55,453 - trainer - INFO] - Train Epoch:[15/30] Step:[20000/25169] Loss: 0.486264 Loss_avg: 0.512444 LR: 0.00042492 Loss Fine: 0.486264 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:35:15,641 - trainer - INFO] - Train Epoch:[15/30] Step:[21000/25169] Loss: 0.621057 Loss_avg: 0.512003 LR: 0.00042321 Loss Fine: 0.621057 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:35:21,140 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[21000/25169] Word_acc: 0.888715 Word_acc_case_ins 0.888715 Edit_distance_acc: 0.957071
[2025-01-22 05:38:41,425 - trainer - INFO] - Train Epoch:[15/30] Step:[22000/25169] Loss: 0.504533 Loss_avg: 0.511829 LR: 0.00042151 Loss Fine: 0.504533 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:42:01,653 - trainer - INFO] - Train Epoch:[15/30] Step:[23000/25169] Loss: 0.621756 Loss_avg: 0.511511 LR: 0.00041980 Loss Fine: 0.621756 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:45:21,833 - trainer - INFO] - Train Epoch:[15/30] Step:[24000/25169] Loss: 0.447089 Loss_avg: 0.511129 LR: 0.00041810 Loss Fine: 0.447089 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:45:27,355 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[24000/25169] Word_acc: 0.885714 Word_acc_case_ins 0.885714 Edit_distance_acc: 0.956678
[2025-01-22 05:48:47,649 - trainer - INFO] - Train Epoch:[15/30] Step:[25000/25169] Loss: 0.395011 Loss_avg: 0.511059 LR: 0.00041639 Loss Fine: 0.395011 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:49:27,219 - trainer - INFO] - [Epoch End] Epoch:[15/30] Loss: 0.511111 LR: 0.00041611
 Validation result after 15 epoch: Word_acc: 0.884932 Word_acc_case_ins: 0.884932 Edit_distance_acc: 0.955081
[2025-01-22 05:49:28,693 - trainer - INFO] - Train Epoch:[16/30] Step:[1/25169] Loss: 0.545956 Loss_avg: 0.545956 LR: 0.00041610 Loss Fine: 0.545956 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:52:48,774 - trainer - INFO] - Train Epoch:[16/30] Step:[1000/25169] Loss: 0.326882 Loss_avg: 0.501738 LR: 0.00041440 Loss Fine: 0.326882 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:56:09,006 - trainer - INFO] - Train Epoch:[16/30] Step:[2000/25169] Loss: 0.350109 Loss_avg: 0.500079 LR: 0.00041269 Loss Fine: 0.350109 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:59:29,234 - trainer - INFO] - Train Epoch:[16/30] Step:[3000/25169] Loss: 0.457416 Loss_avg: 0.502022 LR: 0.00041099 Loss Fine: 0.457416 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 05:59:34,783 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[3000/25169] Word_acc: 0.887149 Word_acc_case_ins 0.887149 Edit_distance_acc: 0.955253
[2025-01-22 06:02:54,917 - trainer - INFO] - Train Epoch:[16/30] Step:[4000/25169] Loss: 0.422878 Loss_avg: 0.501497 LR: 0.00040928 Loss Fine: 0.422878 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:06:15,069 - trainer - INFO] - Train Epoch:[16/30] Step:[5000/25169] Loss: 0.671809 Loss_avg: 0.500627 LR: 0.00040758 Loss Fine: 0.671809 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:09:35,248 - trainer - INFO] - Train Epoch:[16/30] Step:[6000/25169] Loss: 0.629244 Loss_avg: 0.500225 LR: 0.00040587 Loss Fine: 0.629244 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:09:40,813 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[6000/25169] Word_acc: 0.886888 Word_acc_case_ins 0.886888 Edit_distance_acc: 0.958004
[2025-01-22 06:13:01,105 - trainer - INFO] - Train Epoch:[16/30] Step:[7000/25169] Loss: 0.589589 Loss_avg: 0.499961 LR: 0.00040416 Loss Fine: 0.589589 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:16:21,407 - trainer - INFO] - Train Epoch:[16/30] Step:[8000/25169] Loss: 0.373705 Loss_avg: 0.499967 LR: 0.00040246 Loss Fine: 0.373705 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:19:41,728 - trainer - INFO] - Train Epoch:[16/30] Step:[9000/25169] Loss: 0.770246 Loss_avg: 0.499618 LR: 0.00040075 Loss Fine: 0.770246 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:19:47,251 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[9000/25169] Word_acc: 0.891455 Word_acc_case_ins 0.891455 Edit_distance_acc: 0.957660
[2025-01-22 06:19:47,567 - trainer - INFO] - Saving current best (at 16 epoch): model_best.pth Best word_acc: 0.891455
[2025-01-22 06:23:07,766 - trainer - INFO] - Train Epoch:[16/30] Step:[10000/25169] Loss: 0.579062 Loss_avg: 0.499240 LR: 0.00039904 Loss Fine: 0.579062 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:26:28,010 - trainer - INFO] - Train Epoch:[16/30] Step:[11000/25169] Loss: 0.397734 Loss_avg: 0.498902 LR: 0.00039733 Loss Fine: 0.397734 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:29:48,235 - trainer - INFO] - Train Epoch:[16/30] Step:[12000/25169] Loss: 0.468230 Loss_avg: 0.499083 LR: 0.00039563 Loss Fine: 0.468230 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:29:53,773 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[12000/25169] Word_acc: 0.884149 Word_acc_case_ins 0.884149 Edit_distance_acc: 0.954295
[2025-01-22 06:33:13,916 - trainer - INFO] - Train Epoch:[16/30] Step:[13000/25169] Loss: 0.532096 Loss_avg: 0.498860 LR: 0.00039392 Loss Fine: 0.532096 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:36:34,120 - trainer - INFO] - Train Epoch:[16/30] Step:[14000/25169] Loss: 0.599534 Loss_avg: 0.498768 LR: 0.00039221 Loss Fine: 0.599534 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:39:54,346 - trainer - INFO] - Train Epoch:[16/30] Step:[15000/25169] Loss: 0.688370 Loss_avg: 0.498734 LR: 0.00039051 Loss Fine: 0.688370 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:39:59,910 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[15000/25169] Word_acc: 0.888324 Word_acc_case_ins 0.888324 Edit_distance_acc: 0.958691
[2025-01-22 06:43:20,118 - trainer - INFO] - Train Epoch:[16/30] Step:[16000/25169] Loss: 0.296368 Loss_avg: 0.498255 LR: 0.00038880 Loss Fine: 0.296368 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:46:40,407 - trainer - INFO] - Train Epoch:[16/30] Step:[17000/25169] Loss: 0.574503 Loss_avg: 0.498030 LR: 0.00038709 Loss Fine: 0.574503 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:50:00,641 - trainer - INFO] - Train Epoch:[16/30] Step:[18000/25169] Loss: 0.351154 Loss_avg: 0.497539 LR: 0.00038539 Loss Fine: 0.351154 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:50:06,184 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[18000/25169] Word_acc: 0.882975 Word_acc_case_ins 0.882975 Edit_distance_acc: 0.956800
[2025-01-22 06:53:26,449 - trainer - INFO] - Train Epoch:[16/30] Step:[19000/25169] Loss: 0.567591 Loss_avg: 0.497114 LR: 0.00038368 Loss Fine: 0.567591 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 06:56:46,627 - trainer - INFO] - Train Epoch:[16/30] Step:[20000/25169] Loss: 0.391824 Loss_avg: 0.496666 LR: 0.00038198 Loss Fine: 0.391824 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:00:06,873 - trainer - INFO] - Train Epoch:[16/30] Step:[21000/25169] Loss: 0.305487 Loss_avg: 0.496214 LR: 0.00038027 Loss Fine: 0.305487 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:00:12,408 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[21000/25169] Word_acc: 0.895108 Word_acc_case_ins 0.895108 Edit_distance_acc: 0.959109
[2025-01-22 07:00:12,728 - trainer - INFO] - Saving current best (at 16 epoch): model_best.pth Best word_acc: 0.895108
[2025-01-22 07:03:32,981 - trainer - INFO] - Train Epoch:[16/30] Step:[22000/25169] Loss: 0.570207 Loss_avg: 0.495705 LR: 0.00037857 Loss Fine: 0.570207 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:06:53,336 - trainer - INFO] - Train Epoch:[16/30] Step:[23000/25169] Loss: 0.430458 Loss_avg: 0.495787 LR: 0.00037686 Loss Fine: 0.430458 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:10:13,669 - trainer - INFO] - Train Epoch:[16/30] Step:[24000/25169] Loss: 0.364151 Loss_avg: 0.495649 LR: 0.00037516 Loss Fine: 0.364151 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:10:19,217 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[24000/25169] Word_acc: 0.894325 Word_acc_case_ins 0.894325 Edit_distance_acc: 0.958323
[2025-01-22 07:13:39,486 - trainer - INFO] - Train Epoch:[16/30] Step:[25000/25169] Loss: 0.637106 Loss_avg: 0.495390 LR: 0.00037346 Loss Fine: 0.637106 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:14:19,026 - trainer - INFO] - [Epoch End] Epoch:[16/30] Loss: 0.495329 LR: 0.00037317
 Validation result after 16 epoch: Word_acc: 0.878017 Word_acc_case_ins: 0.878017 Edit_distance_acc: 0.953460
[2025-01-22 07:14:20,547 - trainer - INFO] - Train Epoch:[17/30] Step:[1/25169] Loss: 0.436112 Loss_avg: 0.436112 LR: 0.00037317 Loss Fine: 0.436112 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:17:40,622 - trainer - INFO] - Train Epoch:[17/30] Step:[1000/25169] Loss: 0.572430 Loss_avg: 0.481998 LR: 0.00037147 Loss Fine: 0.572430 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:21:00,767 - trainer - INFO] - Train Epoch:[17/30] Step:[2000/25169] Loss: 0.547751 Loss_avg: 0.482596 LR: 0.00036976 Loss Fine: 0.547751 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:24:20,858 - trainer - INFO] - Train Epoch:[17/30] Step:[3000/25169] Loss: 0.350458 Loss_avg: 0.481680 LR: 0.00036806 Loss Fine: 0.350458 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:24:26,380 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[3000/25169] Word_acc: 0.893803 Word_acc_case_ins 0.893803 Edit_distance_acc: 0.959846
[2025-01-22 07:27:46,486 - trainer - INFO] - Train Epoch:[17/30] Step:[4000/25169] Loss: 0.618432 Loss_avg: 0.482548 LR: 0.00036636 Loss Fine: 0.618432 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:31:06,591 - trainer - INFO] - Train Epoch:[17/30] Step:[5000/25169] Loss: 0.648581 Loss_avg: 0.481370 LR: 0.00036466 Loss Fine: 0.648581 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:34:26,754 - trainer - INFO] - Train Epoch:[17/30] Step:[6000/25169] Loss: 0.462749 Loss_avg: 0.482134 LR: 0.00036296 Loss Fine: 0.462749 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:34:32,296 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[6000/25169] Word_acc: 0.892759 Word_acc_case_ins 0.892759 Edit_distance_acc: 0.959919
[2025-01-22 07:37:52,463 - trainer - INFO] - Train Epoch:[17/30] Step:[7000/25169] Loss: 0.345692 Loss_avg: 0.482630 LR: 0.00036126 Loss Fine: 0.345692 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:41:12,631 - trainer - INFO] - Train Epoch:[17/30] Step:[8000/25169] Loss: 0.449997 Loss_avg: 0.483104 LR: 0.00035956 Loss Fine: 0.449997 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:44:32,757 - trainer - INFO] - Train Epoch:[17/30] Step:[9000/25169] Loss: 0.672256 Loss_avg: 0.482461 LR: 0.00035786 Loss Fine: 0.672256 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:44:38,288 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[9000/25169] Word_acc: 0.890672 Word_acc_case_ins 0.890672 Edit_distance_acc: 0.958102
[2025-01-22 07:47:58,489 - trainer - INFO] - Train Epoch:[17/30] Step:[10000/25169] Loss: 0.646528 Loss_avg: 0.482817 LR: 0.00035617 Loss Fine: 0.646528 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:51:18,666 - trainer - INFO] - Train Epoch:[17/30] Step:[11000/25169] Loss: 0.421611 Loss_avg: 0.482712 LR: 0.00035447 Loss Fine: 0.421611 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:54:38,856 - trainer - INFO] - Train Epoch:[17/30] Step:[12000/25169] Loss: 0.486371 Loss_avg: 0.482266 LR: 0.00035278 Loss Fine: 0.486371 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 07:54:44,425 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[12000/25169] Word_acc: 0.895369 Word_acc_case_ins 0.895369 Edit_distance_acc: 0.960558
[2025-01-22 07:54:44,768 - trainer - INFO] - Saving current best (at 17 epoch): model_best.pth Best word_acc: 0.895369
[2025-01-22 07:58:04,875 - trainer - INFO] - Train Epoch:[17/30] Step:[13000/25169] Loss: 0.553802 Loss_avg: 0.482022 LR: 0.00035108 Loss Fine: 0.553802 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:01:25,028 - trainer - INFO] - Train Epoch:[17/30] Step:[14000/25169] Loss: 0.356501 Loss_avg: 0.481734 LR: 0.00034939 Loss Fine: 0.356501 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:04:45,156 - trainer - INFO] - Train Epoch:[17/30] Step:[15000/25169] Loss: 0.351394 Loss_avg: 0.481676 LR: 0.00034770 Loss Fine: 0.351394 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:04:50,700 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[15000/25169] Word_acc: 0.892368 Word_acc_case_ins 0.892368 Edit_distance_acc: 0.957464
[2025-01-22 08:08:10,883 - trainer - INFO] - Train Epoch:[17/30] Step:[16000/25169] Loss: 0.423072 Loss_avg: 0.481597 LR: 0.00034600 Loss Fine: 0.423072 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:11:35,371 - trainer - INFO] - Train Epoch:[17/30] Step:[17000/25169] Loss: 0.412631 Loss_avg: 0.481487 LR: 0.00034431 Loss Fine: 0.412631 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:14:55,563 - trainer - INFO] - Train Epoch:[17/30] Step:[18000/25169] Loss: 0.432888 Loss_avg: 0.480963 LR: 0.00034262 Loss Fine: 0.432888 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:15:01,124 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[18000/25169] Word_acc: 0.896934 Word_acc_case_ins 0.896934 Edit_distance_acc: 0.961442
[2025-01-22 08:15:01,440 - trainer - INFO] - Saving current best (at 17 epoch): model_best.pth Best word_acc: 0.896934
[2025-01-22 08:18:21,597 - trainer - INFO] - Train Epoch:[17/30] Step:[19000/25169] Loss: 0.396058 Loss_avg: 0.480700 LR: 0.00034093 Loss Fine: 0.396058 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:21:41,824 - trainer - INFO] - Train Epoch:[17/30] Step:[20000/25169] Loss: 0.475686 Loss_avg: 0.480376 LR: 0.00033925 Loss Fine: 0.475686 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:25:02,087 - trainer - INFO] - Train Epoch:[17/30] Step:[21000/25169] Loss: 0.463200 Loss_avg: 0.480499 LR: 0.00033756 Loss Fine: 0.463200 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:25:07,644 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[21000/25169] Word_acc: 0.899413 Word_acc_case_ins 0.899413 Edit_distance_acc: 0.962793
[2025-01-22 08:25:07,949 - trainer - INFO] - Saving current best (at 17 epoch): model_best.pth Best word_acc: 0.899413
[2025-01-22 08:28:28,130 - trainer - INFO] - Train Epoch:[17/30] Step:[22000/25169] Loss: 0.575519 Loss_avg: 0.480187 LR: 0.00033587 Loss Fine: 0.575519 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:31:48,338 - trainer - INFO] - Train Epoch:[17/30] Step:[23000/25169] Loss: 0.621173 Loss_avg: 0.480318 LR: 0.00033419 Loss Fine: 0.621173 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:35:08,518 - trainer - INFO] - Train Epoch:[17/30] Step:[24000/25169] Loss: 0.452736 Loss_avg: 0.479984 LR: 0.00033251 Loss Fine: 0.452736 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:35:14,127 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[24000/25169] Word_acc: 0.893542 Word_acc_case_ins 0.893542 Edit_distance_acc: 0.961491
[2025-01-22 08:38:34,279 - trainer - INFO] - Train Epoch:[17/30] Step:[25000/25169] Loss: 0.367786 Loss_avg: 0.479655 LR: 0.00033083 Loss Fine: 0.367786 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:39:13,883 - trainer - INFO] - [Epoch End] Epoch:[17/30] Loss: 0.479571 LR: 0.00033054
 Validation result after 17 epoch: Word_acc: 0.892629 Word_acc_case_ins: 0.892629 Edit_distance_acc: 0.959821
[2025-01-22 08:39:15,579 - trainer - INFO] - Train Epoch:[18/30] Step:[1/25169] Loss: 0.797244 Loss_avg: 0.797244 LR: 0.00033054 Loss Fine: 0.797244 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:42:35,632 - trainer - INFO] - Train Epoch:[18/30] Step:[1000/25169] Loss: 0.481025 Loss_avg: 0.467313 LR: 0.00032886 Loss Fine: 0.481025 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:45:55,777 - trainer - INFO] - Train Epoch:[18/30] Step:[2000/25169] Loss: 0.503917 Loss_avg: 0.465619 LR: 0.00032718 Loss Fine: 0.503917 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:49:16,025 - trainer - INFO] - Train Epoch:[18/30] Step:[3000/25169] Loss: 0.355207 Loss_avg: 0.465269 LR: 0.00032550 Loss Fine: 0.355207 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:49:21,560 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[3000/25169] Word_acc: 0.892498 Word_acc_case_ins 0.892498 Edit_distance_acc: 0.960190
[2025-01-22 08:52:41,803 - trainer - INFO] - Train Epoch:[18/30] Step:[4000/25169] Loss: 0.282643 Loss_avg: 0.465189 LR: 0.00032383 Loss Fine: 0.282643 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:56:02,031 - trainer - INFO] - Train Epoch:[18/30] Step:[5000/25169] Loss: 0.617546 Loss_avg: 0.465621 LR: 0.00032215 Loss Fine: 0.617546 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:59:22,228 - trainer - INFO] - Train Epoch:[18/30] Step:[6000/25169] Loss: 0.452633 Loss_avg: 0.464925 LR: 0.00032048 Loss Fine: 0.452633 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 08:59:27,817 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[6000/25169] Word_acc: 0.900587 Word_acc_case_ins 0.900587 Edit_distance_acc: 0.961737
[2025-01-22 08:59:28,153 - trainer - INFO] - Saving current best (at 18 epoch): model_best.pth Best word_acc: 0.900587
[2025-01-22 09:02:48,493 - trainer - INFO] - Train Epoch:[18/30] Step:[7000/25169] Loss: 0.600673 Loss_avg: 0.464824 LR: 0.00031881 Loss Fine: 0.600673 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:06:08,848 - trainer - INFO] - Train Epoch:[18/30] Step:[8000/25169] Loss: 0.487817 Loss_avg: 0.464940 LR: 0.00031714 Loss Fine: 0.487817 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:09:29,142 - trainer - INFO] - Train Epoch:[18/30] Step:[9000/25169] Loss: 0.532193 Loss_avg: 0.465216 LR: 0.00031547 Loss Fine: 0.532193 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:09:34,687 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[9000/25169] Word_acc: 0.900457 Word_acc_case_ins 0.900457 Edit_distance_acc: 0.962007
[2025-01-22 09:12:54,923 - trainer - INFO] - Train Epoch:[18/30] Step:[10000/25169] Loss: 0.488890 Loss_avg: 0.465447 LR: 0.00031380 Loss Fine: 0.488890 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:16:15,172 - trainer - INFO] - Train Epoch:[18/30] Step:[11000/25169] Loss: 0.491641 Loss_avg: 0.465493 LR: 0.00031213 Loss Fine: 0.491641 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:19:35,357 - trainer - INFO] - Train Epoch:[18/30] Step:[12000/25169] Loss: 0.407194 Loss_avg: 0.465172 LR: 0.00031047 Loss Fine: 0.407194 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:19:40,908 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[12000/25169] Word_acc: 0.898891 Word_acc_case_ins 0.898891 Edit_distance_acc: 0.962007
[2025-01-22 09:23:01,165 - trainer - INFO] - Train Epoch:[18/30] Step:[13000/25169] Loss: 0.756991 Loss_avg: 0.465238 LR: 0.00030881 Loss Fine: 0.756991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:26:21,304 - trainer - INFO] - Train Epoch:[18/30] Step:[14000/25169] Loss: 0.350935 Loss_avg: 0.465232 LR: 0.00030714 Loss Fine: 0.350935 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:29:41,571 - trainer - INFO] - Train Epoch:[18/30] Step:[15000/25169] Loss: 0.600751 Loss_avg: 0.465156 LR: 0.00030549 Loss Fine: 0.600751 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:29:47,160 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[15000/25169] Word_acc: 0.901370 Word_acc_case_ins 0.901370 Edit_distance_acc: 0.964266
[2025-01-22 09:29:47,464 - trainer - INFO] - Saving current best (at 18 epoch): model_best.pth Best word_acc: 0.901370
[2025-01-22 09:33:07,706 - trainer - INFO] - Train Epoch:[18/30] Step:[16000/25169] Loss: 0.418540 Loss_avg: 0.465180 LR: 0.00030383 Loss Fine: 0.418540 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:36:27,880 - trainer - INFO] - Train Epoch:[18/30] Step:[17000/25169] Loss: 0.433104 Loss_avg: 0.464881 LR: 0.00030217 Loss Fine: 0.433104 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:39:48,090 - trainer - INFO] - Train Epoch:[18/30] Step:[18000/25169] Loss: 0.229398 Loss_avg: 0.464650 LR: 0.00030052 Loss Fine: 0.229398 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:39:53,743 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[18000/25169] Word_acc: 0.900457 Word_acc_case_ins 0.900457 Edit_distance_acc: 0.962817
[2025-01-22 09:43:13,987 - trainer - INFO] - Train Epoch:[18/30] Step:[19000/25169] Loss: 0.470397 Loss_avg: 0.464298 LR: 0.00029887 Loss Fine: 0.470397 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:46:34,155 - trainer - INFO] - Train Epoch:[18/30] Step:[20000/25169] Loss: 0.347644 Loss_avg: 0.463800 LR: 0.00029721 Loss Fine: 0.347644 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:49:54,363 - trainer - INFO] - Train Epoch:[18/30] Step:[21000/25169] Loss: 0.570779 Loss_avg: 0.463611 LR: 0.00029557 Loss Fine: 0.570779 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:49:59,928 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[21000/25169] Word_acc: 0.900196 Word_acc_case_ins 0.900196 Edit_distance_acc: 0.962424
[2025-01-22 09:53:20,113 - trainer - INFO] - Train Epoch:[18/30] Step:[22000/25169] Loss: 0.517053 Loss_avg: 0.463208 LR: 0.00029392 Loss Fine: 0.517053 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 09:56:40,407 - trainer - INFO] - Train Epoch:[18/30] Step:[23000/25169] Loss: 0.426759 Loss_avg: 0.462986 LR: 0.00029227 Loss Fine: 0.426759 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:00:00,766 - trainer - INFO] - Train Epoch:[18/30] Step:[24000/25169] Loss: 0.444281 Loss_avg: 0.462573 LR: 0.00029063 Loss Fine: 0.444281 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:00:06,424 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[24000/25169] Word_acc: 0.903327 Word_acc_case_ins 0.903327 Edit_distance_acc: 0.962891
[2025-01-22 10:00:06,767 - trainer - INFO] - Saving current best (at 18 epoch): model_best.pth Best word_acc: 0.903327
[2025-01-22 10:03:27,007 - trainer - INFO] - Train Epoch:[18/30] Step:[25000/25169] Loss: 0.393818 Loss_avg: 0.462265 LR: 0.00028899 Loss Fine: 0.393818 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:04:06,570 - trainer - INFO] - [Epoch End] Epoch:[18/30] Loss: 0.462166 LR: 0.00028871
 Validation result after 18 epoch: Word_acc: 0.898891 Word_acc_case_ins: 0.898891 Edit_distance_acc: 0.962326
[2025-01-22 10:04:07,957 - trainer - INFO] - Train Epoch:[19/30] Step:[1/25169] Loss: 0.445103 Loss_avg: 0.445103 LR: 0.00028871 Loss Fine: 0.445103 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:07:28,120 - trainer - INFO] - Train Epoch:[19/30] Step:[1000/25169] Loss: 0.562358 Loss_avg: 0.445706 LR: 0.00028707 Loss Fine: 0.562358 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:10:48,424 - trainer - INFO] - Train Epoch:[19/30] Step:[2000/25169] Loss: 0.335581 Loss_avg: 0.448815 LR: 0.00028544 Loss Fine: 0.335581 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:14:08,757 - trainer - INFO] - Train Epoch:[19/30] Step:[3000/25169] Loss: 0.308425 Loss_avg: 0.447684 LR: 0.00028380 Loss Fine: 0.308425 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:14:14,320 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[3000/25169] Word_acc: 0.904631 Word_acc_case_ins 0.904631 Edit_distance_acc: 0.964561
[2025-01-22 10:14:14,634 - trainer - INFO] - Saving current best (at 19 epoch): model_best.pth Best word_acc: 0.904631
[2025-01-22 10:17:34,945 - trainer - INFO] - Train Epoch:[19/30] Step:[4000/25169] Loss: 0.352509 Loss_avg: 0.446468 LR: 0.00028217 Loss Fine: 0.352509 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:20:55,299 - trainer - INFO] - Train Epoch:[19/30] Step:[5000/25169] Loss: 0.596134 Loss_avg: 0.447743 LR: 0.00028054 Loss Fine: 0.596134 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:24:15,617 - trainer - INFO] - Train Epoch:[19/30] Step:[6000/25169] Loss: 0.422937 Loss_avg: 0.447145 LR: 0.00027891 Loss Fine: 0.422937 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:24:21,208 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[6000/25169] Word_acc: 0.901761 Word_acc_case_ins 0.901761 Edit_distance_acc: 0.962375
[2025-01-22 10:27:41,492 - trainer - INFO] - Train Epoch:[19/30] Step:[7000/25169] Loss: 0.471287 Loss_avg: 0.447469 LR: 0.00027729 Loss Fine: 0.471287 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:31:01,699 - trainer - INFO] - Train Epoch:[19/30] Step:[8000/25169] Loss: 0.446834 Loss_avg: 0.447234 LR: 0.00027566 Loss Fine: 0.446834 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:34:21,938 - trainer - INFO] - Train Epoch:[19/30] Step:[9000/25169] Loss: 0.349772 Loss_avg: 0.447349 LR: 0.00027404 Loss Fine: 0.349772 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:34:27,553 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[9000/25169] Word_acc: 0.903718 Word_acc_case_ins 0.903718 Edit_distance_acc: 0.964291
[2025-01-22 10:37:47,798 - trainer - INFO] - Train Epoch:[19/30] Step:[10000/25169] Loss: 0.385459 Loss_avg: 0.447327 LR: 0.00027242 Loss Fine: 0.385459 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:41:08,024 - trainer - INFO] - Train Epoch:[19/30] Step:[11000/25169] Loss: 0.348666 Loss_avg: 0.447569 LR: 0.00027081 Loss Fine: 0.348666 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:44:28,175 - trainer - INFO] - Train Epoch:[19/30] Step:[12000/25169] Loss: 0.440931 Loss_avg: 0.447560 LR: 0.00026919 Loss Fine: 0.440931 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:44:33,725 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[12000/25169] Word_acc: 0.906197 Word_acc_case_ins 0.906197 Edit_distance_acc: 0.965863
[2025-01-22 10:44:34,032 - trainer - INFO] - Saving current best (at 19 epoch): model_best.pth Best word_acc: 0.906197
[2025-01-22 10:47:54,234 - trainer - INFO] - Train Epoch:[19/30] Step:[13000/25169] Loss: 0.291695 Loss_avg: 0.447542 LR: 0.00026758 Loss Fine: 0.291695 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:51:14,456 - trainer - INFO] - Train Epoch:[19/30] Step:[14000/25169] Loss: 0.291580 Loss_avg: 0.447219 LR: 0.00026597 Loss Fine: 0.291580 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:54:34,705 - trainer - INFO] - Train Epoch:[19/30] Step:[15000/25169] Loss: 0.316526 Loss_avg: 0.447284 LR: 0.00026437 Loss Fine: 0.316526 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 10:54:40,321 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[15000/25169] Word_acc: 0.905284 Word_acc_case_ins 0.905284 Edit_distance_acc: 0.963505
[2025-01-22 10:58:00,586 - trainer - INFO] - Train Epoch:[19/30] Step:[16000/25169] Loss: 0.539586 Loss_avg: 0.447034 LR: 0.00026276 Loss Fine: 0.539586 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:01:20,709 - trainer - INFO] - Train Epoch:[19/30] Step:[17000/25169] Loss: 0.387469 Loss_avg: 0.446540 LR: 0.00026116 Loss Fine: 0.387469 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:04:40,837 - trainer - INFO] - Train Epoch:[19/30] Step:[18000/25169] Loss: 0.366386 Loss_avg: 0.446345 LR: 0.00025956 Loss Fine: 0.366386 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:04:46,460 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[18000/25169] Word_acc: 0.901500 Word_acc_case_ins 0.901500 Edit_distance_acc: 0.964880
[2025-01-22 11:08:06,661 - trainer - INFO] - Train Epoch:[19/30] Step:[19000/25169] Loss: 0.464111 Loss_avg: 0.445893 LR: 0.00025796 Loss Fine: 0.464111 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:11:26,889 - trainer - INFO] - Train Epoch:[19/30] Step:[20000/25169] Loss: 0.468663 Loss_avg: 0.445732 LR: 0.00025637 Loss Fine: 0.468663 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:14:47,062 - trainer - INFO] - Train Epoch:[19/30] Step:[21000/25169] Loss: 0.368949 Loss_avg: 0.445370 LR: 0.00025478 Loss Fine: 0.368949 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:14:52,637 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[21000/25169] Word_acc: 0.906719 Word_acc_case_ins 0.906719 Edit_distance_acc: 0.965322
[2025-01-22 11:14:52,949 - trainer - INFO] - Saving current best (at 19 epoch): model_best.pth Best word_acc: 0.906719
[2025-01-22 11:18:13,158 - trainer - INFO] - Train Epoch:[19/30] Step:[22000/25169] Loss: 0.309658 Loss_avg: 0.445033 LR: 0.00025319 Loss Fine: 0.309658 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:21:33,392 - trainer - INFO] - Train Epoch:[19/30] Step:[23000/25169] Loss: 0.346552 Loss_avg: 0.444827 LR: 0.00025160 Loss Fine: 0.346552 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:24:53,614 - trainer - INFO] - Train Epoch:[19/30] Step:[24000/25169] Loss: 0.493273 Loss_avg: 0.444560 LR: 0.00025002 Loss Fine: 0.493273 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:24:59,199 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[24000/25169] Word_acc: 0.907241 Word_acc_case_ins 0.907241 Edit_distance_acc: 0.966207
[2025-01-22 11:24:59,535 - trainer - INFO] - Saving current best (at 19 epoch): model_best.pth Best word_acc: 0.907241
[2025-01-22 11:28:19,867 - trainer - INFO] - Train Epoch:[19/30] Step:[25000/25169] Loss: 0.440470 Loss_avg: 0.444147 LR: 0.00024844 Loss Fine: 0.440470 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:28:59,449 - trainer - INFO] - [Epoch End] Epoch:[19/30] Loss: 0.444059 LR: 0.00024817
 Validation result after 19 epoch: Word_acc: 0.903066 Word_acc_case_ins: 0.903066 Edit_distance_acc: 0.964856
[2025-01-22 11:29:01,154 - trainer - INFO] - Train Epoch:[20/30] Step:[1/25169] Loss: 0.375106 Loss_avg: 0.375106 LR: 0.00024817 Loss Fine: 0.375106 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:32:25,698 - trainer - INFO] - Train Epoch:[20/30] Step:[1000/25169] Loss: 0.434458 Loss_avg: 0.422859 LR: 0.00024659 Loss Fine: 0.434458 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:35:45,838 - trainer - INFO] - Train Epoch:[20/30] Step:[2000/25169] Loss: 0.427115 Loss_avg: 0.429919 LR: 0.00024502 Loss Fine: 0.427115 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:39:05,988 - trainer - INFO] - Train Epoch:[20/30] Step:[3000/25169] Loss: 0.448697 Loss_avg: 0.430090 LR: 0.00024344 Loss Fine: 0.448697 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:39:11,588 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[3000/25169] Word_acc: 0.903979 Word_acc_case_ins 0.903979 Edit_distance_acc: 0.964831
[2025-01-22 11:42:31,766 - trainer - INFO] - Train Epoch:[20/30] Step:[4000/25169] Loss: 0.341342 Loss_avg: 0.429217 LR: 0.00024187 Loss Fine: 0.341342 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:45:52,004 - trainer - INFO] - Train Epoch:[20/30] Step:[5000/25169] Loss: 0.447171 Loss_avg: 0.429845 LR: 0.00024031 Loss Fine: 0.447171 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:49:12,171 - trainer - INFO] - Train Epoch:[20/30] Step:[6000/25169] Loss: 0.366649 Loss_avg: 0.429226 LR: 0.00023874 Loss Fine: 0.366649 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:49:17,775 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[6000/25169] Word_acc: 0.903196 Word_acc_case_ins 0.903196 Edit_distance_acc: 0.962793
[2025-01-22 11:52:38,050 - trainer - INFO] - Train Epoch:[20/30] Step:[7000/25169] Loss: 0.561904 Loss_avg: 0.429880 LR: 0.00023718 Loss Fine: 0.561904 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:55:58,258 - trainer - INFO] - Train Epoch:[20/30] Step:[8000/25169] Loss: 0.374356 Loss_avg: 0.429573 LR: 0.00023563 Loss Fine: 0.374356 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:59:18,449 - trainer - INFO] - Train Epoch:[20/30] Step:[9000/25169] Loss: 0.574917 Loss_avg: 0.429816 LR: 0.00023407 Loss Fine: 0.574917 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 11:59:24,024 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[9000/25169] Word_acc: 0.909850 Word_acc_case_ins 0.909850 Edit_distance_acc: 0.966133
[2025-01-22 11:59:24,326 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.909850
[2025-01-22 12:02:44,527 - trainer - INFO] - Train Epoch:[20/30] Step:[10000/25169] Loss: 0.280907 Loss_avg: 0.429709 LR: 0.00023252 Loss Fine: 0.280907 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:06:04,746 - trainer - INFO] - Train Epoch:[20/30] Step:[11000/25169] Loss: 0.496536 Loss_avg: 0.429520 LR: 0.00023097 Loss Fine: 0.496536 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:09:24,962 - trainer - INFO] - Train Epoch:[20/30] Step:[12000/25169] Loss: 0.580427 Loss_avg: 0.429155 LR: 0.00022943 Loss Fine: 0.580427 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:09:30,540 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[12000/25169] Word_acc: 0.910372 Word_acc_case_ins 0.910372 Edit_distance_acc: 0.967680
[2025-01-22 12:09:30,849 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.910372
[2025-01-22 12:12:51,204 - trainer - INFO] - Train Epoch:[20/30] Step:[13000/25169] Loss: 0.320647 Loss_avg: 0.428832 LR: 0.00022788 Loss Fine: 0.320647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:16:11,488 - trainer - INFO] - Train Epoch:[20/30] Step:[14000/25169] Loss: 0.319653 Loss_avg: 0.429219 LR: 0.00022634 Loss Fine: 0.319653 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:19:31,806 - trainer - INFO] - Train Epoch:[20/30] Step:[15000/25169] Loss: 0.443389 Loss_avg: 0.429092 LR: 0.00022481 Loss Fine: 0.443389 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:19:37,424 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[15000/25169] Word_acc: 0.912068 Word_acc_case_ins 0.912068 Edit_distance_acc: 0.966821
[2025-01-22 12:19:37,748 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.912068
[2025-01-22 12:22:57,956 - trainer - INFO] - Train Epoch:[20/30] Step:[16000/25169] Loss: 0.513180 Loss_avg: 0.428654 LR: 0.00022327 Loss Fine: 0.513180 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:26:18,150 - trainer - INFO] - Train Epoch:[20/30] Step:[17000/25169] Loss: 0.523729 Loss_avg: 0.428448 LR: 0.00022175 Loss Fine: 0.523729 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:29:38,406 - trainer - INFO] - Train Epoch:[20/30] Step:[18000/25169] Loss: 0.406391 Loss_avg: 0.428216 LR: 0.00022022 Loss Fine: 0.406391 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:29:43,992 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[18000/25169] Word_acc: 0.907893 Word_acc_case_ins 0.907893 Edit_distance_acc: 0.966624
[2025-01-22 12:33:04,191 - trainer - INFO] - Train Epoch:[20/30] Step:[19000/25169] Loss: 0.501095 Loss_avg: 0.428063 LR: 0.00021870 Loss Fine: 0.501095 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:36:24,426 - trainer - INFO] - Train Epoch:[20/30] Step:[20000/25169] Loss: 0.353726 Loss_avg: 0.428067 LR: 0.00021718 Loss Fine: 0.353726 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:39:44,574 - trainer - INFO] - Train Epoch:[20/30] Step:[21000/25169] Loss: 0.606203 Loss_avg: 0.427564 LR: 0.00021566 Loss Fine: 0.606203 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:39:50,155 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[21000/25169] Word_acc: 0.912851 Word_acc_case_ins 0.912851 Edit_distance_acc: 0.967975
[2025-01-22 12:39:50,464 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.912851
[2025-01-22 12:43:10,741 - trainer - INFO] - Train Epoch:[20/30] Step:[22000/25169] Loss: 0.357463 Loss_avg: 0.427421 LR: 0.00021415 Loss Fine: 0.357463 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:46:30,935 - trainer - INFO] - Train Epoch:[20/30] Step:[23000/25169] Loss: 0.330179 Loss_avg: 0.427187 LR: 0.00021264 Loss Fine: 0.330179 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:49:51,238 - trainer - INFO] - Train Epoch:[20/30] Step:[24000/25169] Loss: 0.561040 Loss_avg: 0.427065 LR: 0.00021113 Loss Fine: 0.561040 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:49:56,832 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[24000/25169] Word_acc: 0.911937 Word_acc_case_ins 0.911937 Edit_distance_acc: 0.967410
[2025-01-22 12:53:17,072 - trainer - INFO] - Train Epoch:[20/30] Step:[25000/25169] Loss: 0.369963 Loss_avg: 0.427031 LR: 0.00020963 Loss Fine: 0.369963 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:53:56,671 - trainer - INFO] - [Epoch End] Epoch:[20/30] Loss: 0.426913 LR: 0.00020937
 Validation result after 20 epoch: Word_acc: 0.908415 Word_acc_case_ins: 0.908415 Edit_distance_acc: 0.966698
[2025-01-22 12:53:58,293 - trainer - INFO] - Train Epoch:[21/30] Step:[1/25169] Loss: 0.334123 Loss_avg: 0.334123 LR: 0.00020937 Loss Fine: 0.334123 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 12:57:18,350 - trainer - INFO] - Train Epoch:[21/30] Step:[1000/25169] Loss: 0.506856 Loss_avg: 0.414832 LR: 0.00020787 Loss Fine: 0.506856 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:00:38,528 - trainer - INFO] - Train Epoch:[21/30] Step:[2000/25169] Loss: 0.414138 Loss_avg: 0.415512 LR: 0.00020638 Loss Fine: 0.414138 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:03:58,716 - trainer - INFO] - Train Epoch:[21/30] Step:[3000/25169] Loss: 0.403571 Loss_avg: 0.415081 LR: 0.00020489 Loss Fine: 0.403571 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:04:04,314 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[3000/25169] Word_acc: 0.913503 Word_acc_case_ins 0.913503 Edit_distance_acc: 0.969178
[2025-01-22 13:04:04,635 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.913503
[2025-01-22 13:07:25,004 - trainer - INFO] - Train Epoch:[21/30] Step:[4000/25169] Loss: 0.360170 Loss_avg: 0.412985 LR: 0.00020340 Loss Fine: 0.360170 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:10:45,281 - trainer - INFO] - Train Epoch:[21/30] Step:[5000/25169] Loss: 0.386596 Loss_avg: 0.413339 LR: 0.00020191 Loss Fine: 0.386596 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:14:05,588 - trainer - INFO] - Train Epoch:[21/30] Step:[6000/25169] Loss: 0.404147 Loss_avg: 0.413437 LR: 0.00020043 Loss Fine: 0.404147 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:14:11,257 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[6000/25169] Word_acc: 0.915199 Word_acc_case_ins 0.915199 Edit_distance_acc: 0.968933
[2025-01-22 13:14:11,574 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.915199
[2025-01-22 13:17:31,842 - trainer - INFO] - Train Epoch:[21/30] Step:[7000/25169] Loss: 0.429235 Loss_avg: 0.413460 LR: 0.00019896 Loss Fine: 0.429235 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:20:52,109 - trainer - INFO] - Train Epoch:[21/30] Step:[8000/25169] Loss: 0.396540 Loss_avg: 0.412861 LR: 0.00019748 Loss Fine: 0.396540 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:24:12,303 - trainer - INFO] - Train Epoch:[21/30] Step:[9000/25169] Loss: 0.405483 Loss_avg: 0.413522 LR: 0.00019601 Loss Fine: 0.405483 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:24:17,911 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[9000/25169] Word_acc: 0.914416 Word_acc_case_ins 0.914416 Edit_distance_acc: 0.967484
[2025-01-22 13:27:38,090 - trainer - INFO] - Train Epoch:[21/30] Step:[10000/25169] Loss: 0.280652 Loss_avg: 0.413210 LR: 0.00019455 Loss Fine: 0.280652 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:30:58,340 - trainer - INFO] - Train Epoch:[21/30] Step:[11000/25169] Loss: 0.382787 Loss_avg: 0.412964 LR: 0.00019308 Loss Fine: 0.382787 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:34:18,598 - trainer - INFO] - Train Epoch:[21/30] Step:[12000/25169] Loss: 0.503636 Loss_avg: 0.412264 LR: 0.00019162 Loss Fine: 0.503636 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:34:24,158 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[12000/25169] Word_acc: 0.913372 Word_acc_case_ins 0.913372 Edit_distance_acc: 0.969055
[2025-01-22 13:37:44,451 - trainer - INFO] - Train Epoch:[21/30] Step:[13000/25169] Loss: 0.527957 Loss_avg: 0.412297 LR: 0.00019017 Loss Fine: 0.527957 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:41:04,747 - trainer - INFO] - Train Epoch:[21/30] Step:[14000/25169] Loss: 0.257903 Loss_avg: 0.412123 LR: 0.00018872 Loss Fine: 0.257903 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:44:25,108 - trainer - INFO] - Train Epoch:[21/30] Step:[15000/25169] Loss: 0.293686 Loss_avg: 0.411600 LR: 0.00018727 Loss Fine: 0.293686 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:44:30,699 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[15000/25169] Word_acc: 0.913633 Word_acc_case_ins 0.913633 Edit_distance_acc: 0.968049
[2025-01-22 13:47:50,923 - trainer - INFO] - Train Epoch:[21/30] Step:[16000/25169] Loss: 0.402128 Loss_avg: 0.411619 LR: 0.00018583 Loss Fine: 0.402128 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:51:11,151 - trainer - INFO] - Train Epoch:[21/30] Step:[17000/25169] Loss: 0.474194 Loss_avg: 0.411399 LR: 0.00018439 Loss Fine: 0.474194 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:54:31,355 - trainer - INFO] - Train Epoch:[21/30] Step:[18000/25169] Loss: 0.384650 Loss_avg: 0.411268 LR: 0.00018295 Loss Fine: 0.384650 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 13:54:36,965 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[18000/25169] Word_acc: 0.912590 Word_acc_case_ins 0.912590 Edit_distance_acc: 0.967901
[2025-01-22 13:57:57,205 - trainer - INFO] - Train Epoch:[21/30] Step:[19000/25169] Loss: 0.300991 Loss_avg: 0.411206 LR: 0.00018152 Loss Fine: 0.300991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:01:17,349 - trainer - INFO] - Train Epoch:[21/30] Step:[20000/25169] Loss: 0.381267 Loss_avg: 0.410769 LR: 0.00018009 Loss Fine: 0.381267 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:04:37,536 - trainer - INFO] - Train Epoch:[21/30] Step:[21000/25169] Loss: 0.370647 Loss_avg: 0.410424 LR: 0.00017867 Loss Fine: 0.370647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:04:43,144 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[21000/25169] Word_acc: 0.915982 Word_acc_case_ins 0.915982 Edit_distance_acc: 0.968417
[2025-01-22 14:04:43,475 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.915982
[2025-01-22 14:08:03,867 - trainer - INFO] - Train Epoch:[21/30] Step:[22000/25169] Loss: 0.343969 Loss_avg: 0.410094 LR: 0.00017725 Loss Fine: 0.343969 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:11:24,090 - trainer - INFO] - Train Epoch:[21/30] Step:[23000/25169] Loss: 0.360696 Loss_avg: 0.409780 LR: 0.00017583 Loss Fine: 0.360696 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:14:44,449 - trainer - INFO] - Train Epoch:[21/30] Step:[24000/25169] Loss: 0.253763 Loss_avg: 0.409539 LR: 0.00017442 Loss Fine: 0.253763 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:14:50,067 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[24000/25169] Word_acc: 0.911937 Word_acc_case_ins 0.911937 Edit_distance_acc: 0.968220
[2025-01-22 14:18:10,258 - trainer - INFO] - Train Epoch:[21/30] Step:[25000/25169] Loss: 0.328362 Loss_avg: 0.409097 LR: 0.00017301 Loss Fine: 0.328362 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:18:49,873 - trainer - INFO] - [Epoch End] Epoch:[21/30] Loss: 0.409008 LR: 0.00017278
 Validation result after 21 epoch: Word_acc: 0.916765 Word_acc_case_ins: 0.916765 Edit_distance_acc: 0.969301
[2025-01-22 14:18:50,182 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.916765
[2025-01-22 14:18:51,835 - trainer - INFO] - Train Epoch:[22/30] Step:[1/25169] Loss: 0.361713 Loss_avg: 0.361713 LR: 0.00017277 Loss Fine: 0.361713 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:22:12,007 - trainer - INFO] - Train Epoch:[22/30] Step:[1000/25169] Loss: 0.334037 Loss_avg: 0.400359 LR: 0.00017137 Loss Fine: 0.334037 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:25:32,316 - trainer - INFO] - Train Epoch:[22/30] Step:[2000/25169] Loss: 0.431870 Loss_avg: 0.399312 LR: 0.00016997 Loss Fine: 0.431870 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:28:52,666 - trainer - INFO] - Train Epoch:[22/30] Step:[3000/25169] Loss: 0.312647 Loss_avg: 0.398984 LR: 0.00016858 Loss Fine: 0.312647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:28:58,267 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[3000/25169] Word_acc: 0.914938 Word_acc_case_ins 0.914938 Edit_distance_acc: 0.968761
[2025-01-22 14:32:18,497 - trainer - INFO] - Train Epoch:[22/30] Step:[4000/25169] Loss: 0.344634 Loss_avg: 0.397675 LR: 0.00016719 Loss Fine: 0.344634 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:35:38,749 - trainer - INFO] - Train Epoch:[22/30] Step:[5000/25169] Loss: 0.394113 Loss_avg: 0.397283 LR: 0.00016580 Loss Fine: 0.394113 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:38:59,009 - trainer - INFO] - Train Epoch:[22/30] Step:[6000/25169] Loss: 0.352206 Loss_avg: 0.397401 LR: 0.00016442 Loss Fine: 0.352206 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:39:04,619 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[6000/25169] Word_acc: 0.916504 Word_acc_case_ins 0.916504 Edit_distance_acc: 0.969620
[2025-01-22 14:42:24,852 - trainer - INFO] - Train Epoch:[22/30] Step:[7000/25169] Loss: 0.399784 Loss_avg: 0.396378 LR: 0.00016304 Loss Fine: 0.399784 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:45:45,037 - trainer - INFO] - Train Epoch:[22/30] Step:[8000/25169] Loss: 0.304899 Loss_avg: 0.396218 LR: 0.00016167 Loss Fine: 0.304899 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:49:05,215 - trainer - INFO] - Train Epoch:[22/30] Step:[9000/25169] Loss: 0.585537 Loss_avg: 0.396735 LR: 0.00016030 Loss Fine: 0.585537 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:49:10,818 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[9000/25169] Word_acc: 0.913894 Word_acc_case_ins 0.913894 Edit_distance_acc: 0.969571
[2025-01-22 14:52:31,033 - trainer - INFO] - Train Epoch:[22/30] Step:[10000/25169] Loss: 0.434239 Loss_avg: 0.396341 LR: 0.00015894 Loss Fine: 0.434239 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:55:51,275 - trainer - INFO] - Train Epoch:[22/30] Step:[11000/25169] Loss: 0.504158 Loss_avg: 0.396004 LR: 0.00015758 Loss Fine: 0.504158 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:59:11,484 - trainer - INFO] - Train Epoch:[22/30] Step:[12000/25169] Loss: 0.333678 Loss_avg: 0.395407 LR: 0.00015622 Loss Fine: 0.333678 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 14:59:17,088 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[12000/25169] Word_acc: 0.917156 Word_acc_case_ins 0.917156 Edit_distance_acc: 0.970259
[2025-01-22 14:59:17,410 - trainer - INFO] - Saving current best (at 22 epoch): model_best.pth Best word_acc: 0.917156
[2025-01-22 15:02:37,667 - trainer - INFO] - Train Epoch:[22/30] Step:[13000/25169] Loss: 0.309701 Loss_avg: 0.394985 LR: 0.00015487 Loss Fine: 0.309701 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:05:57,899 - trainer - INFO] - Train Epoch:[22/30] Step:[14000/25169] Loss: 0.353067 Loss_avg: 0.394343 LR: 0.00015353 Loss Fine: 0.353067 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:09:18,059 - trainer - INFO] - Train Epoch:[22/30] Step:[15000/25169] Loss: 0.539189 Loss_avg: 0.393834 LR: 0.00015218 Loss Fine: 0.539189 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:09:23,669 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[15000/25169] Word_acc: 0.916243 Word_acc_case_ins 0.916243 Edit_distance_acc: 0.969694
[2025-01-22 15:12:43,901 - trainer - INFO] - Train Epoch:[22/30] Step:[16000/25169] Loss: 0.436126 Loss_avg: 0.393549 LR: 0.00015085 Loss Fine: 0.436126 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:16:04,090 - trainer - INFO] - Train Epoch:[22/30] Step:[17000/25169] Loss: 0.381058 Loss_avg: 0.393336 LR: 0.00014951 Loss Fine: 0.381058 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:19:29,450 - trainer - INFO] - Train Epoch:[22/30] Step:[18000/25169] Loss: 0.312968 Loss_avg: 0.393104 LR: 0.00014818 Loss Fine: 0.312968 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:19:35,039 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[18000/25169] Word_acc: 0.918069 Word_acc_case_ins 0.918069 Edit_distance_acc: 0.970603
[2025-01-22 15:19:35,342 - trainer - INFO] - Saving current best (at 22 epoch): model_best.pth Best word_acc: 0.918069
[2025-01-22 15:22:55,529 - trainer - INFO] - Train Epoch:[22/30] Step:[19000/25169] Loss: 0.370966 Loss_avg: 0.392686 LR: 0.00014686 Loss Fine: 0.370966 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:26:15,800 - trainer - INFO] - Train Epoch:[22/30] Step:[20000/25169] Loss: 0.336785 Loss_avg: 0.392266 LR: 0.00014554 Loss Fine: 0.336785 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:29:35,985 - trainer - INFO] - Train Epoch:[22/30] Step:[21000/25169] Loss: 0.352516 Loss_avg: 0.391790 LR: 0.00014423 Loss Fine: 0.352516 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:29:41,620 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[21000/25169] Word_acc: 0.921722 Word_acc_case_ins 0.921722 Edit_distance_acc: 0.971708
[2025-01-22 15:29:41,942 - trainer - INFO] - Saving current best (at 22 epoch): model_best.pth Best word_acc: 0.921722
[2025-01-22 15:33:02,263 - trainer - INFO] - Train Epoch:[22/30] Step:[22000/25169] Loss: 0.357239 Loss_avg: 0.391479 LR: 0.00014292 Loss Fine: 0.357239 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:36:22,540 - trainer - INFO] - Train Epoch:[22/30] Step:[23000/25169] Loss: 0.456699 Loss_avg: 0.391326 LR: 0.00014161 Loss Fine: 0.456699 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:39:42,849 - trainer - INFO] - Train Epoch:[22/30] Step:[24000/25169] Loss: 0.387162 Loss_avg: 0.390833 LR: 0.00014031 Loss Fine: 0.387162 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:39:48,470 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[24000/25169] Word_acc: 0.917808 Word_acc_case_ins 0.917808 Edit_distance_acc: 0.971339
[2025-01-22 15:43:08,694 - trainer - INFO] - Train Epoch:[22/30] Step:[25000/25169] Loss: 0.277263 Loss_avg: 0.390436 LR: 0.00013901 Loss Fine: 0.277263 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:43:48,389 - trainer - INFO] - [Epoch End] Epoch:[22/30] Loss: 0.390399 LR: 0.00013880
 Validation result after 22 epoch: Word_acc: 0.919113 Word_acc_case_ins: 0.919113 Edit_distance_acc: 0.970406
[2025-01-22 15:43:50,094 - trainer - INFO] - Train Epoch:[23/30] Step:[1/25169] Loss: 0.402046 Loss_avg: 0.402046 LR: 0.00013879 Loss Fine: 0.402046 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:47:10,256 - trainer - INFO] - Train Epoch:[23/30] Step:[1000/25169] Loss: 0.306680 Loss_avg: 0.377333 LR: 0.00013751 Loss Fine: 0.306680 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:50:30,537 - trainer - INFO] - Train Epoch:[23/30] Step:[2000/25169] Loss: 0.285084 Loss_avg: 0.378486 LR: 0.00013622 Loss Fine: 0.285084 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:53:50,783 - trainer - INFO] - Train Epoch:[23/30] Step:[3000/25169] Loss: 0.483093 Loss_avg: 0.376740 LR: 0.00013494 Loss Fine: 0.483093 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 15:53:56,483 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[3000/25169] Word_acc: 0.920287 Word_acc_case_ins 0.920287 Edit_distance_acc: 0.970308
[2025-01-22 15:57:16,775 - trainer - INFO] - Train Epoch:[23/30] Step:[4000/25169] Loss: 0.372980 Loss_avg: 0.376090 LR: 0.00013366 Loss Fine: 0.372980 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:00:37,146 - trainer - INFO] - Train Epoch:[23/30] Step:[5000/25169] Loss: 0.300924 Loss_avg: 0.375655 LR: 0.00013239 Loss Fine: 0.300924 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:03:57,457 - trainer - INFO] - Train Epoch:[23/30] Step:[6000/25169] Loss: 0.323277 Loss_avg: 0.375169 LR: 0.00013113 Loss Fine: 0.323277 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:04:03,062 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[6000/25169] Word_acc: 0.920809 Word_acc_case_ins 0.920809 Edit_distance_acc: 0.971978
[2025-01-22 16:07:23,343 - trainer - INFO] - Train Epoch:[23/30] Step:[7000/25169] Loss: 0.400993 Loss_avg: 0.375155 LR: 0.00012986 Loss Fine: 0.400993 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:10:43,634 - trainer - INFO] - Train Epoch:[23/30] Step:[8000/25169] Loss: 0.570565 Loss_avg: 0.375218 LR: 0.00012861 Loss Fine: 0.570565 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:14:03,854 - trainer - INFO] - Train Epoch:[23/30] Step:[9000/25169] Loss: 0.286529 Loss_avg: 0.374954 LR: 0.00012736 Loss Fine: 0.286529 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:14:09,463 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[9000/25169] Word_acc: 0.924070 Word_acc_case_ins 0.924070 Edit_distance_acc: 0.973132
[2025-01-22 16:14:09,783 - trainer - INFO] - Saving current best (at 23 epoch): model_best.pth Best word_acc: 0.924070
[2025-01-22 16:17:30,018 - trainer - INFO] - Train Epoch:[23/30] Step:[10000/25169] Loss: 0.445856 Loss_avg: 0.374903 LR: 0.00012611 Loss Fine: 0.445856 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:20:50,273 - trainer - INFO] - Train Epoch:[23/30] Step:[11000/25169] Loss: 0.416211 Loss_avg: 0.374515 LR: 0.00012487 Loss Fine: 0.416211 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:24:10,482 - trainer - INFO] - Train Epoch:[23/30] Step:[12000/25169] Loss: 0.350666 Loss_avg: 0.374076 LR: 0.00012363 Loss Fine: 0.350666 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:24:16,116 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[12000/25169] Word_acc: 0.920548 Word_acc_case_ins 0.920548 Edit_distance_acc: 0.971929
[2025-01-22 16:27:36,370 - trainer - INFO] - Train Epoch:[23/30] Step:[13000/25169] Loss: 0.503085 Loss_avg: 0.374313 LR: 0.00012240 Loss Fine: 0.503085 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:30:56,596 - trainer - INFO] - Train Epoch:[23/30] Step:[14000/25169] Loss: 0.463757 Loss_avg: 0.374157 LR: 0.00012117 Loss Fine: 0.463757 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:34:16,791 - trainer - INFO] - Train Epoch:[23/30] Step:[15000/25169] Loss: 0.375396 Loss_avg: 0.373913 LR: 0.00011995 Loss Fine: 0.375396 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:34:22,425 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[15000/25169] Word_acc: 0.920287 Word_acc_case_ins 0.920287 Edit_distance_acc: 0.972248
[2025-01-22 16:37:42,641 - trainer - INFO] - Train Epoch:[23/30] Step:[16000/25169] Loss: 0.320800 Loss_avg: 0.373992 LR: 0.00011874 Loss Fine: 0.320800 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:41:02,827 - trainer - INFO] - Train Epoch:[23/30] Step:[17000/25169] Loss: 0.394226 Loss_avg: 0.373977 LR: 0.00011753 Loss Fine: 0.394226 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:44:23,028 - trainer - INFO] - Train Epoch:[23/30] Step:[18000/25169] Loss: 0.320033 Loss_avg: 0.373534 LR: 0.00011632 Loss Fine: 0.320033 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:44:28,686 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[18000/25169] Word_acc: 0.923027 Word_acc_case_ins 0.923027 Edit_distance_acc: 0.972764
[2025-01-22 16:47:48,958 - trainer - INFO] - Train Epoch:[23/30] Step:[19000/25169] Loss: 0.319128 Loss_avg: 0.373194 LR: 0.00011512 Loss Fine: 0.319128 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:51:09,292 - trainer - INFO] - Train Epoch:[23/30] Step:[20000/25169] Loss: 0.268984 Loss_avg: 0.372870 LR: 0.00011392 Loss Fine: 0.268984 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:54:29,669 - trainer - INFO] - Train Epoch:[23/30] Step:[21000/25169] Loss: 0.334469 Loss_avg: 0.372686 LR: 0.00011273 Loss Fine: 0.334469 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 16:54:35,300 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[21000/25169] Word_acc: 0.924853 Word_acc_case_ins 0.924853 Edit_distance_acc: 0.972150
[2025-01-22 16:54:35,609 - trainer - INFO] - Saving current best (at 23 epoch): model_best.pth Best word_acc: 0.924853
[2025-01-22 16:57:55,930 - trainer - INFO] - Train Epoch:[23/30] Step:[22000/25169] Loss: 0.308603 Loss_avg: 0.372802 LR: 0.00011155 Loss Fine: 0.308603 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:01:16,223 - trainer - INFO] - Train Epoch:[23/30] Step:[23000/25169] Loss: 0.400990 Loss_avg: 0.372693 LR: 0.00011037 Loss Fine: 0.400990 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:04:36,464 - trainer - INFO] - Train Epoch:[23/30] Step:[24000/25169] Loss: 0.414849 Loss_avg: 0.372274 LR: 0.00010919 Loss Fine: 0.414849 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:04:42,054 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[24000/25169] Word_acc: 0.925636 Word_acc_case_ins 0.925636 Edit_distance_acc: 0.973304
[2025-01-22 17:04:42,371 - trainer - INFO] - Saving current best (at 23 epoch): model_best.pth Best word_acc: 0.925636
[2025-01-22 17:08:02,716 - trainer - INFO] - Train Epoch:[23/30] Step:[25000/25169] Loss: 0.292865 Loss_avg: 0.371929 LR: 0.00010802 Loss Fine: 0.292865 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:08:42,390 - trainer - INFO] - [Epoch End] Epoch:[23/30] Loss: 0.371830 LR: 0.00010783
 Validation result after 23 epoch: Word_acc: 0.927593 Word_acc_case_ins: 0.927593 Edit_distance_acc: 0.974385
[2025-01-22 17:08:42,730 - trainer - INFO] - Saving current best (at 23 epoch): model_best.pth Best word_acc: 0.927593
[2025-01-22 17:08:44,367 - trainer - INFO] - Train Epoch:[24/30] Step:[1/25169] Loss: 0.230542 Loss_avg: 0.230542 LR: 0.00010783 Loss Fine: 0.230542 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:12:04,526 - trainer - INFO] - Train Epoch:[24/30] Step:[1000/25169] Loss: 0.319361 Loss_avg: 0.355807 LR: 0.00010666 Loss Fine: 0.319361 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:15:24,798 - trainer - INFO] - Train Epoch:[24/30] Step:[2000/25169] Loss: 0.425796 Loss_avg: 0.359653 LR: 0.00010551 Loss Fine: 0.425796 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:18:45,043 - trainer - INFO] - Train Epoch:[24/30] Step:[3000/25169] Loss: 0.392655 Loss_avg: 0.359825 LR: 0.00010435 Loss Fine: 0.392655 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:18:50,645 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[3000/25169] Word_acc: 0.927202 Word_acc_case_ins 0.927202 Edit_distance_acc: 0.973894
[2025-01-22 17:22:10,876 - trainer - INFO] - Train Epoch:[24/30] Step:[4000/25169] Loss: 0.304747 Loss_avg: 0.359048 LR: 0.00010321 Loss Fine: 0.304747 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:25:31,079 - trainer - INFO] - Train Epoch:[24/30] Step:[5000/25169] Loss: 0.310365 Loss_avg: 0.357998 LR: 0.00010206 Loss Fine: 0.310365 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:28:51,330 - trainer - INFO] - Train Epoch:[24/30] Step:[6000/25169] Loss: 0.269988 Loss_avg: 0.357393 LR: 0.00010093 Loss Fine: 0.269988 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:28:56,945 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[6000/25169] Word_acc: 0.928637 Word_acc_case_ins 0.928637 Edit_distance_acc: 0.974532
[2025-01-22 17:28:57,261 - trainer - INFO] - Saving current best (at 24 epoch): model_best.pth Best word_acc: 0.928637
[2025-01-22 17:32:17,470 - trainer - INFO] - Train Epoch:[24/30] Step:[7000/25169] Loss: 0.330456 Loss_avg: 0.356695 LR: 0.00009980 Loss Fine: 0.330456 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:35:37,735 - trainer - INFO] - Train Epoch:[24/30] Step:[8000/25169] Loss: 0.341122 Loss_avg: 0.356515 LR: 0.00009867 Loss Fine: 0.341122 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:38:57,994 - trainer - INFO] - Train Epoch:[24/30] Step:[9000/25169] Loss: 0.375290 Loss_avg: 0.356152 LR: 0.00009755 Loss Fine: 0.375290 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:39:03,605 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[9000/25169] Word_acc: 0.927332 Word_acc_case_ins 0.927332 Edit_distance_acc: 0.973992
[2025-01-22 17:42:23,887 - trainer - INFO] - Train Epoch:[24/30] Step:[10000/25169] Loss: 0.255426 Loss_avg: 0.356159 LR: 0.00009644 Loss Fine: 0.255426 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:45:44,280 - trainer - INFO] - Train Epoch:[24/30] Step:[11000/25169] Loss: 0.208591 Loss_avg: 0.355941 LR: 0.00009533 Loss Fine: 0.208591 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:49:04,594 - trainer - INFO] - Train Epoch:[24/30] Step:[12000/25169] Loss: 0.355518 Loss_avg: 0.355942 LR: 0.00009423 Loss Fine: 0.355518 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:49:10,245 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[12000/25169] Word_acc: 0.924462 Word_acc_case_ins 0.924462 Edit_distance_acc: 0.973157
[2025-01-22 17:52:30,500 - trainer - INFO] - Train Epoch:[24/30] Step:[13000/25169] Loss: 0.390703 Loss_avg: 0.355843 LR: 0.00009313 Loss Fine: 0.390703 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:55:50,800 - trainer - INFO] - Train Epoch:[24/30] Step:[14000/25169] Loss: 0.297195 Loss_avg: 0.355518 LR: 0.00009204 Loss Fine: 0.297195 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:59:11,070 - trainer - INFO] - Train Epoch:[24/30] Step:[15000/25169] Loss: 0.461841 Loss_avg: 0.355651 LR: 0.00009095 Loss Fine: 0.461841 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 17:59:16,730 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[15000/25169] Word_acc: 0.928637 Word_acc_case_ins 0.928637 Edit_distance_acc: 0.973894
[2025-01-22 17:59:17,064 - trainer - INFO] - Saving current best (at 24 epoch): model_best.pth Best word_acc: 0.928637
[2025-01-22 18:02:37,442 - trainer - INFO] - Train Epoch:[24/30] Step:[16000/25169] Loss: 0.268225 Loss_avg: 0.355178 LR: 0.00008987 Loss Fine: 0.268225 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:05:57,814 - trainer - INFO] - Train Epoch:[24/30] Step:[17000/25169] Loss: 0.337076 Loss_avg: 0.355133 LR: 0.00008879 Loss Fine: 0.337076 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:09:18,185 - trainer - INFO] - Train Epoch:[24/30] Step:[18000/25169] Loss: 0.305179 Loss_avg: 0.355041 LR: 0.00008772 Loss Fine: 0.305179 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:09:23,909 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[18000/25169] Word_acc: 0.928115 Word_acc_case_ins 0.928115 Edit_distance_acc: 0.974581
[2025-01-22 18:12:44,238 - trainer - INFO] - Train Epoch:[24/30] Step:[19000/25169] Loss: 0.378413 Loss_avg: 0.354787 LR: 0.00008666 Loss Fine: 0.378413 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:16:04,495 - trainer - INFO] - Train Epoch:[24/30] Step:[20000/25169] Loss: 0.405681 Loss_avg: 0.354746 LR: 0.00008560 Loss Fine: 0.405681 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:19:24,690 - trainer - INFO] - Train Epoch:[24/30] Step:[21000/25169] Loss: 0.306674 Loss_avg: 0.354626 LR: 0.00008455 Loss Fine: 0.306674 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:19:30,370 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[21000/25169] Word_acc: 0.928245 Word_acc_case_ins 0.928245 Edit_distance_acc: 0.974925
[2025-01-22 18:22:50,613 - trainer - INFO] - Train Epoch:[24/30] Step:[22000/25169] Loss: 0.455672 Loss_avg: 0.354555 LR: 0.00008350 Loss Fine: 0.455672 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:26:10,867 - trainer - INFO] - Train Epoch:[24/30] Step:[23000/25169] Loss: 0.251114 Loss_avg: 0.354188 LR: 0.00008246 Loss Fine: 0.251114 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:29:31,156 - trainer - INFO] - Train Epoch:[24/30] Step:[24000/25169] Loss: 0.295971 Loss_avg: 0.353850 LR: 0.00008143 Loss Fine: 0.295971 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:29:36,772 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[24000/25169] Word_acc: 0.929289 Word_acc_case_ins 0.929289 Edit_distance_acc: 0.975809
[2025-01-22 18:29:37,078 - trainer - INFO] - Saving current best (at 24 epoch): model_best.pth Best word_acc: 0.929289
[2025-01-22 18:32:57,306 - trainer - INFO] - Train Epoch:[24/30] Step:[25000/25169] Loss: 0.501117 Loss_avg: 0.353558 LR: 0.00008040 Loss Fine: 0.501117 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:33:36,999 - trainer - INFO] - [Epoch End] Epoch:[24/30] Loss: 0.353553 LR: 0.00008022
 Validation result after 24 epoch: Word_acc: 0.929550 Word_acc_case_ins: 0.929550 Edit_distance_acc: 0.974925
[2025-01-22 18:33:37,318 - trainer - INFO] - Saving current best (at 24 epoch): model_best.pth Best word_acc: 0.929550
[2025-01-22 18:33:39,107 - trainer - INFO] - Train Epoch:[25/30] Step:[1/25169] Loss: 0.374144 Loss_avg: 0.374144 LR: 0.00008022 Loss Fine: 0.374144 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:36:59,137 - trainer - INFO] - Train Epoch:[25/30] Step:[1000/25169] Loss: 0.334150 Loss_avg: 0.344917 LR: 0.00007920 Loss Fine: 0.334150 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:40:19,324 - trainer - INFO] - Train Epoch:[25/30] Step:[2000/25169] Loss: 0.530924 Loss_avg: 0.345104 LR: 0.00007819 Loss Fine: 0.530924 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:43:39,493 - trainer - INFO] - Train Epoch:[25/30] Step:[3000/25169] Loss: 0.286444 Loss_avg: 0.344159 LR: 0.00007717 Loss Fine: 0.286444 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:43:45,112 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[3000/25169] Word_acc: 0.930463 Word_acc_case_ins 0.930463 Edit_distance_acc: 0.975490
[2025-01-22 18:43:45,419 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.930463
[2025-01-22 18:47:05,609 - trainer - INFO] - Train Epoch:[25/30] Step:[4000/25169] Loss: 0.317109 Loss_avg: 0.342037 LR: 0.00007617 Loss Fine: 0.317109 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:50:25,842 - trainer - INFO] - Train Epoch:[25/30] Step:[5000/25169] Loss: 0.261791 Loss_avg: 0.340918 LR: 0.00007517 Loss Fine: 0.261791 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:53:46,067 - trainer - INFO] - Train Epoch:[25/30] Step:[6000/25169] Loss: 0.337886 Loss_avg: 0.341315 LR: 0.00007418 Loss Fine: 0.337886 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 18:53:51,725 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[6000/25169] Word_acc: 0.929811 Word_acc_case_ins 0.929811 Edit_distance_acc: 0.976079
[2025-01-22 18:57:12,009 - trainer - INFO] - Train Epoch:[25/30] Step:[7000/25169] Loss: 0.347868 Loss_avg: 0.340691 LR: 0.00007319 Loss Fine: 0.347868 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:00:32,262 - trainer - INFO] - Train Epoch:[25/30] Step:[8000/25169] Loss: 0.202873 Loss_avg: 0.340184 LR: 0.00007221 Loss Fine: 0.202873 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:03:52,406 - trainer - INFO] - Train Epoch:[25/30] Step:[9000/25169] Loss: 0.360035 Loss_avg: 0.339543 LR: 0.00007123 Loss Fine: 0.360035 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:03:57,984 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[9000/25169] Word_acc: 0.931637 Word_acc_case_ins 0.931637 Edit_distance_acc: 0.975736
[2025-01-22 19:03:58,322 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.931637
[2025-01-22 19:07:18,509 - trainer - INFO] - Train Epoch:[25/30] Step:[10000/25169] Loss: 0.365396 Loss_avg: 0.339500 LR: 0.00007026 Loss Fine: 0.365396 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:10:38,629 - trainer - INFO] - Train Epoch:[25/30] Step:[11000/25169] Loss: 0.369346 Loss_avg: 0.339022 LR: 0.00006930 Loss Fine: 0.369346 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:13:58,858 - trainer - INFO] - Train Epoch:[25/30] Step:[12000/25169] Loss: 0.223557 Loss_avg: 0.338637 LR: 0.00006834 Loss Fine: 0.223557 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:14:04,467 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[12000/25169] Word_acc: 0.930202 Word_acc_case_ins 0.930202 Edit_distance_acc: 0.975367
[2025-01-22 19:17:24,668 - trainer - INFO] - Train Epoch:[25/30] Step:[13000/25169] Loss: 0.334016 Loss_avg: 0.338216 LR: 0.00006739 Loss Fine: 0.334016 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:20:44,954 - trainer - INFO] - Train Epoch:[25/30] Step:[14000/25169] Loss: 0.341029 Loss_avg: 0.338168 LR: 0.00006645 Loss Fine: 0.341029 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:24:05,169 - trainer - INFO] - Train Epoch:[25/30] Step:[15000/25169] Loss: 0.426376 Loss_avg: 0.338022 LR: 0.00006551 Loss Fine: 0.426376 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:24:10,744 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[15000/25169] Word_acc: 0.932029 Word_acc_case_ins 0.932029 Edit_distance_acc: 0.976178
[2025-01-22 19:24:11,055 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.932029
[2025-01-22 19:27:31,296 - trainer - INFO] - Train Epoch:[25/30] Step:[16000/25169] Loss: 0.388012 Loss_avg: 0.337594 LR: 0.00006458 Loss Fine: 0.388012 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:30:51,608 - trainer - INFO] - Train Epoch:[25/30] Step:[17000/25169] Loss: 0.345773 Loss_avg: 0.337257 LR: 0.00006365 Loss Fine: 0.345773 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:34:11,859 - trainer - INFO] - Train Epoch:[25/30] Step:[18000/25169] Loss: 0.279460 Loss_avg: 0.336894 LR: 0.00006273 Loss Fine: 0.279460 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:34:17,507 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[18000/25169] Word_acc: 0.930333 Word_acc_case_ins 0.930333 Edit_distance_acc: 0.975515
[2025-01-22 19:37:37,779 - trainer - INFO] - Train Epoch:[25/30] Step:[19000/25169] Loss: 0.404144 Loss_avg: 0.336770 LR: 0.00006181 Loss Fine: 0.404144 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:41:04,873 - trainer - INFO] - Train Epoch:[25/30] Step:[20000/25169] Loss: 0.289657 Loss_avg: 0.336423 LR: 0.00006091 Loss Fine: 0.289657 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:44:25,122 - trainer - INFO] - Train Epoch:[25/30] Step:[21000/25169] Loss: 0.273461 Loss_avg: 0.335968 LR: 0.00006000 Loss Fine: 0.273461 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:44:30,687 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[21000/25169] Word_acc: 0.933072 Word_acc_case_ins 0.933072 Edit_distance_acc: 0.976374
[2025-01-22 19:44:30,996 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.933072
[2025-01-22 19:47:51,191 - trainer - INFO] - Train Epoch:[25/30] Step:[22000/25169] Loss: 0.357164 Loss_avg: 0.335585 LR: 0.00005911 Loss Fine: 0.357164 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:51:11,428 - trainer - INFO] - Train Epoch:[25/30] Step:[23000/25169] Loss: 0.394901 Loss_avg: 0.335360 LR: 0.00005822 Loss Fine: 0.394901 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:54:31,633 - trainer - INFO] - Train Epoch:[25/30] Step:[24000/25169] Loss: 0.310404 Loss_avg: 0.335118 LR: 0.00005733 Loss Fine: 0.310404 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:54:37,237 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[24000/25169] Word_acc: 0.932681 Word_acc_case_ins 0.932681 Edit_distance_acc: 0.976693
[2025-01-22 19:57:57,408 - trainer - INFO] - Train Epoch:[25/30] Step:[25000/25169] Loss: 0.289253 Loss_avg: 0.334983 LR: 0.00005646 Loss Fine: 0.289253 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 19:58:37,037 - trainer - INFO] - [Epoch End] Epoch:[25/30] Loss: 0.334952 LR: 0.00005631
 Validation result after 25 epoch: Word_acc: 0.932681 Word_acc_case_ins: 0.932681 Edit_distance_acc: 0.977234
[2025-01-22 19:58:38,720 - trainer - INFO] - Train Epoch:[26/30] Step:[1/25169] Loss: 0.265449 Loss_avg: 0.265449 LR: 0.00005631 Loss Fine: 0.265449 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:01:58,762 - trainer - INFO] - Train Epoch:[26/30] Step:[1000/25169] Loss: 0.405497 Loss_avg: 0.317784 LR: 0.00005544 Loss Fine: 0.405497 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:05:18,959 - trainer - INFO] - Train Epoch:[26/30] Step:[2000/25169] Loss: 0.461426 Loss_avg: 0.320871 LR: 0.00005457 Loss Fine: 0.461426 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:08:39,128 - trainer - INFO] - Train Epoch:[26/30] Step:[3000/25169] Loss: 0.370553 Loss_avg: 0.320096 LR: 0.00005372 Loss Fine: 0.370553 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:08:44,739 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[3000/25169] Word_acc: 0.934247 Word_acc_case_ins 0.934247 Edit_distance_acc: 0.976890
[2025-01-22 20:08:45,053 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.934247
[2025-01-22 20:12:05,274 - trainer - INFO] - Train Epoch:[26/30] Step:[4000/25169] Loss: 0.486976 Loss_avg: 0.320451 LR: 0.00005287 Loss Fine: 0.486976 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:15:25,516 - trainer - INFO] - Train Epoch:[26/30] Step:[5000/25169] Loss: 0.310528 Loss_avg: 0.320276 LR: 0.00005202 Loss Fine: 0.310528 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:18:45,769 - trainer - INFO] - Train Epoch:[26/30] Step:[6000/25169] Loss: 0.330282 Loss_avg: 0.320367 LR: 0.00005118 Loss Fine: 0.330282 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:18:51,336 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[6000/25169] Word_acc: 0.932681 Word_acc_case_ins 0.932681 Edit_distance_acc: 0.976276
[2025-01-22 20:22:11,469 - trainer - INFO] - Train Epoch:[26/30] Step:[7000/25169] Loss: 0.345696 Loss_avg: 0.320649 LR: 0.00005035 Loss Fine: 0.345696 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:25:31,655 - trainer - INFO] - Train Epoch:[26/30] Step:[8000/25169] Loss: 0.284944 Loss_avg: 0.320736 LR: 0.00004952 Loss Fine: 0.284944 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:28:51,821 - trainer - INFO] - Train Epoch:[26/30] Step:[9000/25169] Loss: 0.417643 Loss_avg: 0.320615 LR: 0.00004870 Loss Fine: 0.417643 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:28:57,425 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[9000/25169] Word_acc: 0.935812 Word_acc_case_ins 0.935812 Edit_distance_acc: 0.978241
[2025-01-22 20:28:57,754 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.935812
[2025-01-22 20:32:18,036 - trainer - INFO] - Train Epoch:[26/30] Step:[10000/25169] Loss: 0.387594 Loss_avg: 0.320975 LR: 0.00004789 Loss Fine: 0.387594 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:35:38,271 - trainer - INFO] - Train Epoch:[26/30] Step:[11000/25169] Loss: 0.389866 Loss_avg: 0.320611 LR: 0.00004708 Loss Fine: 0.389866 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:38:58,436 - trainer - INFO] - Train Epoch:[26/30] Step:[12000/25169] Loss: 0.422114 Loss_avg: 0.320176 LR: 0.00004628 Loss Fine: 0.422114 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:39:04,048 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[12000/25169] Word_acc: 0.934768 Word_acc_case_ins 0.934768 Edit_distance_acc: 0.977848
[2025-01-22 20:42:24,229 - trainer - INFO] - Train Epoch:[26/30] Step:[13000/25169] Loss: 0.243217 Loss_avg: 0.320116 LR: 0.00004549 Loss Fine: 0.243217 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:45:44,379 - trainer - INFO] - Train Epoch:[26/30] Step:[14000/25169] Loss: 0.351823 Loss_avg: 0.319746 LR: 0.00004470 Loss Fine: 0.351823 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:49:04,542 - trainer - INFO] - Train Epoch:[26/30] Step:[15000/25169] Loss: 0.197167 Loss_avg: 0.319670 LR: 0.00004392 Loss Fine: 0.197167 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:49:10,122 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[15000/25169] Word_acc: 0.934768 Word_acc_case_ins 0.934768 Edit_distance_acc: 0.977774
[2025-01-22 20:52:30,333 - trainer - INFO] - Train Epoch:[26/30] Step:[16000/25169] Loss: 0.350264 Loss_avg: 0.319502 LR: 0.00004315 Loss Fine: 0.350264 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:55:50,480 - trainer - INFO] - Train Epoch:[26/30] Step:[17000/25169] Loss: 0.307100 Loss_avg: 0.319119 LR: 0.00004238 Loss Fine: 0.307100 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:59:10,712 - trainer - INFO] - Train Epoch:[26/30] Step:[18000/25169] Loss: 0.267684 Loss_avg: 0.319064 LR: 0.00004162 Loss Fine: 0.267684 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 20:59:16,349 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[18000/25169] Word_acc: 0.934768 Word_acc_case_ins 0.934768 Edit_distance_acc: 0.977332
[2025-01-22 21:02:36,529 - trainer - INFO] - Train Epoch:[26/30] Step:[19000/25169] Loss: 0.425334 Loss_avg: 0.318655 LR: 0.00004086 Loss Fine: 0.425334 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:05:56,684 - trainer - INFO] - Train Epoch:[26/30] Step:[20000/25169] Loss: 0.276325 Loss_avg: 0.318374 LR: 0.00004012 Loss Fine: 0.276325 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:09:16,852 - trainer - INFO] - Train Epoch:[26/30] Step:[21000/25169] Loss: 0.309191 Loss_avg: 0.317991 LR: 0.00003937 Loss Fine: 0.309191 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:09:22,503 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[21000/25169] Word_acc: 0.936073 Word_acc_case_ins 0.936073 Edit_distance_acc: 0.978339
[2025-01-22 21:09:22,820 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.936073
[2025-01-22 21:12:42,989 - trainer - INFO] - Train Epoch:[26/30] Step:[22000/25169] Loss: 0.267007 Loss_avg: 0.317849 LR: 0.00003864 Loss Fine: 0.267007 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:16:03,163 - trainer - INFO] - Train Epoch:[26/30] Step:[23000/25169] Loss: 0.270572 Loss_avg: 0.317702 LR: 0.00003791 Loss Fine: 0.270572 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:19:23,303 - trainer - INFO] - Train Epoch:[26/30] Step:[24000/25169] Loss: 0.281467 Loss_avg: 0.317492 LR: 0.00003719 Loss Fine: 0.281467 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:19:28,819 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[24000/25169] Word_acc: 0.936464 Word_acc_case_ins 0.936464 Edit_distance_acc: 0.977455
[2025-01-22 21:19:29,132 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.936464
[2025-01-22 21:22:49,337 - trainer - INFO] - Train Epoch:[26/30] Step:[25000/25169] Loss: 0.176645 Loss_avg: 0.317247 LR: 0.00003647 Loss Fine: 0.176645 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:23:29,036 - trainer - INFO] - [Epoch End] Epoch:[26/30] Loss: 0.317243 LR: 0.00003635
 Validation result after 26 epoch: Word_acc: 0.938552 Word_acc_case_ins: 0.938552 Edit_distance_acc: 0.978462
[2025-01-22 21:23:29,384 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.938552
[2025-01-22 21:23:31,265 - trainer - INFO] - Train Epoch:[27/30] Step:[1/25169] Loss: 0.306638 Loss_avg: 0.306638 LR: 0.00003635 Loss Fine: 0.306638 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:26:51,415 - trainer - INFO] - Train Epoch:[27/30] Step:[1000/25169] Loss: 0.278714 Loss_avg: 0.306346 LR: 0.00003564 Loss Fine: 0.278714 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:30:11,671 - trainer - INFO] - Train Epoch:[27/30] Step:[2000/25169] Loss: 0.200564 Loss_avg: 0.304980 LR: 0.00003494 Loss Fine: 0.200564 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:33:31,970 - trainer - INFO] - Train Epoch:[27/30] Step:[3000/25169] Loss: 0.368072 Loss_avg: 0.304914 LR: 0.00003425 Loss Fine: 0.368072 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:33:37,572 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[3000/25169] Word_acc: 0.937639 Word_acc_case_ins 0.937639 Edit_distance_acc: 0.978339
[2025-01-22 21:36:57,774 - trainer - INFO] - Train Epoch:[27/30] Step:[4000/25169] Loss: 0.296655 Loss_avg: 0.305565 LR: 0.00003356 Loss Fine: 0.296655 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:40:18,061 - trainer - INFO] - Train Epoch:[27/30] Step:[5000/25169] Loss: 0.386794 Loss_avg: 0.306464 LR: 0.00003288 Loss Fine: 0.386794 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:43:38,287 - trainer - INFO] - Train Epoch:[27/30] Step:[6000/25169] Loss: 0.276289 Loss_avg: 0.305239 LR: 0.00003221 Loss Fine: 0.276289 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:43:43,848 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[6000/25169] Word_acc: 0.938943 Word_acc_case_ins 0.938943 Edit_distance_acc: 0.978805
[2025-01-22 21:43:44,145 - trainer - INFO] - Saving current best (at 27 epoch): model_best.pth Best word_acc: 0.938943
[2025-01-22 21:47:04,454 - trainer - INFO] - Train Epoch:[27/30] Step:[7000/25169] Loss: 0.599624 Loss_avg: 0.304415 LR: 0.00003154 Loss Fine: 0.599624 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:50:24,752 - trainer - INFO] - Train Epoch:[27/30] Step:[8000/25169] Loss: 0.380509 Loss_avg: 0.304401 LR: 0.00003088 Loss Fine: 0.380509 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:53:45,097 - trainer - INFO] - Train Epoch:[27/30] Step:[9000/25169] Loss: 0.379095 Loss_avg: 0.304027 LR: 0.00003022 Loss Fine: 0.379095 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 21:53:50,685 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[9000/25169] Word_acc: 0.936986 Word_acc_case_ins 0.936986 Edit_distance_acc: 0.977995
[2025-01-22 21:57:10,912 - trainer - INFO] - Train Epoch:[27/30] Step:[10000/25169] Loss: 0.267322 Loss_avg: 0.303758 LR: 0.00002958 Loss Fine: 0.267322 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:00:31,126 - trainer - INFO] - Train Epoch:[27/30] Step:[11000/25169] Loss: 0.364786 Loss_avg: 0.303671 LR: 0.00002894 Loss Fine: 0.364786 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:03:51,377 - trainer - INFO] - Train Epoch:[27/30] Step:[12000/25169] Loss: 0.204894 Loss_avg: 0.303747 LR: 0.00002830 Loss Fine: 0.204894 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:03:56,978 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[12000/25169] Word_acc: 0.938552 Word_acc_case_ins 0.938552 Edit_distance_acc: 0.978511
[2025-01-22 22:07:17,253 - trainer - INFO] - Train Epoch:[27/30] Step:[13000/25169] Loss: 0.410374 Loss_avg: 0.303457 LR: 0.00002767 Loss Fine: 0.410374 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:10:37,504 - trainer - INFO] - Train Epoch:[27/30] Step:[14000/25169] Loss: 0.460861 Loss_avg: 0.303126 LR: 0.00002705 Loss Fine: 0.460861 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:13:57,697 - trainer - INFO] - Train Epoch:[27/30] Step:[15000/25169] Loss: 0.544054 Loss_avg: 0.302810 LR: 0.00002644 Loss Fine: 0.544054 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:14:03,280 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[15000/25169] Word_acc: 0.937117 Word_acc_case_ins 0.937117 Edit_distance_acc: 0.978069
[2025-01-22 22:17:23,442 - trainer - INFO] - Train Epoch:[27/30] Step:[16000/25169] Loss: 0.237925 Loss_avg: 0.302328 LR: 0.00002583 Loss Fine: 0.237925 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:20:43,631 - trainer - INFO] - Train Epoch:[27/30] Step:[17000/25169] Loss: 0.298917 Loss_avg: 0.302062 LR: 0.00002523 Loss Fine: 0.298917 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:24:03,887 - trainer - INFO] - Train Epoch:[27/30] Step:[18000/25169] Loss: 0.289450 Loss_avg: 0.301667 LR: 0.00002464 Loss Fine: 0.289450 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:24:09,464 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[18000/25169] Word_acc: 0.938813 Word_acc_case_ins 0.938813 Edit_distance_acc: 0.978805
[2025-01-22 22:27:29,709 - trainer - INFO] - Train Epoch:[27/30] Step:[19000/25169] Loss: 0.264791 Loss_avg: 0.301471 LR: 0.00002405 Loss Fine: 0.264791 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:30:50,029 - trainer - INFO] - Train Epoch:[27/30] Step:[20000/25169] Loss: 0.310950 Loss_avg: 0.301371 LR: 0.00002347 Loss Fine: 0.310950 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:34:10,322 - trainer - INFO] - Train Epoch:[27/30] Step:[21000/25169] Loss: 0.228223 Loss_avg: 0.301224 LR: 0.00002290 Loss Fine: 0.228223 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:34:15,913 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[21000/25169] Word_acc: 0.939465 Word_acc_case_ins 0.939465 Edit_distance_acc: 0.979272
[2025-01-22 22:34:16,209 - trainer - INFO] - Saving current best (at 27 epoch): model_best.pth Best word_acc: 0.939465
[2025-01-22 22:37:36,479 - trainer - INFO] - Train Epoch:[27/30] Step:[22000/25169] Loss: 0.225842 Loss_avg: 0.300958 LR: 0.00002234 Loss Fine: 0.225842 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:40:56,672 - trainer - INFO] - Train Epoch:[27/30] Step:[23000/25169] Loss: 0.303650 Loss_avg: 0.300847 LR: 0.00002178 Loss Fine: 0.303650 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:44:16,889 - trainer - INFO] - Train Epoch:[27/30] Step:[24000/25169] Loss: 0.298261 Loss_avg: 0.300664 LR: 0.00002122 Loss Fine: 0.298261 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:44:22,488 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[24000/25169] Word_acc: 0.941161 Word_acc_case_ins 0.941161 Edit_distance_acc: 0.978904
[2025-01-22 22:44:22,806 - trainer - INFO] - Saving current best (at 27 epoch): model_best.pth Best word_acc: 0.941161
[2025-01-22 22:47:43,028 - trainer - INFO] - Train Epoch:[27/30] Step:[25000/25169] Loss: 0.251316 Loss_avg: 0.300268 LR: 0.00002068 Loss Fine: 0.251316 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:48:22,717 - trainer - INFO] - [Epoch End] Epoch:[27/30] Loss: 0.300177 LR: 0.00002059
 Validation result after 27 epoch: Word_acc: 0.940509 Word_acc_case_ins: 0.940509 Edit_distance_acc: 0.979518
[2025-01-22 22:48:24,388 - trainer - INFO] - Train Epoch:[28/30] Step:[1/25169] Loss: 0.271516 Loss_avg: 0.271516 LR: 0.00002059 Loss Fine: 0.271516 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:51:44,457 - trainer - INFO] - Train Epoch:[28/30] Step:[1000/25169] Loss: 0.263630 Loss_avg: 0.288966 LR: 0.00002005 Loss Fine: 0.263630 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:55:04,691 - trainer - INFO] - Train Epoch:[28/30] Step:[2000/25169] Loss: 0.259745 Loss_avg: 0.289189 LR: 0.00001952 Loss Fine: 0.259745 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:58:24,848 - trainer - INFO] - Train Epoch:[28/30] Step:[3000/25169] Loss: 0.214417 Loss_avg: 0.290159 LR: 0.00001900 Loss Fine: 0.214417 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 22:58:30,437 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[3000/25169] Word_acc: 0.938943 Word_acc_case_ins 0.938943 Edit_distance_acc: 0.978977
[2025-01-22 23:01:50,684 - trainer - INFO] - Train Epoch:[28/30] Step:[4000/25169] Loss: 0.302816 Loss_avg: 0.290423 LR: 0.00001848 Loss Fine: 0.302816 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:05:11,007 - trainer - INFO] - Train Epoch:[28/30] Step:[5000/25169] Loss: 0.299302 Loss_avg: 0.290759 LR: 0.00001797 Loss Fine: 0.299302 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:08:31,394 - trainer - INFO] - Train Epoch:[28/30] Step:[6000/25169] Loss: 0.154604 Loss_avg: 0.290571 LR: 0.00001747 Loss Fine: 0.154604 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:08:36,983 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[6000/25169] Word_acc: 0.940509 Word_acc_case_ins 0.940509 Edit_distance_acc: 0.979665
[2025-01-22 23:11:57,149 - trainer - INFO] - Train Epoch:[28/30] Step:[7000/25169] Loss: 0.269009 Loss_avg: 0.289872 LR: 0.00001697 Loss Fine: 0.269009 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:15:17,404 - trainer - INFO] - Train Epoch:[28/30] Step:[8000/25169] Loss: 0.220537 Loss_avg: 0.289708 LR: 0.00001649 Loss Fine: 0.220537 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:18:37,557 - trainer - INFO] - Train Epoch:[28/30] Step:[9000/25169] Loss: 0.256919 Loss_avg: 0.289482 LR: 0.00001600 Loss Fine: 0.256919 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:18:43,153 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[9000/25169] Word_acc: 0.939987 Word_acc_case_ins 0.939987 Edit_distance_acc: 0.979272
[2025-01-22 23:22:03,400 - trainer - INFO] - Train Epoch:[28/30] Step:[10000/25169] Loss: 0.280864 Loss_avg: 0.289112 LR: 0.00001553 Loss Fine: 0.280864 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:25:23,600 - trainer - INFO] - Train Epoch:[28/30] Step:[11000/25169] Loss: 0.293118 Loss_avg: 0.289234 LR: 0.00001506 Loss Fine: 0.293118 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:28:43,752 - trainer - INFO] - Train Epoch:[28/30] Step:[12000/25169] Loss: 0.318406 Loss_avg: 0.288821 LR: 0.00001460 Loss Fine: 0.318406 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:28:49,355 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[12000/25169] Word_acc: 0.941292 Word_acc_case_ins 0.941292 Edit_distance_acc: 0.979690
[2025-01-22 23:28:49,674 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.941292
[2025-01-22 23:32:09,881 - trainer - INFO] - Train Epoch:[28/30] Step:[13000/25169] Loss: 0.244801 Loss_avg: 0.288755 LR: 0.00001415 Loss Fine: 0.244801 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:35:30,063 - trainer - INFO] - Train Epoch:[28/30] Step:[14000/25169] Loss: 0.214007 Loss_avg: 0.288608 LR: 0.00001370 Loss Fine: 0.214007 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:38:50,237 - trainer - INFO] - Train Epoch:[28/30] Step:[15000/25169] Loss: 0.339592 Loss_avg: 0.288302 LR: 0.00001326 Loss Fine: 0.339592 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:38:55,893 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[15000/25169] Word_acc: 0.939987 Word_acc_case_ins 0.939987 Edit_distance_acc: 0.978781
[2025-01-22 23:42:16,075 - trainer - INFO] - Train Epoch:[28/30] Step:[16000/25169] Loss: 0.295687 Loss_avg: 0.288191 LR: 0.00001283 Loss Fine: 0.295687 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:45:36,289 - trainer - INFO] - Train Epoch:[28/30] Step:[17000/25169] Loss: 0.320370 Loss_avg: 0.287810 LR: 0.00001241 Loss Fine: 0.320370 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:48:56,576 - trainer - INFO] - Train Epoch:[28/30] Step:[18000/25169] Loss: 0.320682 Loss_avg: 0.287728 LR: 0.00001199 Loss Fine: 0.320682 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:49:02,168 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[18000/25169] Word_acc: 0.941813 Word_acc_case_ins 0.941813 Edit_distance_acc: 0.979812
[2025-01-22 23:49:02,481 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.941813
[2025-01-22 23:52:22,728 - trainer - INFO] - Train Epoch:[28/30] Step:[19000/25169] Loss: 0.287306 Loss_avg: 0.287570 LR: 0.00001158 Loss Fine: 0.287306 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:55:43,059 - trainer - INFO] - Train Epoch:[28/30] Step:[20000/25169] Loss: 0.230483 Loss_avg: 0.287723 LR: 0.00001117 Loss Fine: 0.230483 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:59:03,423 - trainer - INFO] - Train Epoch:[28/30] Step:[21000/25169] Loss: 0.272291 Loss_avg: 0.287732 LR: 0.00001077 Loss Fine: 0.272291 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-22 23:59:09,048 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[21000/25169] Word_acc: 0.941292 Word_acc_case_ins 0.941292 Edit_distance_acc: 0.978830
[2025-01-23 00:02:29,247 - trainer - INFO] - Train Epoch:[28/30] Step:[22000/25169] Loss: 0.265399 Loss_avg: 0.287516 LR: 0.00001038 Loss Fine: 0.265399 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:05:49,450 - trainer - INFO] - Train Epoch:[28/30] Step:[23000/25169] Loss: 0.216712 Loss_avg: 0.287358 LR: 0.00001000 Loss Fine: 0.216712 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:09:09,720 - trainer - INFO] - Train Epoch:[28/30] Step:[24000/25169] Loss: 0.197111 Loss_avg: 0.287324 LR: 0.00000963 Loss Fine: 0.197111 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:09:15,312 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[24000/25169] Word_acc: 0.941161 Word_acc_case_ins 0.941161 Edit_distance_acc: 0.979714
[2025-01-23 00:12:35,562 - trainer - INFO] - Train Epoch:[28/30] Step:[25000/25169] Loss: 0.395348 Loss_avg: 0.287116 LR: 0.00000926 Loss Fine: 0.395348 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:13:15,177 - trainer - INFO] - [Epoch End] Epoch:[28/30] Loss: 0.287084 LR: 0.00000920
 Validation result after 28 epoch: Word_acc: 0.942205 Word_acc_case_ins: 0.942205 Edit_distance_acc: 0.979739
[2025-01-23 00:13:15,504 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.942205
[2025-01-23 00:13:17,133 - trainer - INFO] - Train Epoch:[29/30] Step:[1/25169] Loss: 0.361032 Loss_avg: 0.361032 LR: 0.00000920 Loss Fine: 0.361032 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:16:37,215 - trainer - INFO] - Train Epoch:[29/30] Step:[1000/25169] Loss: 0.211911 Loss_avg: 0.279809 LR: 0.00000884 Loss Fine: 0.211911 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:19:57,417 - trainer - INFO] - Train Epoch:[29/30] Step:[2000/25169] Loss: 0.400902 Loss_avg: 0.278984 LR: 0.00000848 Loss Fine: 0.400902 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:23:17,619 - trainer - INFO] - Train Epoch:[29/30] Step:[3000/25169] Loss: 0.245511 Loss_avg: 0.278569 LR: 0.00000814 Loss Fine: 0.245511 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:23:23,267 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[3000/25169] Word_acc: 0.941813 Word_acc_case_ins 0.941813 Edit_distance_acc: 0.979861
[2025-01-23 00:26:43,504 - trainer - INFO] - Train Epoch:[29/30] Step:[4000/25169] Loss: 0.302045 Loss_avg: 0.278211 LR: 0.00000780 Loss Fine: 0.302045 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:30:03,697 - trainer - INFO] - Train Epoch:[29/30] Step:[5000/25169] Loss: 0.202846 Loss_avg: 0.278059 LR: 0.00000747 Loss Fine: 0.202846 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:33:23,894 - trainer - INFO] - Train Epoch:[29/30] Step:[6000/25169] Loss: 0.269581 Loss_avg: 0.277955 LR: 0.00000714 Loss Fine: 0.269581 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:33:29,500 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[6000/25169] Word_acc: 0.942335 Word_acc_case_ins 0.942335 Edit_distance_acc: 0.979960
[2025-01-23 00:33:29,811 - trainer - INFO] - Saving current best (at 29 epoch): model_best.pth Best word_acc: 0.942335
[2025-01-23 00:36:49,994 - trainer - INFO] - Train Epoch:[29/30] Step:[7000/25169] Loss: 0.307043 Loss_avg: 0.277591 LR: 0.00000682 Loss Fine: 0.307043 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:40:16,824 - trainer - INFO] - Train Epoch:[29/30] Step:[8000/25169] Loss: 0.406241 Loss_avg: 0.277758 LR: 0.00000651 Loss Fine: 0.406241 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:43:36,961 - trainer - INFO] - Train Epoch:[29/30] Step:[9000/25169] Loss: 0.377320 Loss_avg: 0.277510 LR: 0.00000621 Loss Fine: 0.377320 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:43:42,596 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[9000/25169] Word_acc: 0.941292 Word_acc_case_ins 0.941292 Edit_distance_acc: 0.980132
[2025-01-23 00:47:02,830 - trainer - INFO] - Train Epoch:[29/30] Step:[10000/25169] Loss: 0.389339 Loss_avg: 0.277370 LR: 0.00000591 Loss Fine: 0.389339 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:50:23,043 - trainer - INFO] - Train Epoch:[29/30] Step:[11000/25169] Loss: 0.136387 Loss_avg: 0.277146 LR: 0.00000563 Loss Fine: 0.136387 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:53:43,211 - trainer - INFO] - Train Epoch:[29/30] Step:[12000/25169] Loss: 0.357088 Loss_avg: 0.277176 LR: 0.00000534 Loss Fine: 0.357088 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 00:53:48,852 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[12000/25169] Word_acc: 0.940900 Word_acc_case_ins 0.940900 Edit_distance_acc: 0.979714
[2025-01-23 00:57:09,055 - trainer - INFO] - Train Epoch:[29/30] Step:[13000/25169] Loss: 0.464766 Loss_avg: 0.277297 LR: 0.00000507 Loss Fine: 0.464766 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:00:29,293 - trainer - INFO] - Train Epoch:[29/30] Step:[14000/25169] Loss: 0.224797 Loss_avg: 0.277450 LR: 0.00000480 Loss Fine: 0.224797 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:03:49,507 - trainer - INFO] - Train Epoch:[29/30] Step:[15000/25169] Loss: 0.230019 Loss_avg: 0.277258 LR: 0.00000454 Loss Fine: 0.230019 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:03:55,139 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[15000/25169] Word_acc: 0.940639 Word_acc_case_ins 0.940639 Edit_distance_acc: 0.979640
[2025-01-23 01:07:15,365 - trainer - INFO] - Train Epoch:[29/30] Step:[16000/25169] Loss: 0.303978 Loss_avg: 0.277026 LR: 0.00000429 Loss Fine: 0.303978 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:10:35,589 - trainer - INFO] - Train Epoch:[29/30] Step:[17000/25169] Loss: 0.239619 Loss_avg: 0.276963 LR: 0.00000404 Loss Fine: 0.239619 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:13:55,831 - trainer - INFO] - Train Epoch:[29/30] Step:[18000/25169] Loss: 0.306131 Loss_avg: 0.276812 LR: 0.00000381 Loss Fine: 0.306131 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:14:01,468 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[18000/25169] Word_acc: 0.942727 Word_acc_case_ins 0.942727 Edit_distance_acc: 0.979911
[2025-01-23 01:14:01,780 - trainer - INFO] - Saving current best (at 29 epoch): model_best.pth Best word_acc: 0.942727
[2025-01-23 01:17:21,949 - trainer - INFO] - Train Epoch:[29/30] Step:[19000/25169] Loss: 0.270192 Loss_avg: 0.276779 LR: 0.00000357 Loss Fine: 0.270192 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:20:42,181 - trainer - INFO] - Train Epoch:[29/30] Step:[20000/25169] Loss: 0.332388 Loss_avg: 0.276587 LR: 0.00000335 Loss Fine: 0.332388 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:24:02,400 - trainer - INFO] - Train Epoch:[29/30] Step:[21000/25169] Loss: 0.353428 Loss_avg: 0.276552 LR: 0.00000313 Loss Fine: 0.353428 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:24:08,170 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[21000/25169] Word_acc: 0.942857 Word_acc_case_ins 0.942857 Edit_distance_acc: 0.980181
[2025-01-23 01:24:08,492 - trainer - INFO] - Saving current best (at 29 epoch): model_best.pth Best word_acc: 0.942857
[2025-01-23 01:27:28,857 - trainer - INFO] - Train Epoch:[29/30] Step:[22000/25169] Loss: 0.215578 Loss_avg: 0.276272 LR: 0.00000292 Loss Fine: 0.215578 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:30:49,239 - trainer - INFO] - Train Epoch:[29/30] Step:[23000/25169] Loss: 0.208816 Loss_avg: 0.276343 LR: 0.00000272 Loss Fine: 0.208816 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:34:09,562 - trainer - INFO] - Train Epoch:[29/30] Step:[24000/25169] Loss: 0.367773 Loss_avg: 0.276219 LR: 0.00000253 Loss Fine: 0.367773 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:34:15,197 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[24000/25169] Word_acc: 0.942074 Word_acc_case_ins 0.942074 Edit_distance_acc: 0.980083
[2025-01-23 01:37:35,434 - trainer - INFO] - Train Epoch:[29/30] Step:[25000/25169] Loss: 0.418474 Loss_avg: 0.276423 LR: 0.00000234 Loss Fine: 0.418474 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:38:15,196 - trainer - INFO] - [Epoch End] Epoch:[29/30] Loss: 0.276400 LR: 0.00000231
 Validation result after 29 epoch: Word_acc: 0.942335 Word_acc_case_ins: 0.942335 Edit_distance_acc: 0.979911
[2025-01-23 01:38:16,806 - trainer - INFO] - Train Epoch:[30/30] Step:[1/25169] Loss: 0.237740 Loss_avg: 0.237740 LR: 0.00000231 Loss Fine: 0.237740 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:41:37,144 - trainer - INFO] - Train Epoch:[30/30] Step:[1000/25169] Loss: 0.362916 Loss_avg: 0.271477 LR: 0.00000213 Loss Fine: 0.362916 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:44:57,390 - trainer - INFO] - Train Epoch:[30/30] Step:[2000/25169] Loss: 0.334652 Loss_avg: 0.271427 LR: 0.00000196 Loss Fine: 0.334652 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:48:17,695 - trainer - INFO] - Train Epoch:[30/30] Step:[3000/25169] Loss: 0.130661 Loss_avg: 0.271100 LR: 0.00000179 Loss Fine: 0.130661 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:48:23,406 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[3000/25169] Word_acc: 0.941553 Word_acc_case_ins 0.941553 Edit_distance_acc: 0.980058
[2025-01-23 01:51:43,581 - trainer - INFO] - Train Epoch:[30/30] Step:[4000/25169] Loss: 0.244071 Loss_avg: 0.271836 LR: 0.00000163 Loss Fine: 0.244071 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:55:03,776 - trainer - INFO] - Train Epoch:[30/30] Step:[5000/25169] Loss: 0.312547 Loss_avg: 0.271951 LR: 0.00000148 Loss Fine: 0.312547 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:58:23,983 - trainer - INFO] - Train Epoch:[30/30] Step:[6000/25169] Loss: 0.231788 Loss_avg: 0.271354 LR: 0.00000134 Loss Fine: 0.231788 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 01:58:29,634 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[6000/25169] Word_acc: 0.941553 Word_acc_case_ins 0.941553 Edit_distance_acc: 0.979763
[2025-01-23 02:01:49,874 - trainer - INFO] - Train Epoch:[30/30] Step:[7000/25169] Loss: 0.296469 Loss_avg: 0.271672 LR: 0.00000120 Loss Fine: 0.296469 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:05:10,088 - trainer - INFO] - Train Epoch:[30/30] Step:[8000/25169] Loss: 0.188906 Loss_avg: 0.271847 LR: 0.00000108 Loss Fine: 0.188906 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:08:30,243 - trainer - INFO] - Train Epoch:[30/30] Step:[9000/25169] Loss: 0.192884 Loss_avg: 0.271790 LR: 0.00000095 Loss Fine: 0.192884 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:08:35,912 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[9000/25169] Word_acc: 0.942988 Word_acc_case_ins 0.942988 Edit_distance_acc: 0.980156
[2025-01-23 02:08:36,232 - trainer - INFO] - Saving current best (at 30 epoch): model_best.pth Best word_acc: 0.942988
[2025-01-23 02:11:56,461 - trainer - INFO] - Train Epoch:[30/30] Step:[10000/25169] Loss: 0.247060 Loss_avg: 0.271592 LR: 0.00000084 Loss Fine: 0.247060 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:15:16,629 - trainer - INFO] - Train Epoch:[30/30] Step:[11000/25169] Loss: 0.317661 Loss_avg: 0.271840 LR: 0.00000073 Loss Fine: 0.317661 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:18:36,826 - trainer - INFO] - Train Epoch:[30/30] Step:[12000/25169] Loss: 0.306250 Loss_avg: 0.272072 LR: 0.00000063 Loss Fine: 0.306250 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:18:42,513 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[12000/25169] Word_acc: 0.941422 Word_acc_case_ins 0.941422 Edit_distance_acc: 0.980058
[2025-01-23 02:22:02,757 - trainer - INFO] - Train Epoch:[30/30] Step:[13000/25169] Loss: 0.150735 Loss_avg: 0.272183 LR: 0.00000054 Loss Fine: 0.150735 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:25:22,989 - trainer - INFO] - Train Epoch:[30/30] Step:[14000/25169] Loss: 0.317198 Loss_avg: 0.272215 LR: 0.00000046 Loss Fine: 0.317198 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:28:43,170 - trainer - INFO] - Train Epoch:[30/30] Step:[15000/25169] Loss: 0.202715 Loss_avg: 0.272196 LR: 0.00000038 Loss Fine: 0.202715 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:28:48,797 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[15000/25169] Word_acc: 0.942335 Word_acc_case_ins 0.942335 Edit_distance_acc: 0.980205
[2025-01-23 02:32:09,041 - trainer - INFO] - Train Epoch:[30/30] Step:[16000/25169] Loss: 0.278662 Loss_avg: 0.272261 LR: 0.00000031 Loss Fine: 0.278662 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:35:29,261 - trainer - INFO] - Train Epoch:[30/30] Step:[17000/25169] Loss: 0.405484 Loss_avg: 0.272188 LR: 0.00000025 Loss Fine: 0.405484 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:38:49,445 - trainer - INFO] - Train Epoch:[30/30] Step:[18000/25169] Loss: 0.163383 Loss_avg: 0.271957 LR: 0.00000019 Loss Fine: 0.163383 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:38:55,100 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[18000/25169] Word_acc: 0.942205 Word_acc_case_ins 0.942205 Edit_distance_acc: 0.980205
[2025-01-23 02:42:15,232 - trainer - INFO] - Train Epoch:[30/30] Step:[19000/25169] Loss: 0.281859 Loss_avg: 0.271990 LR: 0.00000014 Loss Fine: 0.281859 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:45:35,435 - trainer - INFO] - Train Epoch:[30/30] Step:[20000/25169] Loss: 0.191378 Loss_avg: 0.272130 LR: 0.00000010 Loss Fine: 0.191378 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:48:55,664 - trainer - INFO] - Train Epoch:[30/30] Step:[21000/25169] Loss: 0.309906 Loss_avg: 0.272205 LR: 0.00000007 Loss Fine: 0.309906 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:49:01,330 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[21000/25169] Word_acc: 0.941944 Word_acc_case_ins 0.941944 Edit_distance_acc: 0.980083
[2025-01-23 02:52:21,524 - trainer - INFO] - Train Epoch:[30/30] Step:[22000/25169] Loss: 0.365005 Loss_avg: 0.272143 LR: 0.00000004 Loss Fine: 0.365005 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:55:41,695 - trainer - INFO] - Train Epoch:[30/30] Step:[23000/25169] Loss: 0.220429 Loss_avg: 0.272177 LR: 0.00000002 Loss Fine: 0.220429 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:59:01,869 - trainer - INFO] - Train Epoch:[30/30] Step:[24000/25169] Loss: 0.245500 Loss_avg: 0.271993 LR: 0.00000001 Loss Fine: 0.245500 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 02:59:07,524 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[24000/25169] Word_acc: 0.942074 Word_acc_case_ins 0.942074 Edit_distance_acc: 0.980107
[2025-01-23 03:02:27,845 - trainer - INFO] - Train Epoch:[30/30] Step:[25000/25169] Loss: 0.353243 Loss_avg: 0.271864 LR: 0.00000000 Loss Fine: 0.353243 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 03:03:07,548 - trainer - INFO] - [Epoch End] Epoch:[30/30] Loss: 0.271912 LR: 0.00000000
 Validation result after 30 epoch: Word_acc: 0.942074 Word_acc_case_ins: 0.942074 Edit_distance_acc: 0.980107
[2025-01-23 03:03:07,549 - train - INFO] - Distributed training end...
