[2025-01-23 06:56:37,386 - train - INFO] - One GPU or CPU training mode start...
[2025-01-23 06:56:37,386 - train - WARNING] - You have chosen to deterministic training. This will fix random seed, turn on the CUDNN deterministic setting, turn off the CUDNN benchmark which can slow down your training considerably! 
[2025-01-23 06:56:41,725 - train - INFO] - Dataloader instances have finished. Train datasets: 3221637 Val datasets: 7665 Train_batch_size/gpu: 128 Val_batch_size/gpu: 128.
[2025-01-23 06:56:42,151 - train - INFO] - Model created, trainable parameters: 31.327794 MB.
[2025-01-23 06:56:42,152 - train - INFO] - Optimizer and lr_scheduler created.
[2025-01-23 06:56:42,152 - train - INFO] - Max_epochs: 30 Log_step_interval: 1000 Validation_step_interval: 3000.
[2025-01-23 06:56:42,152 - train - INFO] - Training start...
[2025-01-23 06:56:42,205 - trainer - WARNING] - Training is using GPU 0!
[2025-01-23 06:56:51,461 - trainer - INFO] - [Epoch Start] Epoch:[1/30] LR: 0.00002000
Validation result at 1 epoch: Word_acc: 0.000000 Word_acc_case_ins: 0.000000 Edit_distance_acc: -3.444545
[2025-01-23 06:56:52,720 - trainer - INFO] - Train Epoch:[1/30] Step:[1/25169] Loss: 4.596795 Loss_avg: 4.596795 LR: 0.00002000 Loss Fine: 4.596795 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:00:12,690 - trainer - INFO] - Train Epoch:[1/30] Step:[1000/25169] Loss: 2.624262 Loss_avg: 2.883459 LR: 0.00002332 Loss Fine: 2.624262 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:03:32,647 - trainer - INFO] - Train Epoch:[1/30] Step:[2000/25169] Loss: 1.797452 Loss_avg: 2.596927 LR: 0.00003317 Loss Fine: 1.797452 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:06:52,495 - trainer - INFO] - Train Epoch:[1/30] Step:[3000/25169] Loss: 1.396771 Loss_avg: 2.271272 LR: 0.00004930 Loss Fine: 1.396771 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:06:58,046 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[3000/25169] Word_acc: 0.464318 Word_acc_case_ins 0.464318 Edit_distance_acc: 0.762046
[2025-01-23 07:06:58,406 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.464318
[2025-01-23 07:10:18,460 - trainer - INFO] - Train Epoch:[1/30] Step:[4000/25169] Loss: 1.214184 Loss_avg: 2.034772 LR: 0.00007125 Loss Fine: 1.214184 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:13:38,540 - trainer - INFO] - Train Epoch:[1/30] Step:[5000/25169] Loss: 1.174457 Loss_avg: 1.867940 LR: 0.00009842 Loss Fine: 1.174457 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:16:58,518 - trainer - INFO] - Train Epoch:[1/30] Step:[6000/25169] Loss: 1.110808 Loss_avg: 1.744071 LR: 0.00013005 Loss Fine: 1.110808 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:17:03,981 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[6000/25169] Word_acc: 0.607697 Word_acc_case_ins 0.607697 Edit_distance_acc: 0.848396
[2025-01-23 07:17:04,326 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.607697
[2025-01-23 07:20:24,514 - trainer - INFO] - Train Epoch:[1/30] Step:[7000/25169] Loss: 1.012305 Loss_avg: 1.646475 LR: 0.00016527 Loss Fine: 1.012305 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:23:44,594 - trainer - INFO] - Train Epoch:[1/30] Step:[8000/25169] Loss: 1.080966 Loss_avg: 1.569462 LR: 0.00020311 Loss Fine: 1.080966 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:27:04,725 - trainer - INFO] - Train Epoch:[1/30] Step:[9000/25169] Loss: 0.995879 Loss_avg: 1.505843 LR: 0.00024252 Loss Fine: 0.995879 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:27:10,189 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[9000/25169] Word_acc: 0.720939 Word_acc_case_ins 0.720939 Edit_distance_acc: 0.885603
[2025-01-23 07:27:10,542 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.720939
[2025-01-23 07:30:30,593 - trainer - INFO] - Train Epoch:[1/30] Step:[10000/25169] Loss: 0.950702 Loss_avg: 1.452939 LR: 0.00028242 Loss Fine: 0.950702 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:33:50,740 - trainer - INFO] - Train Epoch:[1/30] Step:[11000/25169] Loss: 1.015536 Loss_avg: 1.408661 LR: 0.00032170 Loss Fine: 1.015536 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:37:10,714 - trainer - INFO] - Train Epoch:[1/30] Step:[12000/25169] Loss: 0.696927 Loss_avg: 1.370209 LR: 0.00035927 Loss Fine: 0.696927 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:37:16,190 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[12000/25169] Word_acc: 0.736204 Word_acc_case_ins 0.736204 Edit_distance_acc: 0.891031
[2025-01-23 07:37:16,522 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.736204
[2025-01-23 07:40:36,469 - trainer - INFO] - Train Epoch:[1/30] Step:[13000/25169] Loss: 0.994568 Loss_avg: 1.337065 LR: 0.00039410 Loss Fine: 0.994568 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:43:56,592 - trainer - INFO] - Train Epoch:[1/30] Step:[14000/25169] Loss: 0.929964 Loss_avg: 1.308388 LR: 0.00042522 Loss Fine: 0.929964 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:47:16,618 - trainer - INFO] - Train Epoch:[1/30] Step:[15000/25169] Loss: 1.288033 Loss_avg: 1.282920 LR: 0.00045178 Loss Fine: 1.288033 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:47:22,102 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[15000/25169] Word_acc: 0.747032 Word_acc_case_ins 0.747032 Edit_distance_acc: 0.892848
[2025-01-23 07:47:22,430 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.747032
[2025-01-23 07:50:42,453 - trainer - INFO] - Train Epoch:[1/30] Step:[16000/25169] Loss: 0.817601 Loss_avg: 1.258474 LR: 0.00047303 Loss Fine: 0.817601 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:54:02,556 - trainer - INFO] - Train Epoch:[1/30] Step:[17000/25169] Loss: 0.980535 Loss_avg: 1.237138 LR: 0.00048840 Loss Fine: 0.980535 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:57:22,546 - trainer - INFO] - Train Epoch:[1/30] Step:[18000/25169] Loss: 0.836919 Loss_avg: 1.217342 LR: 0.00049746 Loss Fine: 0.836919 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 07:57:27,987 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[18000/25169] Word_acc: 0.768950 Word_acc_case_ins 0.768950 Edit_distance_acc: 0.904195
[2025-01-23 07:57:28,331 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.768950
[2025-01-23 08:00:48,312 - trainer - INFO] - Train Epoch:[1/30] Step:[19000/25169] Loss: 0.693107 Loss_avg: 1.199065 LR: 0.00050000 Loss Fine: 0.693107 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:04:08,522 - trainer - INFO] - Train Epoch:[1/30] Step:[20000/25169] Loss: 0.676806 Loss_avg: 1.181400 LR: 0.00050000 Loss Fine: 0.676806 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:07:28,547 - trainer - INFO] - Train Epoch:[1/30] Step:[21000/25169] Loss: 0.758231 Loss_avg: 1.164359 LR: 0.00049999 Loss Fine: 0.758231 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:07:34,052 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[21000/25169] Word_acc: 0.784475 Word_acc_case_ins 0.784475 Edit_distance_acc: 0.909278
[2025-01-23 08:07:34,395 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.784475
[2025-01-23 08:10:54,592 - trainer - INFO] - Train Epoch:[1/30] Step:[22000/25169] Loss: 0.693160 Loss_avg: 1.148540 LR: 0.00049998 Loss Fine: 0.693160 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:14:14,753 - trainer - INFO] - Train Epoch:[1/30] Step:[23000/25169] Loss: 0.796646 Loss_avg: 1.133306 LR: 0.00049996 Loss Fine: 0.796646 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:17:34,964 - trainer - INFO] - Train Epoch:[1/30] Step:[24000/25169] Loss: 0.782387 Loss_avg: 1.118955 LR: 0.00049994 Loss Fine: 0.782387 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:17:40,422 - trainer - INFO] - [Step Validation] Epoch:[1/30] Step:[24000/25169] Word_acc: 0.797521 Word_acc_case_ins 0.797521 Edit_distance_acc: 0.911022
[2025-01-23 08:17:40,761 - trainer - INFO] - Saving current best (at 1 epoch): model_best.pth Best word_acc: 0.797521
[2025-01-23 08:21:00,751 - trainer - INFO] - Train Epoch:[1/30] Step:[25000/25169] Loss: 0.768903 Loss_avg: 1.105125 LR: 0.00049991 Loss Fine: 0.768903 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:21:40,173 - trainer - INFO] - [Epoch End] Epoch:[1/30] Loss: 1.102833 LR: 0.00049991
 Validation result after 1 epoch: Word_acc: 0.786171 Word_acc_case_ins: 0.786171 Edit_distance_acc: 0.911759
[2025-01-23 08:21:41,659 - trainer - INFO] - Train Epoch:[2/30] Step:[1/25169] Loss: 0.686113 Loss_avg: 0.686113 LR: 0.00049991 Loss Fine: 0.686113 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:25:01,618 - trainer - INFO] - Train Epoch:[2/30] Step:[1000/25169] Loss: 0.854008 Loss_avg: 0.750160 LR: 0.00049988 Loss Fine: 0.854008 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:28:21,682 - trainer - INFO] - Train Epoch:[2/30] Step:[2000/25169] Loss: 0.732682 Loss_avg: 0.749754 LR: 0.00049984 Loss Fine: 0.732682 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:31:42,039 - trainer - INFO] - Train Epoch:[2/30] Step:[3000/25169] Loss: 0.728176 Loss_avg: 0.746402 LR: 0.00049980 Loss Fine: 0.728176 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:31:47,450 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[3000/25169] Word_acc: 0.804305 Word_acc_case_ins 0.804305 Edit_distance_acc: 0.920649
[2025-01-23 08:31:47,798 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.804305
[2025-01-23 08:35:07,973 - trainer - INFO] - Train Epoch:[2/30] Step:[4000/25169] Loss: 0.742378 Loss_avg: 0.745733 LR: 0.00049976 Loss Fine: 0.742378 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:38:28,057 - trainer - INFO] - Train Epoch:[2/30] Step:[5000/25169] Loss: 0.856426 Loss_avg: 0.740694 LR: 0.00049971 Loss Fine: 0.856426 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:41:48,170 - trainer - INFO] - Train Epoch:[2/30] Step:[6000/25169] Loss: 0.549213 Loss_avg: 0.735968 LR: 0.00049966 Loss Fine: 0.549213 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:41:53,615 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[6000/25169] Word_acc: 0.822048 Word_acc_case_ins 0.822048 Edit_distance_acc: 0.930080
[2025-01-23 08:41:53,952 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.822048
[2025-01-23 08:45:14,201 - trainer - INFO] - Train Epoch:[2/30] Step:[7000/25169] Loss: 0.721000 Loss_avg: 0.732221 LR: 0.00049960 Loss Fine: 0.721000 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:48:34,657 - trainer - INFO] - Train Epoch:[2/30] Step:[8000/25169] Loss: 0.715085 Loss_avg: 0.728266 LR: 0.00049954 Loss Fine: 0.715085 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:51:54,726 - trainer - INFO] - Train Epoch:[2/30] Step:[9000/25169] Loss: 0.810466 Loss_avg: 0.724516 LR: 0.00049947 Loss Fine: 0.810466 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:52:00,149 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[9000/25169] Word_acc: 0.832877 Word_acc_case_ins 0.832877 Edit_distance_acc: 0.929884
[2025-01-23 08:52:00,474 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.832877
[2025-01-23 08:55:20,648 - trainer - INFO] - Train Epoch:[2/30] Step:[10000/25169] Loss: 0.582037 Loss_avg: 0.721532 LR: 0.00049940 Loss Fine: 0.582037 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 08:58:40,800 - trainer - INFO] - Train Epoch:[2/30] Step:[11000/25169] Loss: 0.744337 Loss_avg: 0.717676 LR: 0.00049932 Loss Fine: 0.744337 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:02:01,000 - trainer - INFO] - Train Epoch:[2/30] Step:[12000/25169] Loss: 0.601426 Loss_avg: 0.714720 LR: 0.00049924 Loss Fine: 0.601426 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:02:06,441 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[12000/25169] Word_acc: 0.825440 Word_acc_case_ins 0.825440 Edit_distance_acc: 0.930154
[2025-01-23 09:05:26,930 - trainer - INFO] - Train Epoch:[2/30] Step:[13000/25169] Loss: 0.963779 Loss_avg: 0.711664 LR: 0.00049915 Loss Fine: 0.963779 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:08:47,083 - trainer - INFO] - Train Epoch:[2/30] Step:[14000/25169] Loss: 0.757106 Loss_avg: 0.709100 LR: 0.00049906 Loss Fine: 0.757106 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:12:07,182 - trainer - INFO] - Train Epoch:[2/30] Step:[15000/25169] Loss: 0.614165 Loss_avg: 0.706633 LR: 0.00049897 Loss Fine: 0.614165 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:12:12,581 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[15000/25169] Word_acc: 0.841096 Word_acc_case_ins 0.841096 Edit_distance_acc: 0.936195
[2025-01-23 09:12:12,889 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.841096
[2025-01-23 09:15:33,055 - trainer - INFO] - Train Epoch:[2/30] Step:[16000/25169] Loss: 0.722305 Loss_avg: 0.703918 LR: 0.00049887 Loss Fine: 0.722305 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:18:53,191 - trainer - INFO] - Train Epoch:[2/30] Step:[17000/25169] Loss: 0.689196 Loss_avg: 0.701377 LR: 0.00049877 Loss Fine: 0.689196 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:22:13,299 - trainer - INFO] - Train Epoch:[2/30] Step:[18000/25169] Loss: 0.686927 Loss_avg: 0.698590 LR: 0.00049866 Loss Fine: 0.686927 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:22:18,706 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[18000/25169] Word_acc: 0.843053 Word_acc_case_ins 0.843053 Edit_distance_acc: 0.938504
[2025-01-23 09:22:19,018 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.843053
[2025-01-23 09:25:39,154 - trainer - INFO] - Train Epoch:[2/30] Step:[19000/25169] Loss: 0.515873 Loss_avg: 0.696171 LR: 0.00049855 Loss Fine: 0.515873 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:28:59,795 - trainer - INFO] - Train Epoch:[2/30] Step:[20000/25169] Loss: 0.528728 Loss_avg: 0.693756 LR: 0.00049843 Loss Fine: 0.528728 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:32:19,865 - trainer - INFO] - Train Epoch:[2/30] Step:[21000/25169] Loss: 0.550889 Loss_avg: 0.691096 LR: 0.00049831 Loss Fine: 0.550889 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:32:25,300 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[21000/25169] Word_acc: 0.847880 Word_acc_case_ins 0.847880 Edit_distance_acc: 0.939142
[2025-01-23 09:32:25,616 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.847880
[2025-01-23 09:35:45,814 - trainer - INFO] - Train Epoch:[2/30] Step:[22000/25169] Loss: 0.830913 Loss_avg: 0.688884 LR: 0.00049818 Loss Fine: 0.830913 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:39:05,958 - trainer - INFO] - Train Epoch:[2/30] Step:[23000/25169] Loss: 0.551190 Loss_avg: 0.686292 LR: 0.00049805 Loss Fine: 0.551190 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:42:26,065 - trainer - INFO] - Train Epoch:[2/30] Step:[24000/25169] Loss: 0.732003 Loss_avg: 0.684110 LR: 0.00049791 Loss Fine: 0.732003 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:42:31,494 - trainer - INFO] - [Step Validation] Epoch:[2/30] Step:[24000/25169] Word_acc: 0.853098 Word_acc_case_ins 0.853098 Edit_distance_acc: 0.942482
[2025-01-23 09:42:31,802 - trainer - INFO] - Saving current best (at 2 epoch): model_best.pth Best word_acc: 0.853098
[2025-01-23 09:45:51,935 - trainer - INFO] - Train Epoch:[2/30] Step:[25000/25169] Loss: 0.744512 Loss_avg: 0.681740 LR: 0.00049777 Loss Fine: 0.744512 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:46:31,382 - trainer - INFO] - [Epoch End] Epoch:[2/30] Loss: 0.681459 LR: 0.00049775
 Validation result after 2 epoch: Word_acc: 0.847880 Word_acc_case_ins: 0.847880 Edit_distance_acc: 0.941181
[2025-01-23 09:46:33,175 - trainer - INFO] - Train Epoch:[3/30] Step:[1/25169] Loss: 0.729465 Loss_avg: 0.729465 LR: 0.00049775 Loss Fine: 0.729465 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:49:53,108 - trainer - INFO] - Train Epoch:[3/30] Step:[1000/25169] Loss: 0.599268 Loss_avg: 0.619874 LR: 0.00049761 Loss Fine: 0.599268 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:53:13,790 - trainer - INFO] - Train Epoch:[3/30] Step:[2000/25169] Loss: 0.618495 Loss_avg: 0.624510 LR: 0.00049746 Loss Fine: 0.618495 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:56:33,915 - trainer - INFO] - Train Epoch:[3/30] Step:[3000/25169] Loss: 0.600436 Loss_avg: 0.623105 LR: 0.00049730 Loss Fine: 0.600436 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 09:56:39,392 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[3000/25169] Word_acc: 0.852316 Word_acc_case_ins 0.852316 Edit_distance_acc: 0.941279
[2025-01-23 09:59:59,548 - trainer - INFO] - Train Epoch:[3/30] Step:[4000/25169] Loss: 0.605608 Loss_avg: 0.622215 LR: 0.00049714 Loss Fine: 0.605608 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:03:19,704 - trainer - INFO] - Train Epoch:[3/30] Step:[5000/25169] Loss: 0.679639 Loss_avg: 0.620990 LR: 0.00049698 Loss Fine: 0.679639 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:06:39,865 - trainer - INFO] - Train Epoch:[3/30] Step:[6000/25169] Loss: 0.518323 Loss_avg: 0.620175 LR: 0.00049681 Loss Fine: 0.518323 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:06:45,322 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[6000/25169] Word_acc: 0.850098 Word_acc_case_ins 0.850098 Edit_distance_acc: 0.938799
[2025-01-23 10:10:05,469 - trainer - INFO] - Train Epoch:[3/30] Step:[7000/25169] Loss: 0.838930 Loss_avg: 0.618568 LR: 0.00049664 Loss Fine: 0.838930 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:13:25,641 - trainer - INFO] - Train Epoch:[3/30] Step:[8000/25169] Loss: 0.630674 Loss_avg: 0.617751 LR: 0.00049646 Loss Fine: 0.630674 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:16:45,765 - trainer - INFO] - Train Epoch:[3/30] Step:[9000/25169] Loss: 0.534843 Loss_avg: 0.616805 LR: 0.00049628 Loss Fine: 0.534843 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:16:51,181 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[9000/25169] Word_acc: 0.860274 Word_acc_case_ins 0.860274 Edit_distance_acc: 0.944447
[2025-01-23 10:16:51,510 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.860274
[2025-01-23 10:20:12,218 - trainer - INFO] - Train Epoch:[3/30] Step:[10000/25169] Loss: 0.632399 Loss_avg: 0.615504 LR: 0.00049610 Loss Fine: 0.632399 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:23:32,349 - trainer - INFO] - Train Epoch:[3/30] Step:[11000/25169] Loss: 0.610861 Loss_avg: 0.614571 LR: 0.00049591 Loss Fine: 0.610861 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:26:52,451 - trainer - INFO] - Train Epoch:[3/30] Step:[12000/25169] Loss: 0.458218 Loss_avg: 0.613449 LR: 0.00049571 Loss Fine: 0.458218 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:26:57,879 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[12000/25169] Word_acc: 0.848141 Word_acc_case_ins 0.848141 Edit_distance_acc: 0.941991
[2025-01-23 10:30:18,005 - trainer - INFO] - Train Epoch:[3/30] Step:[13000/25169] Loss: 0.477339 Loss_avg: 0.612508 LR: 0.00049551 Loss Fine: 0.477339 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:33:38,163 - trainer - INFO] - Train Epoch:[3/30] Step:[14000/25169] Loss: 0.404036 Loss_avg: 0.611516 LR: 0.00049531 Loss Fine: 0.404036 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:36:58,305 - trainer - INFO] - Train Epoch:[3/30] Step:[15000/25169] Loss: 0.668514 Loss_avg: 0.610749 LR: 0.00049510 Loss Fine: 0.668514 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:37:03,763 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[15000/25169] Word_acc: 0.862753 Word_acc_case_ins 0.862753 Edit_distance_acc: 0.946682
[2025-01-23 10:37:04,082 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.862753
[2025-01-23 10:40:24,171 - trainer - INFO] - Train Epoch:[3/30] Step:[16000/25169] Loss: 0.606777 Loss_avg: 0.609740 LR: 0.00049489 Loss Fine: 0.606777 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:43:44,297 - trainer - INFO] - Train Epoch:[3/30] Step:[17000/25169] Loss: 0.640404 Loss_avg: 0.608665 LR: 0.00049467 Loss Fine: 0.640404 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:47:04,454 - trainer - INFO] - Train Epoch:[3/30] Step:[18000/25169] Loss: 0.573606 Loss_avg: 0.607649 LR: 0.00049445 Loss Fine: 0.573606 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:47:09,891 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[18000/25169] Word_acc: 0.857926 Word_acc_case_ins 0.857926 Edit_distance_acc: 0.945405
[2025-01-23 10:50:30,047 - trainer - INFO] - Train Epoch:[3/30] Step:[19000/25169] Loss: 0.791834 Loss_avg: 0.606960 LR: 0.00049423 Loss Fine: 0.791834 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:53:50,894 - trainer - INFO] - Train Epoch:[3/30] Step:[20000/25169] Loss: 0.642608 Loss_avg: 0.606405 LR: 0.00049400 Loss Fine: 0.642608 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:57:11,087 - trainer - INFO] - Train Epoch:[3/30] Step:[21000/25169] Loss: 0.624772 Loss_avg: 0.605729 LR: 0.00049376 Loss Fine: 0.624772 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 10:57:16,535 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[21000/25169] Word_acc: 0.870450 Word_acc_case_ins 0.870450 Edit_distance_acc: 0.949531
[2025-01-23 10:57:16,853 - trainer - INFO] - Saving current best (at 3 epoch): model_best.pth Best word_acc: 0.870450
[2025-01-23 11:00:36,996 - trainer - INFO] - Train Epoch:[3/30] Step:[22000/25169] Loss: 0.573250 Loss_avg: 0.604894 LR: 0.00049352 Loss Fine: 0.573250 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:03:57,113 - trainer - INFO] - Train Epoch:[3/30] Step:[23000/25169] Loss: 0.461747 Loss_avg: 0.604014 LR: 0.00049328 Loss Fine: 0.461747 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:07:17,237 - trainer - INFO] - Train Epoch:[3/30] Step:[24000/25169] Loss: 0.774868 Loss_avg: 0.603178 LR: 0.00049303 Loss Fine: 0.774868 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:07:22,647 - trainer - INFO] - [Step Validation] Epoch:[3/30] Step:[24000/25169] Word_acc: 0.862492 Word_acc_case_ins 0.862492 Edit_distance_acc: 0.947222
[2025-01-23 11:10:42,746 - trainer - INFO] - Train Epoch:[3/30] Step:[25000/25169] Loss: 0.502981 Loss_avg: 0.602497 LR: 0.00049278 Loss Fine: 0.502981 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:11:22,159 - trainer - INFO] - [Epoch End] Epoch:[3/30] Loss: 0.602354 LR: 0.00049274
 Validation result after 3 epoch: Word_acc: 0.855708 Word_acc_case_ins: 0.855708 Edit_distance_acc: 0.944914
[2025-01-23 11:11:23,686 - trainer - INFO] - Train Epoch:[4/30] Step:[1/25169] Loss: 0.693858 Loss_avg: 0.693858 LR: 0.00049273 Loss Fine: 0.693858 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:14:43,589 - trainer - INFO] - Train Epoch:[4/30] Step:[1000/25169] Loss: 0.457307 Loss_avg: 0.577862 LR: 0.00049248 Loss Fine: 0.457307 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:18:03,815 - trainer - INFO] - Train Epoch:[4/30] Step:[2000/25169] Loss: 0.424193 Loss_avg: 0.579831 LR: 0.00049222 Loss Fine: 0.424193 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:21:23,994 - trainer - INFO] - Train Epoch:[4/30] Step:[3000/25169] Loss: 0.415616 Loss_avg: 0.579723 LR: 0.00049195 Loss Fine: 0.415616 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:21:29,427 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[3000/25169] Word_acc: 0.867971 Word_acc_case_ins 0.867971 Edit_distance_acc: 0.948033
[2025-01-23 11:24:49,572 - trainer - INFO] - Train Epoch:[4/30] Step:[4000/25169] Loss: 0.532712 Loss_avg: 0.578284 LR: 0.00049168 Loss Fine: 0.532712 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:28:10,403 - trainer - INFO] - Train Epoch:[4/30] Step:[5000/25169] Loss: 0.678249 Loss_avg: 0.577121 LR: 0.00049140 Loss Fine: 0.678249 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:31:30,560 - trainer - INFO] - Train Epoch:[4/30] Step:[6000/25169] Loss: 0.619549 Loss_avg: 0.576802 LR: 0.00049112 Loss Fine: 0.619549 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:31:35,975 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[6000/25169] Word_acc: 0.869798 Word_acc_case_ins 0.869798 Edit_distance_acc: 0.950243
[2025-01-23 11:34:56,110 - trainer - INFO] - Train Epoch:[4/30] Step:[7000/25169] Loss: 0.815373 Loss_avg: 0.576122 LR: 0.00049084 Loss Fine: 0.815373 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:38:16,399 - trainer - INFO] - Train Epoch:[4/30] Step:[8000/25169] Loss: 0.600997 Loss_avg: 0.575186 LR: 0.00049055 Loss Fine: 0.600997 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:41:36,591 - trainer - INFO] - Train Epoch:[4/30] Step:[9000/25169] Loss: 0.566139 Loss_avg: 0.575189 LR: 0.00049026 Loss Fine: 0.566139 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:41:42,012 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[9000/25169] Word_acc: 0.852577 Word_acc_case_ins 0.852577 Edit_distance_acc: 0.942286
[2025-01-23 11:45:02,228 - trainer - INFO] - Train Epoch:[4/30] Step:[10000/25169] Loss: 0.420879 Loss_avg: 0.575527 LR: 0.00048996 Loss Fine: 0.420879 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:48:22,324 - trainer - INFO] - Train Epoch:[4/30] Step:[11000/25169] Loss: 0.631195 Loss_avg: 0.575187 LR: 0.00048966 Loss Fine: 0.631195 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:51:42,402 - trainer - INFO] - Train Epoch:[4/30] Step:[12000/25169] Loss: 0.692813 Loss_avg: 0.575223 LR: 0.00048935 Loss Fine: 0.692813 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:51:47,900 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[12000/25169] Word_acc: 0.864318 Word_acc_case_ins 0.864318 Edit_distance_acc: 0.947959
[2025-01-23 11:55:08,037 - trainer - INFO] - Train Epoch:[4/30] Step:[13000/25169] Loss: 0.506207 Loss_avg: 0.574760 LR: 0.00048904 Loss Fine: 0.506207 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 11:58:28,178 - trainer - INFO] - Train Epoch:[4/30] Step:[14000/25169] Loss: 0.610860 Loss_avg: 0.574558 LR: 0.00048873 Loss Fine: 0.610860 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:01:48,249 - trainer - INFO] - Train Epoch:[4/30] Step:[15000/25169] Loss: 0.574468 Loss_avg: 0.574293 LR: 0.00048841 Loss Fine: 0.574468 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:01:53,670 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[15000/25169] Word_acc: 0.870059 Word_acc_case_ins 0.870059 Edit_distance_acc: 0.950612
[2025-01-23 12:05:13,829 - trainer - INFO] - Train Epoch:[4/30] Step:[16000/25169] Loss: 0.445796 Loss_avg: 0.574054 LR: 0.00048809 Loss Fine: 0.445796 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:08:33,961 - trainer - INFO] - Train Epoch:[4/30] Step:[17000/25169] Loss: 0.513174 Loss_avg: 0.573632 LR: 0.00048776 Loss Fine: 0.513174 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:11:55,068 - trainer - INFO] - Train Epoch:[4/30] Step:[18000/25169] Loss: 0.506876 Loss_avg: 0.573607 LR: 0.00048743 Loss Fine: 0.506876 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:12:00,527 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[18000/25169] Word_acc: 0.870972 Word_acc_case_ins 0.870972 Edit_distance_acc: 0.949998
[2025-01-23 12:12:00,843 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.870972
[2025-01-23 12:15:21,093 - trainer - INFO] - Train Epoch:[4/30] Step:[19000/25169] Loss: 0.503207 Loss_avg: 0.572800 LR: 0.00048709 Loss Fine: 0.503207 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:18:41,205 - trainer - INFO] - Train Epoch:[4/30] Step:[20000/25169] Loss: 0.641747 Loss_avg: 0.572172 LR: 0.00048675 Loss Fine: 0.641747 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:22:01,386 - trainer - INFO] - Train Epoch:[4/30] Step:[21000/25169] Loss: 0.529428 Loss_avg: 0.571919 LR: 0.00048641 Loss Fine: 0.529428 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:22:06,834 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[21000/25169] Word_acc: 0.868624 Word_acc_case_ins 0.868624 Edit_distance_acc: 0.948720
[2025-01-23 12:25:27,029 - trainer - INFO] - Train Epoch:[4/30] Step:[22000/25169] Loss: 0.594853 Loss_avg: 0.571759 LR: 0.00048606 Loss Fine: 0.594853 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:28:47,173 - trainer - INFO] - Train Epoch:[4/30] Step:[23000/25169] Loss: 0.616283 Loss_avg: 0.571084 LR: 0.00048570 Loss Fine: 0.616283 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:32:07,308 - trainer - INFO] - Train Epoch:[4/30] Step:[24000/25169] Loss: 0.479336 Loss_avg: 0.570399 LR: 0.00048535 Loss Fine: 0.479336 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:32:12,745 - trainer - INFO] - [Step Validation] Epoch:[4/30] Step:[24000/25169] Word_acc: 0.872277 Word_acc_case_ins 0.872277 Edit_distance_acc: 0.949113
[2025-01-23 12:32:13,047 - trainer - INFO] - Saving current best (at 4 epoch): model_best.pth Best word_acc: 0.872277
[2025-01-23 12:35:33,220 - trainer - INFO] - Train Epoch:[4/30] Step:[25000/25169] Loss: 0.806741 Loss_avg: 0.569748 LR: 0.00048498 Loss Fine: 0.806741 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:36:12,624 - trainer - INFO] - [Epoch End] Epoch:[4/30] Loss: 0.569624 LR: 0.00048492
 Validation result after 4 epoch: Word_acc: 0.871885 Word_acc_case_ins: 0.871885 Edit_distance_acc: 0.951643
[2025-01-23 12:36:14,110 - trainer - INFO] - Train Epoch:[5/30] Step:[1/25169] Loss: 0.689843 Loss_avg: 0.689843 LR: 0.00048492 Loss Fine: 0.689843 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:39:34,050 - trainer - INFO] - Train Epoch:[5/30] Step:[1000/25169] Loss: 0.491025 Loss_avg: 0.556222 LR: 0.00048456 Loss Fine: 0.491025 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:42:54,121 - trainer - INFO] - Train Epoch:[5/30] Step:[2000/25169] Loss: 0.479198 Loss_avg: 0.557364 LR: 0.00048418 Loss Fine: 0.479198 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:46:14,221 - trainer - INFO] - Train Epoch:[5/30] Step:[3000/25169] Loss: 0.421647 Loss_avg: 0.555055 LR: 0.00048381 Loss Fine: 0.421647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:46:19,735 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[3000/25169] Word_acc: 0.869537 Word_acc_case_ins 0.869537 Edit_distance_acc: 0.950612
[2025-01-23 12:49:39,961 - trainer - INFO] - Train Epoch:[5/30] Step:[4000/25169] Loss: 0.649558 Loss_avg: 0.555358 LR: 0.00048343 Loss Fine: 0.649558 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:53:00,067 - trainer - INFO] - Train Epoch:[5/30] Step:[5000/25169] Loss: 0.611806 Loss_avg: 0.554616 LR: 0.00048305 Loss Fine: 0.611806 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:56:20,198 - trainer - INFO] - Train Epoch:[5/30] Step:[6000/25169] Loss: 0.603945 Loss_avg: 0.554398 LR: 0.00048266 Loss Fine: 0.603945 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 12:56:25,660 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[6000/25169] Word_acc: 0.873973 Word_acc_case_ins 0.873973 Edit_distance_acc: 0.950661
[2025-01-23 12:56:25,968 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.873973
[2025-01-23 12:59:47,162 - trainer - INFO] - Train Epoch:[5/30] Step:[7000/25169] Loss: 0.450375 Loss_avg: 0.553988 LR: 0.00048226 Loss Fine: 0.450375 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:03:07,314 - trainer - INFO] - Train Epoch:[5/30] Step:[8000/25169] Loss: 0.408106 Loss_avg: 0.554271 LR: 0.00048187 Loss Fine: 0.408106 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:06:27,392 - trainer - INFO] - Train Epoch:[5/30] Step:[9000/25169] Loss: 0.466141 Loss_avg: 0.554116 LR: 0.00048147 Loss Fine: 0.466141 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:06:32,802 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[9000/25169] Word_acc: 0.862492 Word_acc_case_ins 0.862492 Edit_distance_acc: 0.947615
[2025-01-23 13:09:52,933 - trainer - INFO] - Train Epoch:[5/30] Step:[10000/25169] Loss: 0.703305 Loss_avg: 0.554251 LR: 0.00048106 Loss Fine: 0.703305 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:13:13,095 - trainer - INFO] - Train Epoch:[5/30] Step:[11000/25169] Loss: 0.499384 Loss_avg: 0.553825 LR: 0.00048065 Loss Fine: 0.499384 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:16:33,202 - trainer - INFO] - Train Epoch:[5/30] Step:[12000/25169] Loss: 0.729973 Loss_avg: 0.553643 LR: 0.00048024 Loss Fine: 0.729973 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:16:38,642 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[12000/25169] Word_acc: 0.874364 Word_acc_case_ins 0.874364 Edit_distance_acc: 0.951152
[2025-01-23 13:16:38,973 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.874364
[2025-01-23 13:19:59,078 - trainer - INFO] - Train Epoch:[5/30] Step:[13000/25169] Loss: 0.377642 Loss_avg: 0.553311 LR: 0.00047982 Loss Fine: 0.377642 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:23:19,124 - trainer - INFO] - Train Epoch:[5/30] Step:[14000/25169] Loss: 0.588012 Loss_avg: 0.553406 LR: 0.00047940 Loss Fine: 0.588012 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:26:39,231 - trainer - INFO] - Train Epoch:[5/30] Step:[15000/25169] Loss: 0.570769 Loss_avg: 0.553469 LR: 0.00047897 Loss Fine: 0.570769 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:26:44,656 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[15000/25169] Word_acc: 0.875277 Word_acc_case_ins 0.875277 Edit_distance_acc: 0.951987
[2025-01-23 13:26:44,958 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.875277
[2025-01-23 13:30:05,201 - trainer - INFO] - Train Epoch:[5/30] Step:[16000/25169] Loss: 0.518094 Loss_avg: 0.552689 LR: 0.00047854 Loss Fine: 0.518094 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:33:25,489 - trainer - INFO] - Train Epoch:[5/30] Step:[17000/25169] Loss: 0.594002 Loss_avg: 0.552386 LR: 0.00047811 Loss Fine: 0.594002 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:36:45,697 - trainer - INFO] - Train Epoch:[5/30] Step:[18000/25169] Loss: 0.505084 Loss_avg: 0.552016 LR: 0.00047767 Loss Fine: 0.505084 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:36:51,119 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[18000/25169] Word_acc: 0.873320 Word_acc_case_ins 0.873320 Edit_distance_acc: 0.951447
[2025-01-23 13:40:11,393 - trainer - INFO] - Train Epoch:[5/30] Step:[19000/25169] Loss: 0.528431 Loss_avg: 0.551707 LR: 0.00047723 Loss Fine: 0.528431 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:43:31,717 - trainer - INFO] - Train Epoch:[5/30] Step:[20000/25169] Loss: 0.395273 Loss_avg: 0.551248 LR: 0.00047678 Loss Fine: 0.395273 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:46:51,948 - trainer - INFO] - Train Epoch:[5/30] Step:[21000/25169] Loss: 0.492592 Loss_avg: 0.551315 LR: 0.00047633 Loss Fine: 0.492592 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:46:57,425 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[21000/25169] Word_acc: 0.870450 Word_acc_case_ins 0.870450 Edit_distance_acc: 0.950047
[2025-01-23 13:50:17,600 - trainer - INFO] - Train Epoch:[5/30] Step:[22000/25169] Loss: 0.641520 Loss_avg: 0.550892 LR: 0.00047587 Loss Fine: 0.641520 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:53:39,090 - trainer - INFO] - Train Epoch:[5/30] Step:[23000/25169] Loss: 0.518399 Loss_avg: 0.550655 LR: 0.00047541 Loss Fine: 0.518399 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:56:59,183 - trainer - INFO] - Train Epoch:[5/30] Step:[24000/25169] Loss: 0.508292 Loss_avg: 0.550589 LR: 0.00047495 Loss Fine: 0.508292 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 13:57:04,645 - trainer - INFO] - [Step Validation] Epoch:[5/30] Step:[24000/25169] Word_acc: 0.875669 Word_acc_case_ins 0.875669 Edit_distance_acc: 0.953829
[2025-01-23 13:57:04,960 - trainer - INFO] - Saving current best (at 5 epoch): model_best.pth Best word_acc: 0.875669
[2025-01-23 14:00:25,094 - trainer - INFO] - Train Epoch:[5/30] Step:[25000/25169] Loss: 0.438809 Loss_avg: 0.550401 LR: 0.00047448 Loss Fine: 0.438809 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:01:04,577 - trainer - INFO] - [Epoch End] Epoch:[5/30] Loss: 0.550379 LR: 0.00047440
 Validation result after 5 epoch: Word_acc: 0.872016 Word_acc_case_ins: 0.872016 Edit_distance_acc: 0.952036
[2025-01-23 14:01:06,407 - trainer - INFO] - Train Epoch:[6/30] Step:[1/25169] Loss: 0.440617 Loss_avg: 0.440617 LR: 0.00047440 Loss Fine: 0.440617 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:04:26,380 - trainer - INFO] - Train Epoch:[6/30] Step:[1000/25169] Loss: 0.530077 Loss_avg: 0.539052 LR: 0.00047393 Loss Fine: 0.530077 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:07:46,447 - trainer - INFO] - Train Epoch:[6/30] Step:[2000/25169] Loss: 0.497274 Loss_avg: 0.535457 LR: 0.00047345 Loss Fine: 0.497274 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:11:06,584 - trainer - INFO] - Train Epoch:[6/30] Step:[3000/25169] Loss: 0.383739 Loss_avg: 0.538880 LR: 0.00047297 Loss Fine: 0.383739 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:11:12,079 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[3000/25169] Word_acc: 0.873059 Word_acc_case_ins 0.873059 Edit_distance_acc: 0.950955
[2025-01-23 14:14:32,258 - trainer - INFO] - Train Epoch:[6/30] Step:[4000/25169] Loss: 0.700058 Loss_avg: 0.539158 LR: 0.00047249 Loss Fine: 0.700058 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:17:52,403 - trainer - INFO] - Train Epoch:[6/30] Step:[5000/25169] Loss: 0.372164 Loss_avg: 0.539703 LR: 0.00047200 Loss Fine: 0.372164 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:21:12,548 - trainer - INFO] - Train Epoch:[6/30] Step:[6000/25169] Loss: 0.573782 Loss_avg: 0.539338 LR: 0.00047151 Loss Fine: 0.573782 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:21:18,029 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[6000/25169] Word_acc: 0.877365 Word_acc_case_ins 0.877365 Edit_distance_acc: 0.952085
[2025-01-23 14:21:18,341 - trainer - INFO] - Saving current best (at 6 epoch): model_best.pth Best word_acc: 0.877365
[2025-01-23 14:24:38,581 - trainer - INFO] - Train Epoch:[6/30] Step:[7000/25169] Loss: 0.321039 Loss_avg: 0.539294 LR: 0.00047101 Loss Fine: 0.321039 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:27:58,868 - trainer - INFO] - Train Epoch:[6/30] Step:[8000/25169] Loss: 0.623741 Loss_avg: 0.539219 LR: 0.00047051 Loss Fine: 0.623741 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:31:19,047 - trainer - INFO] - Train Epoch:[6/30] Step:[9000/25169] Loss: 0.679733 Loss_avg: 0.539074 LR: 0.00047001 Loss Fine: 0.679733 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:31:24,470 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[9000/25169] Word_acc: 0.871885 Word_acc_case_ins 0.871885 Edit_distance_acc: 0.947812
[2025-01-23 14:34:44,587 - trainer - INFO] - Train Epoch:[6/30] Step:[10000/25169] Loss: 0.467640 Loss_avg: 0.538955 LR: 0.00046950 Loss Fine: 0.467640 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:38:04,677 - trainer - INFO] - Train Epoch:[6/30] Step:[11000/25169] Loss: 0.556570 Loss_avg: 0.538416 LR: 0.00046899 Loss Fine: 0.556570 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:41:24,771 - trainer - INFO] - Train Epoch:[6/30] Step:[12000/25169] Loss: 0.594846 Loss_avg: 0.538552 LR: 0.00046847 Loss Fine: 0.594846 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:41:30,219 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[12000/25169] Word_acc: 0.877495 Word_acc_case_ins 0.877495 Edit_distance_acc: 0.953067
[2025-01-23 14:41:30,560 - trainer - INFO] - Saving current best (at 6 epoch): model_best.pth Best word_acc: 0.877495
[2025-01-23 14:44:50,741 - trainer - INFO] - Train Epoch:[6/30] Step:[13000/25169] Loss: 0.583991 Loss_avg: 0.538758 LR: 0.00046795 Loss Fine: 0.583991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:48:10,924 - trainer - INFO] - Train Epoch:[6/30] Step:[14000/25169] Loss: 0.462786 Loss_avg: 0.538480 LR: 0.00046742 Loss Fine: 0.462786 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:51:31,079 - trainer - INFO] - Train Epoch:[6/30] Step:[15000/25169] Loss: 0.581678 Loss_avg: 0.537771 LR: 0.00046689 Loss Fine: 0.581678 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:51:36,466 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[15000/25169] Word_acc: 0.874364 Word_acc_case_ins 0.874364 Edit_distance_acc: 0.952331
[2025-01-23 14:54:58,044 - trainer - INFO] - Train Epoch:[6/30] Step:[16000/25169] Loss: 0.501597 Loss_avg: 0.537550 LR: 0.00046636 Loss Fine: 0.501597 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 14:58:18,237 - trainer - INFO] - Train Epoch:[6/30] Step:[17000/25169] Loss: 0.694233 Loss_avg: 0.537327 LR: 0.00046583 Loss Fine: 0.694233 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:01:38,455 - trainer - INFO] - Train Epoch:[6/30] Step:[18000/25169] Loss: 0.769973 Loss_avg: 0.537260 LR: 0.00046529 Loss Fine: 0.769973 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:01:43,862 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[18000/25169] Word_acc: 0.881800 Word_acc_case_ins 0.881800 Edit_distance_acc: 0.955302
[2025-01-23 15:01:44,192 - trainer - INFO] - Saving current best (at 6 epoch): model_best.pth Best word_acc: 0.881800
[2025-01-23 15:05:04,411 - trainer - INFO] - Train Epoch:[6/30] Step:[19000/25169] Loss: 0.613770 Loss_avg: 0.537609 LR: 0.00046474 Loss Fine: 0.613770 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:08:24,599 - trainer - INFO] - Train Epoch:[6/30] Step:[20000/25169] Loss: 0.450755 Loss_avg: 0.537448 LR: 0.00046419 Loss Fine: 0.450755 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:11:44,764 - trainer - INFO] - Train Epoch:[6/30] Step:[21000/25169] Loss: 0.511384 Loss_avg: 0.537239 LR: 0.00046364 Loss Fine: 0.511384 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:11:50,238 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[21000/25169] Word_acc: 0.874364 Word_acc_case_ins 0.874364 Edit_distance_acc: 0.950145
[2025-01-23 15:15:10,516 - trainer - INFO] - Train Epoch:[6/30] Step:[22000/25169] Loss: 0.672055 Loss_avg: 0.537036 LR: 0.00046308 Loss Fine: 0.672055 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:18:30,729 - trainer - INFO] - Train Epoch:[6/30] Step:[23000/25169] Loss: 0.418435 Loss_avg: 0.536515 LR: 0.00046252 Loss Fine: 0.418435 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:21:50,959 - trainer - INFO] - Train Epoch:[6/30] Step:[24000/25169] Loss: 0.448604 Loss_avg: 0.536165 LR: 0.00046196 Loss Fine: 0.448604 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:21:56,390 - trainer - INFO] - [Step Validation] Epoch:[6/30] Step:[24000/25169] Word_acc: 0.879843 Word_acc_case_ins 0.879843 Edit_distance_acc: 0.953829
[2025-01-23 15:25:16,555 - trainer - INFO] - Train Epoch:[6/30] Step:[25000/25169] Loss: 0.572025 Loss_avg: 0.535960 LR: 0.00046139 Loss Fine: 0.572025 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:25:56,106 - trainer - INFO] - [Epoch End] Epoch:[6/30] Loss: 0.535890 LR: 0.00046130
 Validation result after 6 epoch: Word_acc: 0.874494 Word_acc_case_ins: 0.874494 Edit_distance_acc: 0.952159
[2025-01-23 15:25:57,410 - trainer - INFO] - Train Epoch:[7/30] Step:[1/25169] Loss: 0.480455 Loss_avg: 0.480455 LR: 0.00046130 Loss Fine: 0.480455 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:29:17,465 - trainer - INFO] - Train Epoch:[7/30] Step:[1000/25169] Loss: 0.461865 Loss_avg: 0.525971 LR: 0.00046072 Loss Fine: 0.461865 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:32:37,675 - trainer - INFO] - Train Epoch:[7/30] Step:[2000/25169] Loss: 0.423308 Loss_avg: 0.526665 LR: 0.00046015 Loss Fine: 0.423308 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:35:57,936 - trainer - INFO] - Train Epoch:[7/30] Step:[3000/25169] Loss: 0.501172 Loss_avg: 0.525580 LR: 0.00045957 Loss Fine: 0.501172 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:36:03,427 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[3000/25169] Word_acc: 0.874494 Word_acc_case_ins 0.874494 Edit_distance_acc: 0.950734
[2025-01-23 15:39:23,566 - trainer - INFO] - Train Epoch:[7/30] Step:[4000/25169] Loss: 0.705129 Loss_avg: 0.525453 LR: 0.00045899 Loss Fine: 0.705129 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:42:43,732 - trainer - INFO] - Train Epoch:[7/30] Step:[5000/25169] Loss: 0.548786 Loss_avg: 0.526161 LR: 0.00045840 Loss Fine: 0.548786 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:46:03,865 - trainer - INFO] - Train Epoch:[7/30] Step:[6000/25169] Loss: 0.461973 Loss_avg: 0.526284 LR: 0.00045781 Loss Fine: 0.461973 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:46:09,306 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[6000/25169] Word_acc: 0.878800 Word_acc_case_ins 0.878800 Edit_distance_acc: 0.951299
[2025-01-23 15:49:29,468 - trainer - INFO] - Train Epoch:[7/30] Step:[7000/25169] Loss: 0.351748 Loss_avg: 0.526820 LR: 0.00045721 Loss Fine: 0.351748 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:52:49,600 - trainer - INFO] - Train Epoch:[7/30] Step:[8000/25169] Loss: 0.630726 Loss_avg: 0.526940 LR: 0.00045661 Loss Fine: 0.630726 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:56:09,800 - trainer - INFO] - Train Epoch:[7/30] Step:[9000/25169] Loss: 0.436504 Loss_avg: 0.527557 LR: 0.00045601 Loss Fine: 0.436504 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 15:56:15,311 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[9000/25169] Word_acc: 0.880626 Word_acc_case_ins 0.880626 Edit_distance_acc: 0.954222
[2025-01-23 15:59:35,439 - trainer - INFO] - Train Epoch:[7/30] Step:[10000/25169] Loss: 0.490134 Loss_avg: 0.527073 LR: 0.00045540 Loss Fine: 0.490134 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:02:55,566 - trainer - INFO] - Train Epoch:[7/30] Step:[11000/25169] Loss: 0.579087 Loss_avg: 0.526814 LR: 0.00045479 Loss Fine: 0.579087 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:06:17,370 - trainer - INFO] - Train Epoch:[7/30] Step:[12000/25169] Loss: 0.491520 Loss_avg: 0.526388 LR: 0.00045418 Loss Fine: 0.491520 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:06:22,833 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[12000/25169] Word_acc: 0.881148 Word_acc_case_ins 0.881148 Edit_distance_acc: 0.953288
[2025-01-23 16:09:43,010 - trainer - INFO] - Train Epoch:[7/30] Step:[13000/25169] Loss: 0.415114 Loss_avg: 0.525544 LR: 0.00045356 Loss Fine: 0.415114 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:13:03,243 - trainer - INFO] - Train Epoch:[7/30] Step:[14000/25169] Loss: 0.540117 Loss_avg: 0.525270 LR: 0.00045294 Loss Fine: 0.540117 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:16:23,422 - trainer - INFO] - Train Epoch:[7/30] Step:[15000/25169] Loss: 0.799543 Loss_avg: 0.525214 LR: 0.00045232 Loss Fine: 0.799543 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:16:28,855 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[15000/25169] Word_acc: 0.881670 Word_acc_case_ins 0.881670 Edit_distance_acc: 0.955229
[2025-01-23 16:19:49,103 - trainer - INFO] - Train Epoch:[7/30] Step:[16000/25169] Loss: 0.427463 Loss_avg: 0.525546 LR: 0.00045169 Loss Fine: 0.427463 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:23:09,339 - trainer - INFO] - Train Epoch:[7/30] Step:[17000/25169] Loss: 0.715569 Loss_avg: 0.525503 LR: 0.00045106 Loss Fine: 0.715569 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:26:29,478 - trainer - INFO] - Train Epoch:[7/30] Step:[18000/25169] Loss: 0.617966 Loss_avg: 0.525530 LR: 0.00045042 Loss Fine: 0.617966 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:26:34,942 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[18000/25169] Word_acc: 0.880365 Word_acc_case_ins 0.880365 Edit_distance_acc: 0.955130
[2025-01-23 16:29:55,047 - trainer - INFO] - Train Epoch:[7/30] Step:[19000/25169] Loss: 0.556491 Loss_avg: 0.525666 LR: 0.00044978 Loss Fine: 0.556491 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:33:15,105 - trainer - INFO] - Train Epoch:[7/30] Step:[20000/25169] Loss: 0.464980 Loss_avg: 0.525677 LR: 0.00044914 Loss Fine: 0.464980 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:36:35,191 - trainer - INFO] - Train Epoch:[7/30] Step:[21000/25169] Loss: 0.473432 Loss_avg: 0.525450 LR: 0.00044849 Loss Fine: 0.473432 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:36:40,640 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[21000/25169] Word_acc: 0.881800 Word_acc_case_ins 0.881800 Edit_distance_acc: 0.956236
[2025-01-23 16:36:40,959 - trainer - INFO] - Saving current best (at 7 epoch): model_best.pth Best word_acc: 0.881800
[2025-01-23 16:40:01,114 - trainer - INFO] - Train Epoch:[7/30] Step:[22000/25169] Loss: 0.531260 Loss_avg: 0.525344 LR: 0.00044784 Loss Fine: 0.531260 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:43:21,305 - trainer - INFO] - Train Epoch:[7/30] Step:[23000/25169] Loss: 0.637876 Loss_avg: 0.525154 LR: 0.00044719 Loss Fine: 0.637876 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:46:41,479 - trainer - INFO] - Train Epoch:[7/30] Step:[24000/25169] Loss: 0.530501 Loss_avg: 0.525031 LR: 0.00044653 Loss Fine: 0.530501 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:46:46,902 - trainer - INFO] - [Step Validation] Epoch:[7/30] Step:[24000/25169] Word_acc: 0.882714 Word_acc_case_ins 0.882714 Edit_distance_acc: 0.955278
[2025-01-23 16:46:47,227 - trainer - INFO] - Saving current best (at 7 epoch): model_best.pth Best word_acc: 0.882714
[2025-01-23 16:50:07,434 - trainer - INFO] - Train Epoch:[7/30] Step:[25000/25169] Loss: 0.718021 Loss_avg: 0.524907 LR: 0.00044587 Loss Fine: 0.718021 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:50:46,929 - trainer - INFO] - [Epoch End] Epoch:[7/30] Loss: 0.524858 LR: 0.00044576
 Validation result after 7 epoch: Word_acc: 0.880235 Word_acc_case_ins: 0.880235 Edit_distance_acc: 0.954713
[2025-01-23 16:50:48,724 - trainer - INFO] - Train Epoch:[8/30] Step:[1/25169] Loss: 0.886166 Loss_avg: 0.886166 LR: 0.00044576 Loss Fine: 0.886166 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:54:08,740 - trainer - INFO] - Train Epoch:[8/30] Step:[1000/25169] Loss: 0.728595 Loss_avg: 0.512136 LR: 0.00044509 Loss Fine: 0.728595 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 16:57:28,921 - trainer - INFO] - Train Epoch:[8/30] Step:[2000/25169] Loss: 0.364605 Loss_avg: 0.514364 LR: 0.00044442 Loss Fine: 0.364605 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:00:49,120 - trainer - INFO] - Train Epoch:[8/30] Step:[3000/25169] Loss: 0.424185 Loss_avg: 0.516394 LR: 0.00044375 Loss Fine: 0.424185 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:00:54,577 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[3000/25169] Word_acc: 0.885584 Word_acc_case_ins 0.885584 Edit_distance_acc: 0.957169
[2025-01-23 17:00:54,892 - trainer - INFO] - Saving current best (at 8 epoch): model_best.pth Best word_acc: 0.885584
[2025-01-23 17:04:15,002 - trainer - INFO] - Train Epoch:[8/30] Step:[4000/25169] Loss: 0.656978 Loss_avg: 0.515795 LR: 0.00044307 Loss Fine: 0.656978 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:07:35,185 - trainer - INFO] - Train Epoch:[8/30] Step:[5000/25169] Loss: 0.623586 Loss_avg: 0.515429 LR: 0.00044239 Loss Fine: 0.623586 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:10:55,372 - trainer - INFO] - Train Epoch:[8/30] Step:[6000/25169] Loss: 0.476024 Loss_avg: 0.516361 LR: 0.00044171 Loss Fine: 0.476024 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:11:00,822 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[6000/25169] Word_acc: 0.880496 Word_acc_case_ins 0.880496 Edit_distance_acc: 0.955523
[2025-01-23 17:14:20,957 - trainer - INFO] - Train Epoch:[8/30] Step:[7000/25169] Loss: 0.436109 Loss_avg: 0.515879 LR: 0.00044102 Loss Fine: 0.436109 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:17:41,119 - trainer - INFO] - Train Epoch:[8/30] Step:[8000/25169] Loss: 0.539910 Loss_avg: 0.515674 LR: 0.00044033 Loss Fine: 0.539910 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:21:01,224 - trainer - INFO] - Train Epoch:[8/30] Step:[9000/25169] Loss: 0.485362 Loss_avg: 0.515695 LR: 0.00043964 Loss Fine: 0.485362 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:21:06,716 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[9000/25169] Word_acc: 0.881670 Word_acc_case_ins 0.881670 Edit_distance_acc: 0.953829
[2025-01-23 17:24:28,783 - trainer - INFO] - Train Epoch:[8/30] Step:[10000/25169] Loss: 0.735144 Loss_avg: 0.515483 LR: 0.00043894 Loss Fine: 0.735144 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:27:48,969 - trainer - INFO] - Train Epoch:[8/30] Step:[11000/25169] Loss: 0.638848 Loss_avg: 0.515464 LR: 0.00043824 Loss Fine: 0.638848 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:31:09,109 - trainer - INFO] - Train Epoch:[8/30] Step:[12000/25169] Loss: 0.602329 Loss_avg: 0.516042 LR: 0.00043754 Loss Fine: 0.602329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:31:14,574 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[12000/25169] Word_acc: 0.880626 Word_acc_case_ins 0.880626 Edit_distance_acc: 0.954713
[2025-01-23 17:34:34,745 - trainer - INFO] - Train Epoch:[8/30] Step:[13000/25169] Loss: 0.529130 Loss_avg: 0.515823 LR: 0.00043683 Loss Fine: 0.529130 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:37:54,956 - trainer - INFO] - Train Epoch:[8/30] Step:[14000/25169] Loss: 0.597832 Loss_avg: 0.515945 LR: 0.00043612 Loss Fine: 0.597832 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:41:15,150 - trainer - INFO] - Train Epoch:[8/30] Step:[15000/25169] Loss: 0.400580 Loss_avg: 0.515627 LR: 0.00043541 Loss Fine: 0.400580 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:41:20,619 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[15000/25169] Word_acc: 0.881670 Word_acc_case_ins 0.881670 Edit_distance_acc: 0.956506
[2025-01-23 17:44:40,773 - trainer - INFO] - Train Epoch:[8/30] Step:[16000/25169] Loss: 0.437027 Loss_avg: 0.515510 LR: 0.00043469 Loss Fine: 0.437027 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:48:00,896 - trainer - INFO] - Train Epoch:[8/30] Step:[17000/25169] Loss: 0.696998 Loss_avg: 0.515177 LR: 0.00043397 Loss Fine: 0.696998 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:51:21,080 - trainer - INFO] - Train Epoch:[8/30] Step:[18000/25169] Loss: 0.583232 Loss_avg: 0.515031 LR: 0.00043325 Loss Fine: 0.583232 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:51:26,576 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[18000/25169] Word_acc: 0.886367 Word_acc_case_ins 0.886367 Edit_distance_acc: 0.957758
[2025-01-23 17:51:26,898 - trainer - INFO] - Saving current best (at 8 epoch): model_best.pth Best word_acc: 0.886367
[2025-01-23 17:54:47,124 - trainer - INFO] - Train Epoch:[8/30] Step:[19000/25169] Loss: 0.651755 Loss_avg: 0.515112 LR: 0.00043252 Loss Fine: 0.651755 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 17:58:07,315 - trainer - INFO] - Train Epoch:[8/30] Step:[20000/25169] Loss: 0.481607 Loss_avg: 0.514932 LR: 0.00043179 Loss Fine: 0.481607 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:01:27,502 - trainer - INFO] - Train Epoch:[8/30] Step:[21000/25169] Loss: 0.263709 Loss_avg: 0.514622 LR: 0.00043105 Loss Fine: 0.263709 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:01:32,969 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[21000/25169] Word_acc: 0.884801 Word_acc_case_ins 0.884801 Edit_distance_acc: 0.956776
[2025-01-23 18:04:53,126 - trainer - INFO] - Train Epoch:[8/30] Step:[22000/25169] Loss: 0.622329 Loss_avg: 0.514447 LR: 0.00043032 Loss Fine: 0.622329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:08:13,215 - trainer - INFO] - Train Epoch:[8/30] Step:[23000/25169] Loss: 0.403646 Loss_avg: 0.514347 LR: 0.00042958 Loss Fine: 0.403646 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:11:33,442 - trainer - INFO] - Train Epoch:[8/30] Step:[24000/25169] Loss: 0.667911 Loss_avg: 0.514200 LR: 0.00042883 Loss Fine: 0.667911 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:11:38,927 - trainer - INFO] - [Step Validation] Epoch:[8/30] Step:[24000/25169] Word_acc: 0.874755 Word_acc_case_ins 0.874755 Edit_distance_acc: 0.953976
[2025-01-23 18:14:59,160 - trainer - INFO] - Train Epoch:[8/30] Step:[25000/25169] Loss: 0.563776 Loss_avg: 0.514436 LR: 0.00042809 Loss Fine: 0.563776 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:15:38,590 - trainer - INFO] - [Epoch End] Epoch:[8/30] Loss: 0.514417 LR: 0.00042796
 Validation result after 8 epoch: Word_acc: 0.882975 Word_acc_case_ins: 0.882975 Edit_distance_acc: 0.956162
[2025-01-23 18:15:40,125 - trainer - INFO] - Train Epoch:[9/30] Step:[1/25169] Loss: 0.560791 Loss_avg: 0.560791 LR: 0.00042796 Loss Fine: 0.560791 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:19:00,166 - trainer - INFO] - Train Epoch:[9/30] Step:[1000/25169] Loss: 0.515023 Loss_avg: 0.506041 LR: 0.00042721 Loss Fine: 0.515023 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:22:20,295 - trainer - INFO] - Train Epoch:[9/30] Step:[2000/25169] Loss: 0.682456 Loss_avg: 0.503939 LR: 0.00042645 Loss Fine: 0.682456 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:25:40,367 - trainer - INFO] - Train Epoch:[9/30] Step:[3000/25169] Loss: 0.402695 Loss_avg: 0.504650 LR: 0.00042570 Loss Fine: 0.402695 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:25:45,829 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[3000/25169] Word_acc: 0.884671 Word_acc_case_ins 0.884671 Edit_distance_acc: 0.956162
[2025-01-23 18:29:05,970 - trainer - INFO] - Train Epoch:[9/30] Step:[4000/25169] Loss: 0.514399 Loss_avg: 0.504319 LR: 0.00042494 Loss Fine: 0.514399 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:32:26,109 - trainer - INFO] - Train Epoch:[9/30] Step:[5000/25169] Loss: 0.579457 Loss_avg: 0.505762 LR: 0.00042417 Loss Fine: 0.579457 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:35:46,280 - trainer - INFO] - Train Epoch:[9/30] Step:[6000/25169] Loss: 0.624730 Loss_avg: 0.505442 LR: 0.00042341 Loss Fine: 0.624730 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:35:51,746 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[6000/25169] Word_acc: 0.882714 Word_acc_case_ins 0.882714 Edit_distance_acc: 0.954983
[2025-01-23 18:39:11,928 - trainer - INFO] - Train Epoch:[9/30] Step:[7000/25169] Loss: 0.535333 Loss_avg: 0.505345 LR: 0.00042264 Loss Fine: 0.535333 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:42:32,063 - trainer - INFO] - Train Epoch:[9/30] Step:[8000/25169] Loss: 0.539415 Loss_avg: 0.505093 LR: 0.00042186 Loss Fine: 0.539415 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:45:52,296 - trainer - INFO] - Train Epoch:[9/30] Step:[9000/25169] Loss: 0.700329 Loss_avg: 0.505137 LR: 0.00042109 Loss Fine: 0.700329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:45:57,743 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[9000/25169] Word_acc: 0.883235 Word_acc_case_ins 0.883235 Edit_distance_acc: 0.957169
[2025-01-23 18:49:17,941 - trainer - INFO] - Train Epoch:[9/30] Step:[10000/25169] Loss: 0.555774 Loss_avg: 0.504969 LR: 0.00042031 Loss Fine: 0.555774 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:52:38,105 - trainer - INFO] - Train Epoch:[9/30] Step:[11000/25169] Loss: 0.593084 Loss_avg: 0.504821 LR: 0.00041952 Loss Fine: 0.593084 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:56:00,281 - trainer - INFO] - Train Epoch:[9/30] Step:[12000/25169] Loss: 0.622329 Loss_avg: 0.504824 LR: 0.00041874 Loss Fine: 0.622329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 18:56:05,734 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[12000/25169] Word_acc: 0.884671 Word_acc_case_ins 0.884671 Edit_distance_acc: 0.957095
[2025-01-23 18:59:25,836 - trainer - INFO] - Train Epoch:[9/30] Step:[13000/25169] Loss: 0.522201 Loss_avg: 0.504577 LR: 0.00041795 Loss Fine: 0.522201 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:02:46,021 - trainer - INFO] - Train Epoch:[9/30] Step:[14000/25169] Loss: 0.623213 Loss_avg: 0.504677 LR: 0.00041716 Loss Fine: 0.623213 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:06:06,106 - trainer - INFO] - Train Epoch:[9/30] Step:[15000/25169] Loss: 0.447034 Loss_avg: 0.504479 LR: 0.00041636 Loss Fine: 0.447034 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:06:11,628 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[15000/25169] Word_acc: 0.889628 Word_acc_case_ins 0.889628 Edit_distance_acc: 0.956579
[2025-01-23 19:06:11,927 - trainer - INFO] - Saving current best (at 9 epoch): model_best.pth Best word_acc: 0.889628
[2025-01-23 19:09:32,056 - trainer - INFO] - Train Epoch:[9/30] Step:[16000/25169] Loss: 0.497519 Loss_avg: 0.504420 LR: 0.00041556 Loss Fine: 0.497519 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:12:52,184 - trainer - INFO] - Train Epoch:[9/30] Step:[17000/25169] Loss: 0.592445 Loss_avg: 0.504095 LR: 0.00041476 Loss Fine: 0.592445 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:16:12,345 - trainer - INFO] - Train Epoch:[9/30] Step:[18000/25169] Loss: 0.715914 Loss_avg: 0.503823 LR: 0.00041396 Loss Fine: 0.715914 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:16:17,803 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[18000/25169] Word_acc: 0.888454 Word_acc_case_ins 0.888454 Edit_distance_acc: 0.957660
[2025-01-23 19:19:37,993 - trainer - INFO] - Train Epoch:[9/30] Step:[19000/25169] Loss: 0.377479 Loss_avg: 0.503503 LR: 0.00041315 Loss Fine: 0.377479 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:22:58,167 - trainer - INFO] - Train Epoch:[9/30] Step:[20000/25169] Loss: 0.594613 Loss_avg: 0.503661 LR: 0.00041234 Loss Fine: 0.594613 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:26:18,285 - trainer - INFO] - Train Epoch:[9/30] Step:[21000/25169] Loss: 0.300428 Loss_avg: 0.503502 LR: 0.00041153 Loss Fine: 0.300428 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:26:23,770 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[21000/25169] Word_acc: 0.885584 Word_acc_case_ins 0.885584 Edit_distance_acc: 0.954909
[2025-01-23 19:29:44,019 - trainer - INFO] - Train Epoch:[9/30] Step:[22000/25169] Loss: 0.605807 Loss_avg: 0.503408 LR: 0.00041072 Loss Fine: 0.605807 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:33:04,272 - trainer - INFO] - Train Epoch:[9/30] Step:[23000/25169] Loss: 0.589639 Loss_avg: 0.503446 LR: 0.00040990 Loss Fine: 0.589639 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:36:24,492 - trainer - INFO] - Train Epoch:[9/30] Step:[24000/25169] Loss: 0.475572 Loss_avg: 0.503516 LR: 0.00040907 Loss Fine: 0.475572 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:36:30,013 - trainer - INFO] - [Step Validation] Epoch:[9/30] Step:[24000/25169] Word_acc: 0.887149 Word_acc_case_ins 0.887149 Edit_distance_acc: 0.957095
[2025-01-23 19:39:50,159 - trainer - INFO] - Train Epoch:[9/30] Step:[25000/25169] Loss: 0.592388 Loss_avg: 0.503570 LR: 0.00040825 Loss Fine: 0.592388 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:40:29,615 - trainer - INFO] - [Epoch End] Epoch:[9/30] Loss: 0.503522 LR: 0.00040811
 Validation result after 9 epoch: Word_acc: 0.888584 Word_acc_case_ins: 0.888584 Edit_distance_acc: 0.956923
[2025-01-23 19:40:31,060 - trainer - INFO] - Train Epoch:[10/30] Step:[1/25169] Loss: 0.392127 Loss_avg: 0.392127 LR: 0.00040811 Loss Fine: 0.392127 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:43:51,027 - trainer - INFO] - Train Epoch:[10/30] Step:[1000/25169] Loss: 0.496474 Loss_avg: 0.496104 LR: 0.00040728 Loss Fine: 0.496474 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:47:11,055 - trainer - INFO] - Train Epoch:[10/30] Step:[2000/25169] Loss: 0.634123 Loss_avg: 0.496552 LR: 0.00040645 Loss Fine: 0.634123 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:50:31,180 - trainer - INFO] - Train Epoch:[10/30] Step:[3000/25169] Loss: 0.780937 Loss_avg: 0.498184 LR: 0.00040562 Loss Fine: 0.780937 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:50:36,640 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[3000/25169] Word_acc: 0.887671 Word_acc_case_ins 0.887671 Edit_distance_acc: 0.957562
[2025-01-23 19:53:56,799 - trainer - INFO] - Train Epoch:[10/30] Step:[4000/25169] Loss: 0.410766 Loss_avg: 0.497755 LR: 0.00040478 Loss Fine: 0.410766 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 19:57:16,893 - trainer - INFO] - Train Epoch:[10/30] Step:[5000/25169] Loss: 0.298934 Loss_avg: 0.496977 LR: 0.00040394 Loss Fine: 0.298934 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:00:36,996 - trainer - INFO] - Train Epoch:[10/30] Step:[6000/25169] Loss: 0.430536 Loss_avg: 0.496036 LR: 0.00040310 Loss Fine: 0.430536 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:00:42,463 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[6000/25169] Word_acc: 0.887280 Word_acc_case_ins 0.887280 Edit_distance_acc: 0.957218
[2025-01-23 20:04:02,536 - trainer - INFO] - Train Epoch:[10/30] Step:[7000/25169] Loss: 0.546293 Loss_avg: 0.496611 LR: 0.00040226 Loss Fine: 0.546293 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:07:22,614 - trainer - INFO] - Train Epoch:[10/30] Step:[8000/25169] Loss: 0.389345 Loss_avg: 0.496521 LR: 0.00040141 Loss Fine: 0.389345 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:10:42,652 - trainer - INFO] - Train Epoch:[10/30] Step:[9000/25169] Loss: 0.540700 Loss_avg: 0.496251 LR: 0.00040056 Loss Fine: 0.540700 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:10:48,114 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[9000/25169] Word_acc: 0.878408 Word_acc_case_ins 0.878408 Edit_distance_acc: 0.954246
[2025-01-23 20:14:08,234 - trainer - INFO] - Train Epoch:[10/30] Step:[10000/25169] Loss: 0.419852 Loss_avg: 0.496054 LR: 0.00039971 Loss Fine: 0.419852 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:17:28,357 - trainer - INFO] - Train Epoch:[10/30] Step:[11000/25169] Loss: 0.551948 Loss_avg: 0.495753 LR: 0.00039885 Loss Fine: 0.551948 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:20:48,501 - trainer - INFO] - Train Epoch:[10/30] Step:[12000/25169] Loss: 0.506032 Loss_avg: 0.495676 LR: 0.00039799 Loss Fine: 0.506032 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:20:53,973 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[12000/25169] Word_acc: 0.884801 Word_acc_case_ins 0.884801 Edit_distance_acc: 0.957513
[2025-01-23 20:24:14,132 - trainer - INFO] - Train Epoch:[10/30] Step:[13000/25169] Loss: 0.404661 Loss_avg: 0.495539 LR: 0.00039713 Loss Fine: 0.404661 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:27:34,195 - trainer - INFO] - Train Epoch:[10/30] Step:[14000/25169] Loss: 0.629319 Loss_avg: 0.495548 LR: 0.00039627 Loss Fine: 0.629319 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:30:54,345 - trainer - INFO] - Train Epoch:[10/30] Step:[15000/25169] Loss: 0.578502 Loss_avg: 0.495191 LR: 0.00039540 Loss Fine: 0.578502 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:30:59,850 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[15000/25169] Word_acc: 0.884279 Word_acc_case_ins 0.884279 Edit_distance_acc: 0.954345
[2025-01-23 20:34:19,958 - trainer - INFO] - Train Epoch:[10/30] Step:[16000/25169] Loss: 0.594699 Loss_avg: 0.495210 LR: 0.00039453 Loss Fine: 0.594699 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:37:40,093 - trainer - INFO] - Train Epoch:[10/30] Step:[17000/25169] Loss: 0.495900 Loss_avg: 0.495011 LR: 0.00039366 Loss Fine: 0.495900 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:41:02,547 - trainer - INFO] - Train Epoch:[10/30] Step:[18000/25169] Loss: 0.562581 Loss_avg: 0.494632 LR: 0.00039278 Loss Fine: 0.562581 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:41:08,028 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[18000/25169] Word_acc: 0.887149 Word_acc_case_ins 0.887149 Edit_distance_acc: 0.959576
[2025-01-23 20:44:28,088 - trainer - INFO] - Train Epoch:[10/30] Step:[19000/25169] Loss: 0.437217 Loss_avg: 0.494523 LR: 0.00039191 Loss Fine: 0.437217 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:47:48,233 - trainer - INFO] - Train Epoch:[10/30] Step:[20000/25169] Loss: 0.339588 Loss_avg: 0.494134 LR: 0.00039103 Loss Fine: 0.339588 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:51:08,378 - trainer - INFO] - Train Epoch:[10/30] Step:[21000/25169] Loss: 0.471621 Loss_avg: 0.494250 LR: 0.00039015 Loss Fine: 0.471621 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:51:13,868 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[21000/25169] Word_acc: 0.891063 Word_acc_case_ins 0.891063 Edit_distance_acc: 0.959919
[2025-01-23 20:51:14,184 - trainer - INFO] - Saving current best (at 10 epoch): model_best.pth Best word_acc: 0.891063
[2025-01-23 20:54:34,368 - trainer - INFO] - Train Epoch:[10/30] Step:[22000/25169] Loss: 0.287698 Loss_avg: 0.493969 LR: 0.00038926 Loss Fine: 0.287698 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 20:57:54,551 - trainer - INFO] - Train Epoch:[10/30] Step:[23000/25169] Loss: 0.342976 Loss_avg: 0.493903 LR: 0.00038837 Loss Fine: 0.342976 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:01:14,732 - trainer - INFO] - Train Epoch:[10/30] Step:[24000/25169] Loss: 0.423789 Loss_avg: 0.493808 LR: 0.00038748 Loss Fine: 0.423789 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:01:20,178 - trainer - INFO] - [Step Validation] Epoch:[10/30] Step:[24000/25169] Word_acc: 0.891716 Word_acc_case_ins 0.891716 Edit_distance_acc: 0.959919
[2025-01-23 21:01:20,484 - trainer - INFO] - Saving current best (at 10 epoch): model_best.pth Best word_acc: 0.891716
[2025-01-23 21:04:40,680 - trainer - INFO] - Train Epoch:[10/30] Step:[25000/25169] Loss: 0.528036 Loss_avg: 0.493887 LR: 0.00038659 Loss Fine: 0.528036 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:05:20,242 - trainer - INFO] - [Epoch End] Epoch:[10/30] Loss: 0.493816 LR: 0.00038644
 Validation result after 10 epoch: Word_acc: 0.886758 Word_acc_case_ins: 0.886758 Edit_distance_acc: 0.956162
[2025-01-23 21:05:21,888 - trainer - INFO] - Train Epoch:[11/30] Step:[1/25169] Loss: 0.392396 Loss_avg: 0.392396 LR: 0.00038644 Loss Fine: 0.392396 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:08:41,923 - trainer - INFO] - Train Epoch:[11/30] Step:[1000/25169] Loss: 0.452363 Loss_avg: 0.484484 LR: 0.00038555 Loss Fine: 0.452363 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:12:02,092 - trainer - INFO] - Train Epoch:[11/30] Step:[2000/25169] Loss: 0.409800 Loss_avg: 0.485162 LR: 0.00038465 Loss Fine: 0.409800 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:15:22,200 - trainer - INFO] - Train Epoch:[11/30] Step:[3000/25169] Loss: 0.505075 Loss_avg: 0.484962 LR: 0.00038375 Loss Fine: 0.505075 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:15:27,662 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[3000/25169] Word_acc: 0.892890 Word_acc_case_ins 0.892890 Edit_distance_acc: 0.959428
[2025-01-23 21:15:27,978 - trainer - INFO] - Saving current best (at 11 epoch): model_best.pth Best word_acc: 0.892890
[2025-01-23 21:18:48,082 - trainer - INFO] - Train Epoch:[11/30] Step:[4000/25169] Loss: 0.546380 Loss_avg: 0.485026 LR: 0.00038285 Loss Fine: 0.546380 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:22:08,266 - trainer - INFO] - Train Epoch:[11/30] Step:[5000/25169] Loss: 0.739878 Loss_avg: 0.486688 LR: 0.00038194 Loss Fine: 0.739878 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:25:28,478 - trainer - INFO] - Train Epoch:[11/30] Step:[6000/25169] Loss: 0.664094 Loss_avg: 0.487133 LR: 0.00038103 Loss Fine: 0.664094 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:25:33,956 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[6000/25169] Word_acc: 0.889759 Word_acc_case_ins 0.889759 Edit_distance_acc: 0.958102
[2025-01-23 21:28:54,085 - trainer - INFO] - Train Epoch:[11/30] Step:[7000/25169] Loss: 0.323658 Loss_avg: 0.486537 LR: 0.00038012 Loss Fine: 0.323658 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:32:14,164 - trainer - INFO] - Train Epoch:[11/30] Step:[8000/25169] Loss: 0.390490 Loss_avg: 0.486340 LR: 0.00037921 Loss Fine: 0.390490 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:35:34,301 - trainer - INFO] - Train Epoch:[11/30] Step:[9000/25169] Loss: 0.435518 Loss_avg: 0.486378 LR: 0.00037830 Loss Fine: 0.435518 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:35:39,749 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[9000/25169] Word_acc: 0.894716 Word_acc_case_ins 0.894716 Edit_distance_acc: 0.960730
[2025-01-23 21:35:40,062 - trainer - INFO] - Saving current best (at 11 epoch): model_best.pth Best word_acc: 0.894716
[2025-01-23 21:39:00,219 - trainer - INFO] - Train Epoch:[11/30] Step:[10000/25169] Loss: 0.380466 Loss_avg: 0.486042 LR: 0.00037738 Loss Fine: 0.380466 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:42:20,432 - trainer - INFO] - Train Epoch:[11/30] Step:[11000/25169] Loss: 0.455040 Loss_avg: 0.486263 LR: 0.00037646 Loss Fine: 0.455040 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:45:40,657 - trainer - INFO] - Train Epoch:[11/30] Step:[12000/25169] Loss: 0.390531 Loss_avg: 0.485657 LR: 0.00037554 Loss Fine: 0.390531 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:45:46,144 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[12000/25169] Word_acc: 0.892629 Word_acc_case_ins 0.892629 Edit_distance_acc: 0.959379
[2025-01-23 21:49:06,328 - trainer - INFO] - Train Epoch:[11/30] Step:[13000/25169] Loss: 0.609012 Loss_avg: 0.485529 LR: 0.00037462 Loss Fine: 0.609012 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:52:26,537 - trainer - INFO] - Train Epoch:[11/30] Step:[14000/25169] Loss: 0.392750 Loss_avg: 0.485941 LR: 0.00037369 Loss Fine: 0.392750 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:55:46,650 - trainer - INFO] - Train Epoch:[11/30] Step:[15000/25169] Loss: 0.439683 Loss_avg: 0.485571 LR: 0.00037276 Loss Fine: 0.439683 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 21:55:52,133 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[15000/25169] Word_acc: 0.890280 Word_acc_case_ins 0.890280 Edit_distance_acc: 0.958127
[2025-01-23 21:59:12,324 - trainer - INFO] - Train Epoch:[11/30] Step:[16000/25169] Loss: 0.602693 Loss_avg: 0.485559 LR: 0.00037183 Loss Fine: 0.602693 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:02:32,512 - trainer - INFO] - Train Epoch:[11/30] Step:[17000/25169] Loss: 0.512305 Loss_avg: 0.485121 LR: 0.00037090 Loss Fine: 0.512305 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:05:52,720 - trainer - INFO] - Train Epoch:[11/30] Step:[18000/25169] Loss: 0.469021 Loss_avg: 0.484983 LR: 0.00036996 Loss Fine: 0.469021 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:05:58,234 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[18000/25169] Word_acc: 0.887019 Word_acc_case_ins 0.887019 Edit_distance_acc: 0.956113
[2025-01-23 22:09:18,387 - trainer - INFO] - Train Epoch:[11/30] Step:[19000/25169] Loss: 0.410577 Loss_avg: 0.485118 LR: 0.00036903 Loss Fine: 0.410577 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:12:38,468 - trainer - INFO] - Train Epoch:[11/30] Step:[20000/25169] Loss: 0.478013 Loss_avg: 0.484822 LR: 0.00036809 Loss Fine: 0.478013 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:15:58,595 - trainer - INFO] - Train Epoch:[11/30] Step:[21000/25169] Loss: 0.365447 Loss_avg: 0.484596 LR: 0.00036715 Loss Fine: 0.365447 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:16:04,048 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[21000/25169] Word_acc: 0.896021 Word_acc_case_ins 0.896021 Edit_distance_acc: 0.959772
[2025-01-23 22:16:04,347 - trainer - INFO] - Saving current best (at 11 epoch): model_best.pth Best word_acc: 0.896021
[2025-01-23 22:19:24,528 - trainer - INFO] - Train Epoch:[11/30] Step:[22000/25169] Loss: 0.409474 Loss_avg: 0.484489 LR: 0.00036620 Loss Fine: 0.409474 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:22:44,699 - trainer - INFO] - Train Epoch:[11/30] Step:[23000/25169] Loss: 0.845927 Loss_avg: 0.484463 LR: 0.00036526 Loss Fine: 0.845927 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:26:04,793 - trainer - INFO] - Train Epoch:[11/30] Step:[24000/25169] Loss: 0.566112 Loss_avg: 0.484505 LR: 0.00036431 Loss Fine: 0.566112 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:26:10,265 - trainer - INFO] - [Step Validation] Epoch:[11/30] Step:[24000/25169] Word_acc: 0.888063 Word_acc_case_ins 0.888063 Edit_distance_acc: 0.958249
[2025-01-23 22:29:30,444 - trainer - INFO] - Train Epoch:[11/30] Step:[25000/25169] Loss: 0.353696 Loss_avg: 0.484288 LR: 0.00036336 Loss Fine: 0.353696 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:30:09,950 - trainer - INFO] - [Epoch End] Epoch:[11/30] Loss: 0.484230 LR: 0.00036320
 Validation result after 11 epoch: Word_acc: 0.891324 Word_acc_case_ins: 0.891324 Edit_distance_acc: 0.957414
[2025-01-23 22:30:11,503 - trainer - INFO] - Train Epoch:[12/30] Step:[1/25169] Loss: 0.613975 Loss_avg: 0.613975 LR: 0.00036320 Loss Fine: 0.613975 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:33:31,585 - trainer - INFO] - Train Epoch:[12/30] Step:[1000/25169] Loss: 0.535898 Loss_avg: 0.473275 LR: 0.00036225 Loss Fine: 0.535898 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:36:51,756 - trainer - INFO] - Train Epoch:[12/30] Step:[2000/25169] Loss: 0.615206 Loss_avg: 0.472485 LR: 0.00036129 Loss Fine: 0.615206 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:40:14,677 - trainer - INFO] - Train Epoch:[12/30] Step:[3000/25169] Loss: 0.314804 Loss_avg: 0.472639 LR: 0.00036034 Loss Fine: 0.314804 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:40:20,131 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[3000/25169] Word_acc: 0.896151 Word_acc_case_ins 0.896151 Edit_distance_acc: 0.961147
[2025-01-23 22:40:20,438 - trainer - INFO] - Saving current best (at 12 epoch): model_best.pth Best word_acc: 0.896151
[2025-01-23 22:43:40,627 - trainer - INFO] - Train Epoch:[12/30] Step:[4000/25169] Loss: 0.525050 Loss_avg: 0.473324 LR: 0.00035938 Loss Fine: 0.525050 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:47:00,846 - trainer - INFO] - Train Epoch:[12/30] Step:[5000/25169] Loss: 0.301044 Loss_avg: 0.474531 LR: 0.00035842 Loss Fine: 0.301044 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:50:21,013 - trainer - INFO] - Train Epoch:[12/30] Step:[6000/25169] Loss: 0.569138 Loss_avg: 0.475570 LR: 0.00035745 Loss Fine: 0.569138 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:50:26,480 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[6000/25169] Word_acc: 0.888845 Word_acc_case_ins 0.888845 Edit_distance_acc: 0.959428
[2025-01-23 22:53:46,668 - trainer - INFO] - Train Epoch:[12/30] Step:[7000/25169] Loss: 0.557229 Loss_avg: 0.476357 LR: 0.00035649 Loss Fine: 0.557229 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 22:57:06,748 - trainer - INFO] - Train Epoch:[12/30] Step:[8000/25169] Loss: 0.562160 Loss_avg: 0.475843 LR: 0.00035552 Loss Fine: 0.562160 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:00:26,915 - trainer - INFO] - Train Epoch:[12/30] Step:[9000/25169] Loss: 0.346024 Loss_avg: 0.475764 LR: 0.00035456 Loss Fine: 0.346024 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:00:32,414 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[9000/25169] Word_acc: 0.897978 Word_acc_case_ins 0.897978 Edit_distance_acc: 0.961663
[2025-01-23 23:00:32,734 - trainer - INFO] - Saving current best (at 12 epoch): model_best.pth Best word_acc: 0.897978
[2025-01-23 23:03:52,913 - trainer - INFO] - Train Epoch:[12/30] Step:[10000/25169] Loss: 0.522732 Loss_avg: 0.475479 LR: 0.00035359 Loss Fine: 0.522732 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:07:13,071 - trainer - INFO] - Train Epoch:[12/30] Step:[11000/25169] Loss: 0.528037 Loss_avg: 0.475393 LR: 0.00035261 Loss Fine: 0.528037 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:10:33,151 - trainer - INFO] - Train Epoch:[12/30] Step:[12000/25169] Loss: 0.413494 Loss_avg: 0.475241 LR: 0.00035164 Loss Fine: 0.413494 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:10:38,594 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[12000/25169] Word_acc: 0.893020 Word_acc_case_ins 0.893020 Edit_distance_acc: 0.960337
[2025-01-23 23:13:58,843 - trainer - INFO] - Train Epoch:[12/30] Step:[13000/25169] Loss: 0.385325 Loss_avg: 0.474992 LR: 0.00035066 Loss Fine: 0.385325 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:17:19,108 - trainer - INFO] - Train Epoch:[12/30] Step:[14000/25169] Loss: 0.384921 Loss_avg: 0.475670 LR: 0.00034969 Loss Fine: 0.384921 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:20:39,305 - trainer - INFO] - Train Epoch:[12/30] Step:[15000/25169] Loss: 0.350503 Loss_avg: 0.475544 LR: 0.00034871 Loss Fine: 0.350503 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:20:44,770 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[15000/25169] Word_acc: 0.897978 Word_acc_case_ins 0.897978 Edit_distance_acc: 0.962400
[2025-01-23 23:20:45,103 - trainer - INFO] - Saving current best (at 12 epoch): model_best.pth Best word_acc: 0.897978
[2025-01-23 23:24:05,210 - trainer - INFO] - Train Epoch:[12/30] Step:[16000/25169] Loss: 0.297124 Loss_avg: 0.475192 LR: 0.00034773 Loss Fine: 0.297124 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:27:25,325 - trainer - INFO] - Train Epoch:[12/30] Step:[17000/25169] Loss: 0.572905 Loss_avg: 0.475140 LR: 0.00034674 Loss Fine: 0.572905 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:30:45,534 - trainer - INFO] - Train Epoch:[12/30] Step:[18000/25169] Loss: 0.423972 Loss_avg: 0.474945 LR: 0.00034576 Loss Fine: 0.423972 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:30:51,020 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[18000/25169] Word_acc: 0.890802 Word_acc_case_ins 0.890802 Edit_distance_acc: 0.958127
[2025-01-23 23:34:11,221 - trainer - INFO] - Train Epoch:[12/30] Step:[19000/25169] Loss: 0.478853 Loss_avg: 0.474549 LR: 0.00034477 Loss Fine: 0.478853 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:37:31,333 - trainer - INFO] - Train Epoch:[12/30] Step:[20000/25169] Loss: 0.399688 Loss_avg: 0.474367 LR: 0.00034379 Loss Fine: 0.399688 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:40:51,460 - trainer - INFO] - Train Epoch:[12/30] Step:[21000/25169] Loss: 0.651737 Loss_avg: 0.474458 LR: 0.00034280 Loss Fine: 0.651737 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:40:56,919 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[21000/25169] Word_acc: 0.895108 Word_acc_case_ins 0.895108 Edit_distance_acc: 0.960312
[2025-01-23 23:44:17,091 - trainer - INFO] - Train Epoch:[12/30] Step:[22000/25169] Loss: 0.580246 Loss_avg: 0.474153 LR: 0.00034180 Loss Fine: 0.580246 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:47:37,409 - trainer - INFO] - Train Epoch:[12/30] Step:[23000/25169] Loss: 0.307556 Loss_avg: 0.474108 LR: 0.00034081 Loss Fine: 0.307556 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:50:57,671 - trainer - INFO] - Train Epoch:[12/30] Step:[24000/25169] Loss: 0.543204 Loss_avg: 0.474007 LR: 0.00033982 Loss Fine: 0.543204 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:51:03,138 - trainer - INFO] - [Step Validation] Epoch:[12/30] Step:[24000/25169] Word_acc: 0.896804 Word_acc_case_ins 0.896804 Edit_distance_acc: 0.961614
[2025-01-23 23:54:23,352 - trainer - INFO] - Train Epoch:[12/30] Step:[25000/25169] Loss: 0.509160 Loss_avg: 0.473930 LR: 0.00033882 Loss Fine: 0.509160 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:55:02,914 - trainer - INFO] - [Epoch End] Epoch:[12/30] Loss: 0.473887 LR: 0.00033865
 Validation result after 12 epoch: Word_acc: 0.896021 Word_acc_case_ins: 0.896021 Edit_distance_acc: 0.959919
[2025-01-23 23:55:04,344 - trainer - INFO] - Train Epoch:[13/30] Step:[1/25169] Loss: 0.557778 Loss_avg: 0.557778 LR: 0.00033865 Loss Fine: 0.557778 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-23 23:58:24,457 - trainer - INFO] - Train Epoch:[13/30] Step:[1000/25169] Loss: 0.408849 Loss_avg: 0.468903 LR: 0.00033765 Loss Fine: 0.408849 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:01:44,656 - trainer - INFO] - Train Epoch:[13/30] Step:[2000/25169] Loss: 0.414614 Loss_avg: 0.462483 LR: 0.00033665 Loss Fine: 0.414614 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:05:04,879 - trainer - INFO] - Train Epoch:[13/30] Step:[3000/25169] Loss: 0.299937 Loss_avg: 0.461564 LR: 0.00033565 Loss Fine: 0.299937 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:05:10,349 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[3000/25169] Word_acc: 0.897978 Word_acc_case_ins 0.897978 Edit_distance_acc: 0.962768
[2025-01-24 00:05:10,650 - trainer - INFO] - Saving current best (at 13 epoch): model_best.pth Best word_acc: 0.897978
[2025-01-24 00:08:30,743 - trainer - INFO] - Train Epoch:[13/30] Step:[4000/25169] Loss: 0.418265 Loss_avg: 0.462083 LR: 0.00033465 Loss Fine: 0.418265 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:11:50,884 - trainer - INFO] - Train Epoch:[13/30] Step:[5000/25169] Loss: 0.461032 Loss_avg: 0.463361 LR: 0.00033364 Loss Fine: 0.461032 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:15:11,037 - trainer - INFO] - Train Epoch:[13/30] Step:[6000/25169] Loss: 0.405985 Loss_avg: 0.463727 LR: 0.00033264 Loss Fine: 0.405985 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:15:16,508 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[6000/25169] Word_acc: 0.892629 Word_acc_case_ins 0.892629 Edit_distance_acc: 0.960214
[2025-01-24 00:18:36,711 - trainer - INFO] - Train Epoch:[13/30] Step:[7000/25169] Loss: 0.547426 Loss_avg: 0.464320 LR: 0.00033163 Loss Fine: 0.547426 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:21:56,847 - trainer - INFO] - Train Epoch:[13/30] Step:[8000/25169] Loss: 0.345825 Loss_avg: 0.463985 LR: 0.00033062 Loss Fine: 0.345825 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:25:16,994 - trainer - INFO] - Train Epoch:[13/30] Step:[9000/25169] Loss: 0.469673 Loss_avg: 0.463946 LR: 0.00032961 Loss Fine: 0.469673 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:25:22,498 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[9000/25169] Word_acc: 0.901239 Word_acc_case_ins 0.901239 Edit_distance_acc: 0.963751
[2025-01-24 00:25:22,833 - trainer - INFO] - Saving current best (at 13 epoch): model_best.pth Best word_acc: 0.901239
[2025-01-24 00:28:43,099 - trainer - INFO] - Train Epoch:[13/30] Step:[10000/25169] Loss: 0.707204 Loss_avg: 0.464377 LR: 0.00032860 Loss Fine: 0.707204 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:32:03,310 - trainer - INFO] - Train Epoch:[13/30] Step:[11000/25169] Loss: 0.642645 Loss_avg: 0.465406 LR: 0.00032758 Loss Fine: 0.642645 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:35:23,478 - trainer - INFO] - Train Epoch:[13/30] Step:[12000/25169] Loss: 0.494699 Loss_avg: 0.465092 LR: 0.00032657 Loss Fine: 0.494699 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:35:28,961 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[12000/25169] Word_acc: 0.903588 Word_acc_case_ins 0.903588 Edit_distance_acc: 0.963775
[2025-01-24 00:35:29,266 - trainer - INFO] - Saving current best (at 13 epoch): model_best.pth Best word_acc: 0.903588
[2025-01-24 00:38:49,462 - trainer - INFO] - Train Epoch:[13/30] Step:[13000/25169] Loss: 0.424994 Loss_avg: 0.465126 LR: 0.00032555 Loss Fine: 0.424994 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:42:09,606 - trainer - INFO] - Train Epoch:[13/30] Step:[14000/25169] Loss: 0.554946 Loss_avg: 0.465457 LR: 0.00032454 Loss Fine: 0.554946 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:45:29,707 - trainer - INFO] - Train Epoch:[13/30] Step:[15000/25169] Loss: 0.472741 Loss_avg: 0.465495 LR: 0.00032352 Loss Fine: 0.472741 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:45:35,182 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[15000/25169] Word_acc: 0.901631 Word_acc_case_ins 0.901631 Edit_distance_acc: 0.961761
[2025-01-24 00:48:55,363 - trainer - INFO] - Train Epoch:[13/30] Step:[16000/25169] Loss: 0.375367 Loss_avg: 0.465206 LR: 0.00032250 Loss Fine: 0.375367 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:52:15,530 - trainer - INFO] - Train Epoch:[13/30] Step:[17000/25169] Loss: 0.469561 Loss_avg: 0.464886 LR: 0.00032147 Loss Fine: 0.469561 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:55:39,206 - trainer - INFO] - Train Epoch:[13/30] Step:[18000/25169] Loss: 0.397659 Loss_avg: 0.464658 LR: 0.00032045 Loss Fine: 0.397659 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 00:55:44,726 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[18000/25169] Word_acc: 0.899804 Word_acc_case_ins 0.899804 Edit_distance_acc: 0.963505
[2025-01-24 00:59:04,922 - trainer - INFO] - Train Epoch:[13/30] Step:[19000/25169] Loss: 0.519329 Loss_avg: 0.464495 LR: 0.00031943 Loss Fine: 0.519329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:02:25,184 - trainer - INFO] - Train Epoch:[13/30] Step:[20000/25169] Loss: 0.651435 Loss_avg: 0.464377 LR: 0.00031840 Loss Fine: 0.651435 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:05:45,399 - trainer - INFO] - Train Epoch:[13/30] Step:[21000/25169] Loss: 0.489838 Loss_avg: 0.464289 LR: 0.00031738 Loss Fine: 0.489838 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:05:50,878 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[21000/25169] Word_acc: 0.896282 Word_acc_case_ins 0.896282 Edit_distance_acc: 0.960239
[2025-01-24 01:09:11,102 - trainer - INFO] - Train Epoch:[13/30] Step:[22000/25169] Loss: 0.520060 Loss_avg: 0.464082 LR: 0.00031635 Loss Fine: 0.520060 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:12:31,335 - trainer - INFO] - Train Epoch:[13/30] Step:[23000/25169] Loss: 0.514672 Loss_avg: 0.463690 LR: 0.00031532 Loss Fine: 0.514672 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:15:51,544 - trainer - INFO] - Train Epoch:[13/30] Step:[24000/25169] Loss: 0.532808 Loss_avg: 0.463419 LR: 0.00031429 Loss Fine: 0.532808 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:15:56,997 - trainer - INFO] - [Step Validation] Epoch:[13/30] Step:[24000/25169] Word_acc: 0.902283 Word_acc_case_ins 0.902283 Edit_distance_acc: 0.964045
[2025-01-24 01:19:17,174 - trainer - INFO] - Train Epoch:[13/30] Step:[25000/25169] Loss: 0.561089 Loss_avg: 0.463168 LR: 0.00031326 Loss Fine: 0.561089 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:19:56,728 - trainer - INFO] - [Epoch End] Epoch:[13/30] Loss: 0.463145 LR: 0.00031308
 Validation result after 13 epoch: Word_acc: 0.898891 Word_acc_case_ins: 0.898891 Edit_distance_acc: 0.961344
[2025-01-24 01:19:58,305 - trainer - INFO] - Train Epoch:[14/30] Step:[1/25169] Loss: 0.448825 Loss_avg: 0.448825 LR: 0.00031308 Loss Fine: 0.448825 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:23:18,211 - trainer - INFO] - Train Epoch:[14/30] Step:[1000/25169] Loss: 0.663894 Loss_avg: 0.449742 LR: 0.00031205 Loss Fine: 0.663894 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:26:38,258 - trainer - INFO] - Train Epoch:[14/30] Step:[2000/25169] Loss: 0.425650 Loss_avg: 0.455552 LR: 0.00031102 Loss Fine: 0.425650 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:29:58,408 - trainer - INFO] - Train Epoch:[14/30] Step:[3000/25169] Loss: 0.385054 Loss_avg: 0.456043 LR: 0.00030998 Loss Fine: 0.385054 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:30:03,882 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[3000/25169] Word_acc: 0.899804 Word_acc_case_ins 0.899804 Edit_distance_acc: 0.962744
[2025-01-24 01:33:24,041 - trainer - INFO] - Train Epoch:[14/30] Step:[4000/25169] Loss: 0.439786 Loss_avg: 0.455247 LR: 0.00030894 Loss Fine: 0.439786 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:36:44,188 - trainer - INFO] - Train Epoch:[14/30] Step:[5000/25169] Loss: 0.494194 Loss_avg: 0.454225 LR: 0.00030791 Loss Fine: 0.494194 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:40:04,363 - trainer - INFO] - Train Epoch:[14/30] Step:[6000/25169] Loss: 0.395278 Loss_avg: 0.454552 LR: 0.00030687 Loss Fine: 0.395278 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:40:09,850 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[6000/25169] Word_acc: 0.897065 Word_acc_case_ins 0.897065 Edit_distance_acc: 0.961712
[2025-01-24 01:43:30,016 - trainer - INFO] - Train Epoch:[14/30] Step:[7000/25169] Loss: 0.510933 Loss_avg: 0.454899 LR: 0.00030583 Loss Fine: 0.510933 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:46:50,106 - trainer - INFO] - Train Epoch:[14/30] Step:[8000/25169] Loss: 0.504108 Loss_avg: 0.454422 LR: 0.00030479 Loss Fine: 0.504108 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:50:10,276 - trainer - INFO] - Train Epoch:[14/30] Step:[9000/25169] Loss: 0.413459 Loss_avg: 0.454354 LR: 0.00030375 Loss Fine: 0.413459 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:50:15,774 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[9000/25169] Word_acc: 0.902283 Word_acc_case_ins 0.902283 Edit_distance_acc: 0.963186
[2025-01-24 01:53:35,987 - trainer - INFO] - Train Epoch:[14/30] Step:[10000/25169] Loss: 0.490164 Loss_avg: 0.454033 LR: 0.00030270 Loss Fine: 0.490164 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 01:56:56,074 - trainer - INFO] - Train Epoch:[14/30] Step:[11000/25169] Loss: 0.594026 Loss_avg: 0.453965 LR: 0.00030166 Loss Fine: 0.594026 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:00:16,224 - trainer - INFO] - Train Epoch:[14/30] Step:[12000/25169] Loss: 0.407000 Loss_avg: 0.453838 LR: 0.00030062 Loss Fine: 0.407000 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:00:21,730 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[12000/25169] Word_acc: 0.900718 Word_acc_case_ins 0.900718 Edit_distance_acc: 0.962277
[2025-01-24 02:03:41,986 - trainer - INFO] - Train Epoch:[14/30] Step:[13000/25169] Loss: 0.548267 Loss_avg: 0.453610 LR: 0.00029957 Loss Fine: 0.548267 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:07:02,065 - trainer - INFO] - Train Epoch:[14/30] Step:[14000/25169] Loss: 0.420444 Loss_avg: 0.453730 LR: 0.00029853 Loss Fine: 0.420444 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:10:22,213 - trainer - INFO] - Train Epoch:[14/30] Step:[15000/25169] Loss: 0.400470 Loss_avg: 0.453367 LR: 0.00029748 Loss Fine: 0.400470 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:10:27,699 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[15000/25169] Word_acc: 0.904371 Word_acc_case_ins 0.904371 Edit_distance_acc: 0.961958
[2025-01-24 02:10:28,012 - trainer - INFO] - Saving current best (at 14 epoch): model_best.pth Best word_acc: 0.904371
[2025-01-24 02:13:48,224 - trainer - INFO] - Train Epoch:[14/30] Step:[16000/25169] Loss: 0.370830 Loss_avg: 0.453367 LR: 0.00029643 Loss Fine: 0.370830 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:17:08,306 - trainer - INFO] - Train Epoch:[14/30] Step:[17000/25169] Loss: 0.573587 Loss_avg: 0.453206 LR: 0.00029538 Loss Fine: 0.573587 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:20:28,491 - trainer - INFO] - Train Epoch:[14/30] Step:[18000/25169] Loss: 0.324370 Loss_avg: 0.452950 LR: 0.00029433 Loss Fine: 0.324370 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:20:33,986 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[18000/25169] Word_acc: 0.899674 Word_acc_case_ins 0.899674 Edit_distance_acc: 0.964316
[2025-01-24 02:23:54,164 - trainer - INFO] - Train Epoch:[14/30] Step:[19000/25169] Loss: 0.324026 Loss_avg: 0.452702 LR: 0.00029328 Loss Fine: 0.324026 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:27:14,291 - trainer - INFO] - Train Epoch:[14/30] Step:[20000/25169] Loss: 0.399544 Loss_avg: 0.452506 LR: 0.00029223 Loss Fine: 0.399544 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:30:34,490 - trainer - INFO] - Train Epoch:[14/30] Step:[21000/25169] Loss: 0.471241 Loss_avg: 0.452287 LR: 0.00029118 Loss Fine: 0.471241 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:30:39,986 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[21000/25169] Word_acc: 0.907241 Word_acc_case_ins 0.907241 Edit_distance_acc: 0.965372
[2025-01-24 02:30:40,296 - trainer - INFO] - Saving current best (at 14 epoch): model_best.pth Best word_acc: 0.907241
[2025-01-24 02:34:00,583 - trainer - INFO] - Train Epoch:[14/30] Step:[22000/25169] Loss: 0.523534 Loss_avg: 0.452045 LR: 0.00029013 Loss Fine: 0.523534 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:37:20,823 - trainer - INFO] - Train Epoch:[14/30] Step:[23000/25169] Loss: 0.476767 Loss_avg: 0.452068 LR: 0.00028907 Loss Fine: 0.476767 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:40:41,072 - trainer - INFO] - Train Epoch:[14/30] Step:[24000/25169] Loss: 0.332101 Loss_avg: 0.452138 LR: 0.00028802 Loss Fine: 0.332101 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:40:46,569 - trainer - INFO] - [Step Validation] Epoch:[14/30] Step:[24000/25169] Word_acc: 0.902935 Word_acc_case_ins 0.902935 Edit_distance_acc: 0.963333
[2025-01-24 02:44:06,741 - trainer - INFO] - Train Epoch:[14/30] Step:[25000/25169] Loss: 0.630369 Loss_avg: 0.451861 LR: 0.00028696 Loss Fine: 0.630369 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:44:46,247 - trainer - INFO] - [Epoch End] Epoch:[14/30] Loss: 0.451852 LR: 0.00028679
 Validation result after 14 epoch: Word_acc: 0.906067 Word_acc_case_ins: 0.906067 Edit_distance_acc: 0.965986
[2025-01-24 02:44:48,037 - trainer - INFO] - Train Epoch:[15/30] Step:[1/25169] Loss: 0.452579 Loss_avg: 0.452579 LR: 0.00028679 Loss Fine: 0.452579 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:48:07,973 - trainer - INFO] - Train Epoch:[15/30] Step:[1000/25169] Loss: 0.391889 Loss_avg: 0.442545 LR: 0.00028573 Loss Fine: 0.391889 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:51:28,159 - trainer - INFO] - Train Epoch:[15/30] Step:[2000/25169] Loss: 0.441242 Loss_avg: 0.441384 LR: 0.00028467 Loss Fine: 0.441242 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:54:48,277 - trainer - INFO] - Train Epoch:[15/30] Step:[3000/25169] Loss: 0.533192 Loss_avg: 0.442739 LR: 0.00028362 Loss Fine: 0.533192 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 02:54:53,773 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[3000/25169] Word_acc: 0.902805 Word_acc_case_ins 0.902805 Edit_distance_acc: 0.965028
[2025-01-24 02:58:13,932 - trainer - INFO] - Train Epoch:[15/30] Step:[4000/25169] Loss: 0.554181 Loss_avg: 0.444499 LR: 0.00028256 Loss Fine: 0.554181 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:01:34,066 - trainer - INFO] - Train Epoch:[15/30] Step:[5000/25169] Loss: 0.499025 Loss_avg: 0.443492 LR: 0.00028150 Loss Fine: 0.499025 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:04:54,195 - trainer - INFO] - Train Epoch:[15/30] Step:[6000/25169] Loss: 0.559387 Loss_avg: 0.444577 LR: 0.00028044 Loss Fine: 0.559387 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:04:59,694 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[6000/25169] Word_acc: 0.901892 Word_acc_case_ins 0.901892 Edit_distance_acc: 0.963137
[2025-01-24 03:08:19,880 - trainer - INFO] - Train Epoch:[15/30] Step:[7000/25169] Loss: 0.507999 Loss_avg: 0.444222 LR: 0.00027938 Loss Fine: 0.507999 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:11:40,150 - trainer - INFO] - Train Epoch:[15/30] Step:[8000/25169] Loss: 0.558625 Loss_avg: 0.443838 LR: 0.00027832 Loss Fine: 0.558625 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:15:00,376 - trainer - INFO] - Train Epoch:[15/30] Step:[9000/25169] Loss: 0.310832 Loss_avg: 0.443850 LR: 0.00027726 Loss Fine: 0.310832 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:15:05,874 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[9000/25169] Word_acc: 0.904240 Word_acc_case_ins 0.904240 Edit_distance_acc: 0.964708
[2025-01-24 03:18:26,035 - trainer - INFO] - Train Epoch:[15/30] Step:[10000/25169] Loss: 0.409148 Loss_avg: 0.443790 LR: 0.00027620 Loss Fine: 0.409148 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:21:46,276 - trainer - INFO] - Train Epoch:[15/30] Step:[11000/25169] Loss: 0.370044 Loss_avg: 0.443286 LR: 0.00027514 Loss Fine: 0.370044 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:25:06,526 - trainer - INFO] - Train Epoch:[15/30] Step:[12000/25169] Loss: 0.541724 Loss_avg: 0.443628 LR: 0.00027408 Loss Fine: 0.541724 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:25:12,026 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[12000/25169] Word_acc: 0.902283 Word_acc_case_ins 0.902283 Edit_distance_acc: 0.965642
[2025-01-24 03:28:36,300 - trainer - INFO] - Train Epoch:[15/30] Step:[13000/25169] Loss: 0.372471 Loss_avg: 0.443430 LR: 0.00027302 Loss Fine: 0.372471 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:31:56,507 - trainer - INFO] - Train Epoch:[15/30] Step:[14000/25169] Loss: 0.353744 Loss_avg: 0.443178 LR: 0.00027196 Loss Fine: 0.353744 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:35:16,725 - trainer - INFO] - Train Epoch:[15/30] Step:[15000/25169] Loss: 0.364054 Loss_avg: 0.442659 LR: 0.00027089 Loss Fine: 0.364054 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:35:22,211 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[15000/25169] Word_acc: 0.903196 Word_acc_case_ins 0.903196 Edit_distance_acc: 0.964340
[2025-01-24 03:38:42,358 - trainer - INFO] - Train Epoch:[15/30] Step:[16000/25169] Loss: 0.356700 Loss_avg: 0.442735 LR: 0.00026983 Loss Fine: 0.356700 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:42:02,521 - trainer - INFO] - Train Epoch:[15/30] Step:[17000/25169] Loss: 0.550029 Loss_avg: 0.442607 LR: 0.00026877 Loss Fine: 0.550029 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:45:22,594 - trainer - INFO] - Train Epoch:[15/30] Step:[18000/25169] Loss: 0.396300 Loss_avg: 0.442105 LR: 0.00026770 Loss Fine: 0.396300 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:45:28,104 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[18000/25169] Word_acc: 0.908937 Word_acc_case_ins 0.908937 Edit_distance_acc: 0.966747
[2025-01-24 03:45:28,419 - trainer - INFO] - Saving current best (at 15 epoch): model_best.pth Best word_acc: 0.908937
[2025-01-24 03:48:48,608 - trainer - INFO] - Train Epoch:[15/30] Step:[19000/25169] Loss: 0.438882 Loss_avg: 0.441916 LR: 0.00026664 Loss Fine: 0.438882 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:52:08,815 - trainer - INFO] - Train Epoch:[15/30] Step:[20000/25169] Loss: 0.373854 Loss_avg: 0.441362 LR: 0.00026557 Loss Fine: 0.373854 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:55:29,056 - trainer - INFO] - Train Epoch:[15/30] Step:[21000/25169] Loss: 0.519186 Loss_avg: 0.440986 LR: 0.00026451 Loss Fine: 0.519186 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 03:55:34,570 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[21000/25169] Word_acc: 0.902153 Word_acc_case_ins 0.902153 Edit_distance_acc: 0.962793
[2025-01-24 03:58:54,718 - trainer - INFO] - Train Epoch:[15/30] Step:[22000/25169] Loss: 0.551047 Loss_avg: 0.440814 LR: 0.00026344 Loss Fine: 0.551047 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:02:14,798 - trainer - INFO] - Train Epoch:[15/30] Step:[23000/25169] Loss: 0.599518 Loss_avg: 0.440571 LR: 0.00026238 Loss Fine: 0.599518 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:05:34,944 - trainer - INFO] - Train Epoch:[15/30] Step:[24000/25169] Loss: 0.409972 Loss_avg: 0.440401 LR: 0.00026131 Loss Fine: 0.409972 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:05:40,438 - trainer - INFO] - [Step Validation] Epoch:[15/30] Step:[24000/25169] Word_acc: 0.902153 Word_acc_case_ins 0.902153 Edit_distance_acc: 0.964684
[2025-01-24 04:09:00,641 - trainer - INFO] - Train Epoch:[15/30] Step:[25000/25169] Loss: 0.361932 Loss_avg: 0.440400 LR: 0.00026025 Loss Fine: 0.361932 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:09:40,163 - trainer - INFO] - [Epoch End] Epoch:[15/30] Loss: 0.440457 LR: 0.00026007
 Validation result after 15 epoch: Word_acc: 0.903066 Word_acc_case_ins: 0.903066 Edit_distance_acc: 0.963923
[2025-01-24 04:09:41,660 - trainer - INFO] - Train Epoch:[16/30] Step:[1/25169] Loss: 0.518291 Loss_avg: 0.518291 LR: 0.00026007 Loss Fine: 0.518291 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:13:01,649 - trainer - INFO] - Train Epoch:[16/30] Step:[1000/25169] Loss: 0.285294 Loss_avg: 0.431129 LR: 0.00025900 Loss Fine: 0.285294 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:16:21,715 - trainer - INFO] - Train Epoch:[16/30] Step:[2000/25169] Loss: 0.388807 Loss_avg: 0.432853 LR: 0.00025793 Loss Fine: 0.388807 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:19:41,793 - trainer - INFO] - Train Epoch:[16/30] Step:[3000/25169] Loss: 0.378593 Loss_avg: 0.433860 LR: 0.00025687 Loss Fine: 0.378593 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:19:47,278 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[3000/25169] Word_acc: 0.905414 Word_acc_case_ins 0.905414 Edit_distance_acc: 0.964316
[2025-01-24 04:23:07,314 - trainer - INFO] - Train Epoch:[16/30] Step:[4000/25169] Loss: 0.353692 Loss_avg: 0.433605 LR: 0.00025580 Loss Fine: 0.353692 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:26:27,405 - trainer - INFO] - Train Epoch:[16/30] Step:[5000/25169] Loss: 0.569756 Loss_avg: 0.432377 LR: 0.00025473 Loss Fine: 0.569756 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:29:47,462 - trainer - INFO] - Train Epoch:[16/30] Step:[6000/25169] Loss: 0.546523 Loss_avg: 0.431711 LR: 0.00025367 Loss Fine: 0.546523 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:29:52,950 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[6000/25169] Word_acc: 0.905284 Word_acc_case_ins 0.905284 Edit_distance_acc: 0.964561
[2025-01-24 04:33:13,061 - trainer - INFO] - Train Epoch:[16/30] Step:[7000/25169] Loss: 0.443957 Loss_avg: 0.431509 LR: 0.00025260 Loss Fine: 0.443957 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:36:33,221 - trainer - INFO] - Train Epoch:[16/30] Step:[8000/25169] Loss: 0.337223 Loss_avg: 0.431614 LR: 0.00025153 Loss Fine: 0.337223 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:39:53,370 - trainer - INFO] - Train Epoch:[16/30] Step:[9000/25169] Loss: 0.659178 Loss_avg: 0.431825 LR: 0.00025047 Loss Fine: 0.659178 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:39:58,867 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[9000/25169] Word_acc: 0.905936 Word_acc_case_ins 0.905936 Edit_distance_acc: 0.966428
[2025-01-24 04:43:19,009 - trainer - INFO] - Train Epoch:[16/30] Step:[10000/25169] Loss: 0.500884 Loss_avg: 0.431368 LR: 0.00024940 Loss Fine: 0.500884 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:46:39,113 - trainer - INFO] - Train Epoch:[16/30] Step:[11000/25169] Loss: 0.326218 Loss_avg: 0.431204 LR: 0.00024833 Loss Fine: 0.326218 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:49:59,288 - trainer - INFO] - Train Epoch:[16/30] Step:[12000/25169] Loss: 0.412951 Loss_avg: 0.431310 LR: 0.00024727 Loss Fine: 0.412951 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:50:04,777 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[12000/25169] Word_acc: 0.906197 Word_acc_case_ins 0.906197 Edit_distance_acc: 0.965273
[2025-01-24 04:53:24,961 - trainer - INFO] - Train Epoch:[16/30] Step:[13000/25169] Loss: 0.452549 Loss_avg: 0.431036 LR: 0.00024620 Loss Fine: 0.452549 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 04:56:45,158 - trainer - INFO] - Train Epoch:[16/30] Step:[14000/25169] Loss: 0.502737 Loss_avg: 0.431182 LR: 0.00024513 Loss Fine: 0.502737 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:00:05,404 - trainer - INFO] - Train Epoch:[16/30] Step:[15000/25169] Loss: 0.591594 Loss_avg: 0.431328 LR: 0.00024407 Loss Fine: 0.591594 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:00:10,881 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[15000/25169] Word_acc: 0.904501 Word_acc_case_ins 0.904501 Edit_distance_acc: 0.965347
[2025-01-24 05:03:30,952 - trainer - INFO] - Train Epoch:[16/30] Step:[16000/25169] Loss: 0.257843 Loss_avg: 0.430879 LR: 0.00024300 Loss Fine: 0.257843 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:06:51,190 - trainer - INFO] - Train Epoch:[16/30] Step:[17000/25169] Loss: 0.515471 Loss_avg: 0.430996 LR: 0.00024193 Loss Fine: 0.515471 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:10:11,310 - trainer - INFO] - Train Epoch:[16/30] Step:[18000/25169] Loss: 0.312947 Loss_avg: 0.430569 LR: 0.00024087 Loss Fine: 0.312947 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:10:16,818 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[18000/25169] Word_acc: 0.904240 Word_acc_case_ins 0.904240 Edit_distance_acc: 0.965715
[2025-01-24 05:13:37,096 - trainer - INFO] - Train Epoch:[16/30] Step:[19000/25169] Loss: 0.461882 Loss_avg: 0.430018 LR: 0.00023980 Loss Fine: 0.461882 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:16:57,272 - trainer - INFO] - Train Epoch:[16/30] Step:[20000/25169] Loss: 0.331649 Loss_avg: 0.429747 LR: 0.00023874 Loss Fine: 0.331649 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:20:17,510 - trainer - INFO] - Train Epoch:[16/30] Step:[21000/25169] Loss: 0.306239 Loss_avg: 0.429423 LR: 0.00023767 Loss Fine: 0.306239 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:20:23,049 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[21000/25169] Word_acc: 0.911024 Word_acc_case_ins 0.911024 Edit_distance_acc: 0.966894
[2025-01-24 05:20:23,343 - trainer - INFO] - Saving current best (at 16 epoch): model_best.pth Best word_acc: 0.911024
[2025-01-24 05:23:43,450 - trainer - INFO] - Train Epoch:[16/30] Step:[22000/25169] Loss: 0.437041 Loss_avg: 0.429124 LR: 0.00023661 Loss Fine: 0.437041 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:27:03,587 - trainer - INFO] - Train Epoch:[16/30] Step:[23000/25169] Loss: 0.384094 Loss_avg: 0.429347 LR: 0.00023554 Loss Fine: 0.384094 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:30:23,754 - trainer - INFO] - Train Epoch:[16/30] Step:[24000/25169] Loss: 0.288881 Loss_avg: 0.429306 LR: 0.00023448 Loss Fine: 0.288881 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:30:29,284 - trainer - INFO] - [Step Validation] Epoch:[16/30] Step:[24000/25169] Word_acc: 0.909067 Word_acc_case_ins 0.909067 Edit_distance_acc: 0.966157
[2025-01-24 05:33:49,435 - trainer - INFO] - Train Epoch:[16/30] Step:[25000/25169] Loss: 0.579325 Loss_avg: 0.429076 LR: 0.00023341 Loss Fine: 0.579325 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:34:28,923 - trainer - INFO] - [Epoch End] Epoch:[16/30] Loss: 0.428953 LR: 0.00023323
 Validation result after 16 epoch: Word_acc: 0.911155 Word_acc_case_ins: 0.911155 Edit_distance_acc: 0.967140
[2025-01-24 05:34:29,263 - trainer - INFO] - Saving current best (at 16 epoch): model_best.pth Best word_acc: 0.911155
[2025-01-24 05:34:30,978 - trainer - INFO] - Train Epoch:[17/30] Step:[1/25169] Loss: 0.357979 Loss_avg: 0.357979 LR: 0.00023323 Loss Fine: 0.357979 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:37:50,956 - trainer - INFO] - Train Epoch:[17/30] Step:[1000/25169] Loss: 0.510727 Loss_avg: 0.416138 LR: 0.00023217 Loss Fine: 0.510727 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:41:11,146 - trainer - INFO] - Train Epoch:[17/30] Step:[2000/25169] Loss: 0.398417 Loss_avg: 0.417401 LR: 0.00023110 Loss Fine: 0.398417 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:44:31,224 - trainer - INFO] - Train Epoch:[17/30] Step:[3000/25169] Loss: 0.293207 Loss_avg: 0.417809 LR: 0.00023004 Loss Fine: 0.293207 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:44:36,719 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[3000/25169] Word_acc: 0.909459 Word_acc_case_ins 0.909459 Edit_distance_acc: 0.967385
[2025-01-24 05:47:56,842 - trainer - INFO] - Train Epoch:[17/30] Step:[4000/25169] Loss: 0.483748 Loss_avg: 0.418794 LR: 0.00022898 Loss Fine: 0.483748 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:51:16,946 - trainer - INFO] - Train Epoch:[17/30] Step:[5000/25169] Loss: 0.570807 Loss_avg: 0.417751 LR: 0.00022791 Loss Fine: 0.570807 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:54:37,042 - trainer - INFO] - Train Epoch:[17/30] Step:[6000/25169] Loss: 0.466234 Loss_avg: 0.418160 LR: 0.00022685 Loss Fine: 0.466234 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 05:54:42,514 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[6000/25169] Word_acc: 0.910502 Word_acc_case_ins 0.910502 Edit_distance_acc: 0.968270
[2025-01-24 05:58:02,658 - trainer - INFO] - Train Epoch:[17/30] Step:[7000/25169] Loss: 0.248279 Loss_avg: 0.418020 LR: 0.00022579 Loss Fine: 0.248279 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:01:22,805 - trainer - INFO] - Train Epoch:[17/30] Step:[8000/25169] Loss: 0.375514 Loss_avg: 0.417924 LR: 0.00022473 Loss Fine: 0.375514 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:04:42,911 - trainer - INFO] - Train Epoch:[17/30] Step:[9000/25169] Loss: 0.613319 Loss_avg: 0.418280 LR: 0.00022367 Loss Fine: 0.613319 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:04:48,417 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[9000/25169] Word_acc: 0.911937 Word_acc_case_ins 0.911937 Edit_distance_acc: 0.967999
[2025-01-24 06:04:48,714 - trainer - INFO] - Saving current best (at 17 epoch): model_best.pth Best word_acc: 0.911937
[2025-01-24 06:08:08,847 - trainer - INFO] - Train Epoch:[17/30] Step:[10000/25169] Loss: 0.540177 Loss_avg: 0.418448 LR: 0.00022260 Loss Fine: 0.540177 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:11:28,964 - trainer - INFO] - Train Epoch:[17/30] Step:[11000/25169] Loss: 0.396755 Loss_avg: 0.418622 LR: 0.00022154 Loss Fine: 0.396755 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:14:49,103 - trainer - INFO] - Train Epoch:[17/30] Step:[12000/25169] Loss: 0.428069 Loss_avg: 0.418167 LR: 0.00022049 Loss Fine: 0.428069 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:14:54,645 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[12000/25169] Word_acc: 0.911676 Word_acc_case_ins 0.911676 Edit_distance_acc: 0.966722
[2025-01-24 06:18:14,887 - trainer - INFO] - Train Epoch:[17/30] Step:[13000/25169] Loss: 0.545210 Loss_avg: 0.418297 LR: 0.00021943 Loss Fine: 0.545210 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:21:35,122 - trainer - INFO] - Train Epoch:[17/30] Step:[14000/25169] Loss: 0.322002 Loss_avg: 0.418106 LR: 0.00021837 Loss Fine: 0.322002 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:25:00,003 - trainer - INFO] - Train Epoch:[17/30] Step:[15000/25169] Loss: 0.342713 Loss_avg: 0.418163 LR: 0.00021731 Loss Fine: 0.342713 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:25:05,498 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[15000/25169] Word_acc: 0.909198 Word_acc_case_ins 0.909198 Edit_distance_acc: 0.967066
[2025-01-24 06:28:25,679 - trainer - INFO] - Train Epoch:[17/30] Step:[16000/25169] Loss: 0.374219 Loss_avg: 0.418027 LR: 0.00021625 Loss Fine: 0.374219 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:31:45,780 - trainer - INFO] - Train Epoch:[17/30] Step:[17000/25169] Loss: 0.371862 Loss_avg: 0.418033 LR: 0.00021520 Loss Fine: 0.371862 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:35:05,951 - trainer - INFO] - Train Epoch:[17/30] Step:[18000/25169] Loss: 0.347142 Loss_avg: 0.417569 LR: 0.00021414 Loss Fine: 0.347142 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:35:11,485 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[18000/25169] Word_acc: 0.908806 Word_acc_case_ins 0.908806 Edit_distance_acc: 0.967484
[2025-01-24 06:38:31,675 - trainer - INFO] - Train Epoch:[17/30] Step:[19000/25169] Loss: 0.321201 Loss_avg: 0.417335 LR: 0.00021308 Loss Fine: 0.321201 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:41:51,807 - trainer - INFO] - Train Epoch:[17/30] Step:[20000/25169] Loss: 0.427781 Loss_avg: 0.417078 LR: 0.00021203 Loss Fine: 0.427781 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:45:11,934 - trainer - INFO] - Train Epoch:[17/30] Step:[21000/25169] Loss: 0.390171 Loss_avg: 0.417234 LR: 0.00021097 Loss Fine: 0.390171 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:45:17,460 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[21000/25169] Word_acc: 0.911024 Word_acc_case_ins 0.911024 Edit_distance_acc: 0.967975
[2025-01-24 06:48:37,715 - trainer - INFO] - Train Epoch:[17/30] Step:[22000/25169] Loss: 0.473116 Loss_avg: 0.417041 LR: 0.00020992 Loss Fine: 0.473116 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:51:58,001 - trainer - INFO] - Train Epoch:[17/30] Step:[23000/25169] Loss: 0.536051 Loss_avg: 0.417041 LR: 0.00020887 Loss Fine: 0.536051 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:55:18,213 - trainer - INFO] - Train Epoch:[17/30] Step:[24000/25169] Loss: 0.388353 Loss_avg: 0.416769 LR: 0.00020782 Loss Fine: 0.388353 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:55:23,714 - trainer - INFO] - [Step Validation] Epoch:[17/30] Step:[24000/25169] Word_acc: 0.912981 Word_acc_case_ins 0.912981 Edit_distance_acc: 0.967999
[2025-01-24 06:55:24,055 - trainer - INFO] - Saving current best (at 17 epoch): model_best.pth Best word_acc: 0.912981
[2025-01-24 06:58:44,169 - trainer - INFO] - Train Epoch:[17/30] Step:[25000/25169] Loss: 0.301333 Loss_avg: 0.416473 LR: 0.00020677 Loss Fine: 0.301333 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 06:59:23,678 - trainer - INFO] - [Epoch End] Epoch:[17/30] Loss: 0.416472 LR: 0.00020659
 Validation result after 17 epoch: Word_acc: 0.909850 Word_acc_case_ins: 0.909850 Edit_distance_acc: 0.967533
[2025-01-24 06:59:25,042 - trainer - INFO] - Train Epoch:[18/30] Step:[1/25169] Loss: 0.583613 Loss_avg: 0.583613 LR: 0.00020659 Loss Fine: 0.583613 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:02:45,103 - trainer - INFO] - Train Epoch:[18/30] Step:[1000/25169] Loss: 0.409921 Loss_avg: 0.404959 LR: 0.00020554 Loss Fine: 0.409921 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:06:05,093 - trainer - INFO] - Train Epoch:[18/30] Step:[2000/25169] Loss: 0.437365 Loss_avg: 0.405613 LR: 0.00020449 Loss Fine: 0.437365 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:09:25,225 - trainer - INFO] - Train Epoch:[18/30] Step:[3000/25169] Loss: 0.325308 Loss_avg: 0.404057 LR: 0.00020344 Loss Fine: 0.325308 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:09:30,754 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[3000/25169] Word_acc: 0.910111 Word_acc_case_ins 0.910111 Edit_distance_acc: 0.967287
[2025-01-24 07:12:51,032 - trainer - INFO] - Train Epoch:[18/30] Step:[4000/25169] Loss: 0.232006 Loss_avg: 0.404796 LR: 0.00020239 Loss Fine: 0.232006 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:16:11,291 - trainer - INFO] - Train Epoch:[18/30] Step:[5000/25169] Loss: 0.524814 Loss_avg: 0.405842 LR: 0.00020135 Loss Fine: 0.524814 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:19:31,500 - trainer - INFO] - Train Epoch:[18/30] Step:[6000/25169] Loss: 0.377647 Loss_avg: 0.404993 LR: 0.00020030 Loss Fine: 0.377647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:19:36,991 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[6000/25169] Word_acc: 0.913242 Word_acc_case_ins 0.913242 Edit_distance_acc: 0.968147
[2025-01-24 07:19:37,313 - trainer - INFO] - Saving current best (at 18 epoch): model_best.pth Best word_acc: 0.913242
[2025-01-24 07:22:57,555 - trainer - INFO] - Train Epoch:[18/30] Step:[7000/25169] Loss: 0.539329 Loss_avg: 0.405140 LR: 0.00019925 Loss Fine: 0.539329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:26:17,730 - trainer - INFO] - Train Epoch:[18/30] Step:[8000/25169] Loss: 0.438353 Loss_avg: 0.405446 LR: 0.00019821 Loss Fine: 0.438353 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:29:37,955 - trainer - INFO] - Train Epoch:[18/30] Step:[9000/25169] Loss: 0.473283 Loss_avg: 0.405728 LR: 0.00019717 Loss Fine: 0.473283 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:29:43,441 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[9000/25169] Word_acc: 0.914155 Word_acc_case_ins 0.914155 Edit_distance_acc: 0.969006
[2025-01-24 07:29:43,755 - trainer - INFO] - Saving current best (at 18 epoch): model_best.pth Best word_acc: 0.914155
[2025-01-24 07:33:03,885 - trainer - INFO] - Train Epoch:[18/30] Step:[10000/25169] Loss: 0.398787 Loss_avg: 0.405728 LR: 0.00019612 Loss Fine: 0.398787 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:36:24,013 - trainer - INFO] - Train Epoch:[18/30] Step:[11000/25169] Loss: 0.403276 Loss_avg: 0.406003 LR: 0.00019508 Loss Fine: 0.403276 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:39:44,177 - trainer - INFO] - Train Epoch:[18/30] Step:[12000/25169] Loss: 0.326107 Loss_avg: 0.405814 LR: 0.00019404 Loss Fine: 0.326107 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:39:49,710 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[12000/25169] Word_acc: 0.913372 Word_acc_case_ins 0.913372 Edit_distance_acc: 0.969227
[2025-01-24 07:43:09,887 - trainer - INFO] - Train Epoch:[18/30] Step:[13000/25169] Loss: 0.698825 Loss_avg: 0.406209 LR: 0.00019300 Loss Fine: 0.698825 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:46:29,973 - trainer - INFO] - Train Epoch:[18/30] Step:[14000/25169] Loss: 0.321871 Loss_avg: 0.406258 LR: 0.00019197 Loss Fine: 0.321871 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:49:50,079 - trainer - INFO] - Train Epoch:[18/30] Step:[15000/25169] Loss: 0.486308 Loss_avg: 0.406141 LR: 0.00019093 Loss Fine: 0.486308 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:49:55,581 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[15000/25169] Word_acc: 0.913894 Word_acc_case_ins 0.913894 Edit_distance_acc: 0.969203
[2025-01-24 07:53:15,803 - trainer - INFO] - Train Epoch:[18/30] Step:[16000/25169] Loss: 0.429119 Loss_avg: 0.406428 LR: 0.00018989 Loss Fine: 0.429119 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:56:36,015 - trainer - INFO] - Train Epoch:[18/30] Step:[17000/25169] Loss: 0.339417 Loss_avg: 0.406250 LR: 0.00018886 Loss Fine: 0.339417 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 07:59:56,299 - trainer - INFO] - Train Epoch:[18/30] Step:[18000/25169] Loss: 0.223060 Loss_avg: 0.406182 LR: 0.00018782 Loss Fine: 0.223060 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:00:01,798 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[18000/25169] Word_acc: 0.911285 Word_acc_case_ins 0.911285 Edit_distance_acc: 0.969178
[2025-01-24 08:03:21,982 - trainer - INFO] - Train Epoch:[18/30] Step:[19000/25169] Loss: 0.358018 Loss_avg: 0.405731 LR: 0.00018679 Loss Fine: 0.358018 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:06:42,131 - trainer - INFO] - Train Epoch:[18/30] Step:[20000/25169] Loss: 0.328035 Loss_avg: 0.405335 LR: 0.00018576 Loss Fine: 0.328035 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:10:02,268 - trainer - INFO] - Train Epoch:[18/30] Step:[21000/25169] Loss: 0.496174 Loss_avg: 0.405131 LR: 0.00018473 Loss Fine: 0.496174 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:10:07,775 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[21000/25169] Word_acc: 0.911676 Word_acc_case_ins 0.911676 Edit_distance_acc: 0.968540
[2025-01-24 08:13:27,924 - trainer - INFO] - Train Epoch:[18/30] Step:[22000/25169] Loss: 0.458159 Loss_avg: 0.404883 LR: 0.00018370 Loss Fine: 0.458159 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:16:48,052 - trainer - INFO] - Train Epoch:[18/30] Step:[23000/25169] Loss: 0.397659 Loss_avg: 0.404616 LR: 0.00018267 Loss Fine: 0.397659 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:20:08,245 - trainer - INFO] - Train Epoch:[18/30] Step:[24000/25169] Loss: 0.397929 Loss_avg: 0.404268 LR: 0.00018164 Loss Fine: 0.397929 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:20:13,723 - trainer - INFO] - [Step Validation] Epoch:[18/30] Step:[24000/25169] Word_acc: 0.914547 Word_acc_case_ins 0.914547 Edit_distance_acc: 0.967827
[2025-01-24 08:20:14,065 - trainer - INFO] - Saving current best (at 18 epoch): model_best.pth Best word_acc: 0.914547
[2025-01-24 08:23:34,196 - trainer - INFO] - Train Epoch:[18/30] Step:[25000/25169] Loss: 0.359282 Loss_avg: 0.404124 LR: 0.00018062 Loss Fine: 0.359282 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:24:13,706 - trainer - INFO] - [Epoch End] Epoch:[18/30] Loss: 0.404027 LR: 0.00018045
 Validation result after 18 epoch: Word_acc: 0.911937 Word_acc_case_ins: 0.911937 Edit_distance_acc: 0.968515
[2025-01-24 08:24:15,131 - trainer - INFO] - Train Epoch:[19/30] Step:[1/25169] Loss: 0.380539 Loss_avg: 0.380539 LR: 0.00018044 Loss Fine: 0.380539 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:27:35,153 - trainer - INFO] - Train Epoch:[19/30] Step:[1000/25169] Loss: 0.484794 Loss_avg: 0.389655 LR: 0.00017942 Loss Fine: 0.484794 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:30:55,266 - trainer - INFO] - Train Epoch:[19/30] Step:[2000/25169] Loss: 0.281772 Loss_avg: 0.392238 LR: 0.00017840 Loss Fine: 0.281772 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:34:15,511 - trainer - INFO] - Train Epoch:[19/30] Step:[3000/25169] Loss: 0.279824 Loss_avg: 0.391804 LR: 0.00017738 Loss Fine: 0.279824 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:34:21,011 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[3000/25169] Word_acc: 0.914025 Word_acc_case_ins 0.914025 Edit_distance_acc: 0.968294
[2025-01-24 08:37:41,112 - trainer - INFO] - Train Epoch:[19/30] Step:[4000/25169] Loss: 0.290177 Loss_avg: 0.390626 LR: 0.00017636 Loss Fine: 0.290177 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:41:01,235 - trainer - INFO] - Train Epoch:[19/30] Step:[5000/25169] Loss: 0.517718 Loss_avg: 0.391952 LR: 0.00017534 Loss Fine: 0.517718 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:44:21,342 - trainer - INFO] - Train Epoch:[19/30] Step:[6000/25169] Loss: 0.351555 Loss_avg: 0.391390 LR: 0.00017432 Loss Fine: 0.351555 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:44:26,825 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[6000/25169] Word_acc: 0.919113 Word_acc_case_ins 0.919113 Edit_distance_acc: 0.970087
[2025-01-24 08:44:27,146 - trainer - INFO] - Saving current best (at 19 epoch): model_best.pth Best word_acc: 0.919113
[2025-01-24 08:47:47,313 - trainer - INFO] - Train Epoch:[19/30] Step:[7000/25169] Loss: 0.405490 Loss_avg: 0.391580 LR: 0.00017331 Loss Fine: 0.405490 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:51:07,469 - trainer - INFO] - Train Epoch:[19/30] Step:[8000/25169] Loss: 0.381480 Loss_avg: 0.391848 LR: 0.00017229 Loss Fine: 0.381480 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:54:27,597 - trainer - INFO] - Train Epoch:[19/30] Step:[9000/25169] Loss: 0.299444 Loss_avg: 0.391938 LR: 0.00017128 Loss Fine: 0.299444 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 08:54:33,089 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[9000/25169] Word_acc: 0.917156 Word_acc_case_ins 0.917156 Edit_distance_acc: 0.970087
[2025-01-24 08:57:53,223 - trainer - INFO] - Train Epoch:[19/30] Step:[10000/25169] Loss: 0.319296 Loss_avg: 0.391907 LR: 0.00017027 Loss Fine: 0.319296 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:01:13,293 - trainer - INFO] - Train Epoch:[19/30] Step:[11000/25169] Loss: 0.281984 Loss_avg: 0.391852 LR: 0.00016925 Loss Fine: 0.281984 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:04:33,461 - trainer - INFO] - Train Epoch:[19/30] Step:[12000/25169] Loss: 0.317690 Loss_avg: 0.392031 LR: 0.00016825 Loss Fine: 0.317690 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:04:38,984 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[12000/25169] Word_acc: 0.911676 Word_acc_case_ins 0.911676 Edit_distance_acc: 0.968220
[2025-01-24 09:07:59,127 - trainer - INFO] - Train Epoch:[19/30] Step:[13000/25169] Loss: 0.268025 Loss_avg: 0.392090 LR: 0.00016724 Loss Fine: 0.268025 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:11:19,226 - trainer - INFO] - Train Epoch:[19/30] Step:[14000/25169] Loss: 0.240613 Loss_avg: 0.392223 LR: 0.00016623 Loss Fine: 0.240613 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:14:39,376 - trainer - INFO] - Train Epoch:[19/30] Step:[15000/25169] Loss: 0.287116 Loss_avg: 0.392243 LR: 0.00016523 Loss Fine: 0.287116 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:14:44,835 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[15000/25169] Word_acc: 0.917678 Word_acc_case_ins 0.917678 Edit_distance_acc: 0.970087
[2025-01-24 09:18:05,034 - trainer - INFO] - Train Epoch:[19/30] Step:[16000/25169] Loss: 0.516362 Loss_avg: 0.392077 LR: 0.00016423 Loss Fine: 0.516362 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:21:25,130 - trainer - INFO] - Train Epoch:[19/30] Step:[17000/25169] Loss: 0.352872 Loss_avg: 0.391589 LR: 0.00016322 Loss Fine: 0.352872 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:24:45,248 - trainer - INFO] - Train Epoch:[19/30] Step:[18000/25169] Loss: 0.250867 Loss_avg: 0.391680 LR: 0.00016222 Loss Fine: 0.250867 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:24:50,754 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[18000/25169] Word_acc: 0.916504 Word_acc_case_ins 0.916504 Edit_distance_acc: 0.970013
[2025-01-24 09:28:10,991 - trainer - INFO] - Train Epoch:[19/30] Step:[19000/25169] Loss: 0.389753 Loss_avg: 0.391409 LR: 0.00016123 Loss Fine: 0.389753 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:31:31,254 - trainer - INFO] - Train Epoch:[19/30] Step:[20000/25169] Loss: 0.427893 Loss_avg: 0.391434 LR: 0.00016023 Loss Fine: 0.427893 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:34:51,461 - trainer - INFO] - Train Epoch:[19/30] Step:[21000/25169] Loss: 0.298600 Loss_avg: 0.391136 LR: 0.00015923 Loss Fine: 0.298600 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:34:56,978 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[21000/25169] Word_acc: 0.916634 Word_acc_case_ins 0.916634 Edit_distance_acc: 0.969522
[2025-01-24 09:38:17,279 - trainer - INFO] - Train Epoch:[19/30] Step:[22000/25169] Loss: 0.245537 Loss_avg: 0.391040 LR: 0.00015824 Loss Fine: 0.245537 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:41:37,484 - trainer - INFO] - Train Epoch:[19/30] Step:[23000/25169] Loss: 0.309096 Loss_avg: 0.390830 LR: 0.00015725 Loss Fine: 0.309096 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:44:57,873 - trainer - INFO] - Train Epoch:[19/30] Step:[24000/25169] Loss: 0.421203 Loss_avg: 0.390649 LR: 0.00015626 Loss Fine: 0.421203 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:45:03,376 - trainer - INFO] - [Step Validation] Epoch:[19/30] Step:[24000/25169] Word_acc: 0.919504 Word_acc_case_ins 0.919504 Edit_distance_acc: 0.971315
[2025-01-24 09:45:03,706 - trainer - INFO] - Saving current best (at 19 epoch): model_best.pth Best word_acc: 0.919504
[2025-01-24 09:48:28,375 - trainer - INFO] - Train Epoch:[19/30] Step:[25000/25169] Loss: 0.423395 Loss_avg: 0.390459 LR: 0.00015527 Loss Fine: 0.423395 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:49:07,942 - trainer - INFO] - [Epoch End] Epoch:[19/30] Loss: 0.390392 LR: 0.00015511
 Validation result after 19 epoch: Word_acc: 0.915199 Word_acc_case_ins: 0.915199 Edit_distance_acc: 0.969841
[2025-01-24 09:49:09,535 - trainer - INFO] - Train Epoch:[20/30] Step:[1/25169] Loss: 0.339358 Loss_avg: 0.339358 LR: 0.00015510 Loss Fine: 0.339358 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:52:29,577 - trainer - INFO] - Train Epoch:[20/30] Step:[1000/25169] Loss: 0.410876 Loss_avg: 0.371573 LR: 0.00015412 Loss Fine: 0.410876 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:55:49,721 - trainer - INFO] - Train Epoch:[20/30] Step:[2000/25169] Loss: 0.387866 Loss_avg: 0.377801 LR: 0.00015313 Loss Fine: 0.387866 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:59:09,850 - trainer - INFO] - Train Epoch:[20/30] Step:[3000/25169] Loss: 0.413474 Loss_avg: 0.377889 LR: 0.00015215 Loss Fine: 0.413474 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 09:59:15,427 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[3000/25169] Word_acc: 0.916112 Word_acc_case_ins 0.916112 Edit_distance_acc: 0.970554
[2025-01-24 10:02:35,462 - trainer - INFO] - Train Epoch:[20/30] Step:[4000/25169] Loss: 0.367236 Loss_avg: 0.377218 LR: 0.00015117 Loss Fine: 0.367236 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:05:55,589 - trainer - INFO] - Train Epoch:[20/30] Step:[5000/25169] Loss: 0.405730 Loss_avg: 0.378215 LR: 0.00015019 Loss Fine: 0.405730 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:09:15,630 - trainer - INFO] - Train Epoch:[20/30] Step:[6000/25169] Loss: 0.354708 Loss_avg: 0.377685 LR: 0.00014922 Loss Fine: 0.354708 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:09:21,207 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[6000/25169] Word_acc: 0.920026 Word_acc_case_ins 0.920026 Edit_distance_acc: 0.970848
[2025-01-24 10:09:21,547 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.920026
[2025-01-24 10:12:41,760 - trainer - INFO] - Train Epoch:[20/30] Step:[7000/25169] Loss: 0.456375 Loss_avg: 0.378294 LR: 0.00014824 Loss Fine: 0.456375 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:16:01,993 - trainer - INFO] - Train Epoch:[20/30] Step:[8000/25169] Loss: 0.314568 Loss_avg: 0.378101 LR: 0.00014727 Loss Fine: 0.314568 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:19:22,272 - trainer - INFO] - Train Epoch:[20/30] Step:[9000/25169] Loss: 0.550145 Loss_avg: 0.378424 LR: 0.00014629 Loss Fine: 0.550145 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:19:27,808 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[9000/25169] Word_acc: 0.919374 Word_acc_case_ins 0.919374 Edit_distance_acc: 0.971487
[2025-01-24 10:22:47,965 - trainer - INFO] - Train Epoch:[20/30] Step:[10000/25169] Loss: 0.269986 Loss_avg: 0.378225 LR: 0.00014532 Loss Fine: 0.269986 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:26:08,073 - trainer - INFO] - Train Epoch:[20/30] Step:[11000/25169] Loss: 0.470939 Loss_avg: 0.378504 LR: 0.00014436 Loss Fine: 0.470939 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:29:28,155 - trainer - INFO] - Train Epoch:[20/30] Step:[12000/25169] Loss: 0.518183 Loss_avg: 0.378445 LR: 0.00014339 Loss Fine: 0.518183 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:29:33,696 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[12000/25169] Word_acc: 0.923027 Word_acc_case_ins 0.923027 Edit_distance_acc: 0.973059
[2025-01-24 10:29:34,008 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.923027
[2025-01-24 10:32:54,142 - trainer - INFO] - Train Epoch:[20/30] Step:[13000/25169] Loss: 0.305349 Loss_avg: 0.378336 LR: 0.00014243 Loss Fine: 0.305349 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:36:14,228 - trainer - INFO] - Train Epoch:[20/30] Step:[14000/25169] Loss: 0.299247 Loss_avg: 0.378794 LR: 0.00014146 Loss Fine: 0.299247 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:39:34,333 - trainer - INFO] - Train Epoch:[20/30] Step:[15000/25169] Loss: 0.443323 Loss_avg: 0.378805 LR: 0.00014050 Loss Fine: 0.443323 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:39:39,843 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[15000/25169] Word_acc: 0.918721 Word_acc_case_ins 0.918721 Edit_distance_acc: 0.971266
[2025-01-24 10:43:00,008 - trainer - INFO] - Train Epoch:[20/30] Step:[16000/25169] Loss: 0.489901 Loss_avg: 0.378528 LR: 0.00013955 Loss Fine: 0.489901 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:46:20,101 - trainer - INFO] - Train Epoch:[20/30] Step:[17000/25169] Loss: 0.525587 Loss_avg: 0.378486 LR: 0.00013859 Loss Fine: 0.525587 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:49:40,168 - trainer - INFO] - Train Epoch:[20/30] Step:[18000/25169] Loss: 0.305443 Loss_avg: 0.378496 LR: 0.00013764 Loss Fine: 0.305443 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:49:45,743 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[18000/25169] Word_acc: 0.918330 Word_acc_case_ins 0.918330 Edit_distance_acc: 0.971560
[2025-01-24 10:53:05,887 - trainer - INFO] - Train Epoch:[20/30] Step:[19000/25169] Loss: 0.463243 Loss_avg: 0.378433 LR: 0.00013668 Loss Fine: 0.463243 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:56:25,970 - trainer - INFO] - Train Epoch:[20/30] Step:[20000/25169] Loss: 0.312096 Loss_avg: 0.378389 LR: 0.00013573 Loss Fine: 0.312096 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:59:46,068 - trainer - INFO] - Train Epoch:[20/30] Step:[21000/25169] Loss: 0.503064 Loss_avg: 0.377938 LR: 0.00013479 Loss Fine: 0.503064 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 10:59:51,628 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[21000/25169] Word_acc: 0.917939 Word_acc_case_ins 0.917939 Edit_distance_acc: 0.970824
[2025-01-24 11:03:11,776 - trainer - INFO] - Train Epoch:[20/30] Step:[22000/25169] Loss: 0.365483 Loss_avg: 0.377923 LR: 0.00013384 Loss Fine: 0.365483 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:06:31,862 - trainer - INFO] - Train Epoch:[20/30] Step:[23000/25169] Loss: 0.339861 Loss_avg: 0.377783 LR: 0.00013290 Loss Fine: 0.339861 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:09:52,030 - trainer - INFO] - Train Epoch:[20/30] Step:[24000/25169] Loss: 0.460281 Loss_avg: 0.377897 LR: 0.00013196 Loss Fine: 0.460281 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:09:57,558 - trainer - INFO] - [Step Validation] Epoch:[20/30] Step:[24000/25169] Word_acc: 0.923027 Word_acc_case_ins 0.923027 Edit_distance_acc: 0.972518
[2025-01-24 11:09:57,872 - trainer - INFO] - Saving current best (at 20 epoch): model_best.pth Best word_acc: 0.923027
[2025-01-24 11:13:18,003 - trainer - INFO] - Train Epoch:[20/30] Step:[25000/25169] Loss: 0.351668 Loss_avg: 0.377943 LR: 0.00013102 Loss Fine: 0.351668 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:13:57,530 - trainer - INFO] - [Epoch End] Epoch:[20/30] Loss: 0.377829 LR: 0.00013086
 Validation result after 20 epoch: Word_acc: 0.920809 Word_acc_case_ins: 0.920809 Edit_distance_acc: 0.973280
[2025-01-24 11:13:59,185 - trainer - INFO] - Train Epoch:[21/30] Step:[1/25169] Loss: 0.229504 Loss_avg: 0.229504 LR: 0.00013086 Loss Fine: 0.229504 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:17:19,228 - trainer - INFO] - Train Epoch:[21/30] Step:[1000/25169] Loss: 0.446359 Loss_avg: 0.366268 LR: 0.00012992 Loss Fine: 0.446359 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:20:39,464 - trainer - INFO] - Train Epoch:[21/30] Step:[2000/25169] Loss: 0.384778 Loss_avg: 0.370019 LR: 0.00012899 Loss Fine: 0.384778 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:23:59,675 - trainer - INFO] - Train Epoch:[21/30] Step:[3000/25169] Loss: 0.349531 Loss_avg: 0.369855 LR: 0.00012805 Loss Fine: 0.349531 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:24:05,237 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[3000/25169] Word_acc: 0.920287 Word_acc_case_ins 0.920287 Edit_distance_acc: 0.972199
[2025-01-24 11:27:25,352 - trainer - INFO] - Train Epoch:[21/30] Step:[4000/25169] Loss: 0.349238 Loss_avg: 0.367890 LR: 0.00012712 Loss Fine: 0.349238 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:30:45,449 - trainer - INFO] - Train Epoch:[21/30] Step:[5000/25169] Loss: 0.355837 Loss_avg: 0.368028 LR: 0.00012620 Loss Fine: 0.355837 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:34:05,612 - trainer - INFO] - Train Epoch:[21/30] Step:[6000/25169] Loss: 0.335847 Loss_avg: 0.368475 LR: 0.00012527 Loss Fine: 0.335847 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:34:11,174 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[6000/25169] Word_acc: 0.923679 Word_acc_case_ins 0.923679 Edit_distance_acc: 0.972862
[2025-01-24 11:34:11,507 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.923679
[2025-01-24 11:37:31,716 - trainer - INFO] - Train Epoch:[21/30] Step:[7000/25169] Loss: 0.354514 Loss_avg: 0.368294 LR: 0.00012435 Loss Fine: 0.354514 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:40:51,804 - trainer - INFO] - Train Epoch:[21/30] Step:[8000/25169] Loss: 0.370786 Loss_avg: 0.367827 LR: 0.00012343 Loss Fine: 0.370786 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:44:11,940 - trainer - INFO] - Train Epoch:[21/30] Step:[9000/25169] Loss: 0.360094 Loss_avg: 0.369084 LR: 0.00012251 Loss Fine: 0.360094 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:44:17,489 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[9000/25169] Word_acc: 0.922244 Word_acc_case_ins 0.922244 Edit_distance_acc: 0.972150
[2025-01-24 11:47:37,574 - trainer - INFO] - Train Epoch:[21/30] Step:[10000/25169] Loss: 0.213842 Loss_avg: 0.368334 LR: 0.00012159 Loss Fine: 0.213842 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:50:57,686 - trainer - INFO] - Train Epoch:[21/30] Step:[11000/25169] Loss: 0.356050 Loss_avg: 0.368360 LR: 0.00012068 Loss Fine: 0.356050 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:54:17,777 - trainer - INFO] - Train Epoch:[21/30] Step:[12000/25169] Loss: 0.477760 Loss_avg: 0.368054 LR: 0.00011976 Loss Fine: 0.477760 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 11:54:23,330 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[12000/25169] Word_acc: 0.918200 Word_acc_case_ins 0.918200 Edit_distance_acc: 0.971511
[2025-01-24 11:57:43,377 - trainer - INFO] - Train Epoch:[21/30] Step:[13000/25169] Loss: 0.424942 Loss_avg: 0.368283 LR: 0.00011886 Loss Fine: 0.424942 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:01:03,489 - trainer - INFO] - Train Epoch:[21/30] Step:[14000/25169] Loss: 0.266034 Loss_avg: 0.367929 LR: 0.00011795 Loss Fine: 0.266034 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:04:23,659 - trainer - INFO] - Train Epoch:[21/30] Step:[15000/25169] Loss: 0.252369 Loss_avg: 0.367390 LR: 0.00011704 Loss Fine: 0.252369 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:04:29,206 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[15000/25169] Word_acc: 0.921853 Word_acc_case_ins 0.921853 Edit_distance_acc: 0.973304
[2025-01-24 12:07:49,446 - trainer - INFO] - Train Epoch:[21/30] Step:[16000/25169] Loss: 0.332096 Loss_avg: 0.367236 LR: 0.00011614 Loss Fine: 0.332096 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:11:09,643 - trainer - INFO] - Train Epoch:[21/30] Step:[17000/25169] Loss: 0.457472 Loss_avg: 0.366991 LR: 0.00011524 Loss Fine: 0.457472 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:14:29,891 - trainer - INFO] - Train Epoch:[21/30] Step:[18000/25169] Loss: 0.279133 Loss_avg: 0.366925 LR: 0.00011434 Loss Fine: 0.279133 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:14:35,451 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[18000/25169] Word_acc: 0.925114 Word_acc_case_ins 0.925114 Edit_distance_acc: 0.972887
[2025-01-24 12:14:35,753 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.925114
[2025-01-24 12:17:55,855 - trainer - INFO] - Train Epoch:[21/30] Step:[19000/25169] Loss: 0.256202 Loss_avg: 0.366822 LR: 0.00011345 Loss Fine: 0.256202 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:21:15,928 - trainer - INFO] - Train Epoch:[21/30] Step:[20000/25169] Loss: 0.391612 Loss_avg: 0.366535 LR: 0.00011256 Loss Fine: 0.391612 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:24:36,069 - trainer - INFO] - Train Epoch:[21/30] Step:[21000/25169] Loss: 0.320445 Loss_avg: 0.366334 LR: 0.00011167 Loss Fine: 0.320445 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:24:41,595 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[21000/25169] Word_acc: 0.922374 Word_acc_case_ins 0.922374 Edit_distance_acc: 0.973009
[2025-01-24 12:28:01,730 - trainer - INFO] - Train Epoch:[21/30] Step:[22000/25169] Loss: 0.313774 Loss_avg: 0.365995 LR: 0.00011078 Loss Fine: 0.313774 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:31:21,833 - trainer - INFO] - Train Epoch:[21/30] Step:[23000/25169] Loss: 0.322991 Loss_avg: 0.365766 LR: 0.00010989 Loss Fine: 0.322991 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:34:42,022 - trainer - INFO] - Train Epoch:[21/30] Step:[24000/25169] Loss: 0.230170 Loss_avg: 0.365747 LR: 0.00010901 Loss Fine: 0.230170 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:34:47,603 - trainer - INFO] - [Step Validation] Epoch:[21/30] Step:[24000/25169] Word_acc: 0.925114 Word_acc_case_ins 0.925114 Edit_distance_acc: 0.973943
[2025-01-24 12:34:47,920 - trainer - INFO] - Saving current best (at 21 epoch): model_best.pth Best word_acc: 0.925114
[2025-01-24 12:38:08,015 - trainer - INFO] - Train Epoch:[21/30] Step:[25000/25169] Loss: 0.294336 Loss_avg: 0.365242 LR: 0.00010813 Loss Fine: 0.294336 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:38:47,584 - trainer - INFO] - [Epoch End] Epoch:[21/30] Loss: 0.365169 LR: 0.00010798
 Validation result after 21 epoch: Word_acc: 0.922766 Word_acc_case_ins: 0.922766 Edit_distance_acc: 0.972297
[2025-01-24 12:38:49,129 - trainer - INFO] - Train Epoch:[22/30] Step:[1/25169] Loss: 0.337014 Loss_avg: 0.337014 LR: 0.00010798 Loss Fine: 0.337014 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:42:09,202 - trainer - INFO] - Train Epoch:[22/30] Step:[1000/25169] Loss: 0.311362 Loss_avg: 0.355709 LR: 0.00010711 Loss Fine: 0.311362 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:45:29,391 - trainer - INFO] - Train Epoch:[22/30] Step:[2000/25169] Loss: 0.356233 Loss_avg: 0.355055 LR: 0.00010623 Loss Fine: 0.356233 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:48:49,497 - trainer - INFO] - Train Epoch:[22/30] Step:[3000/25169] Loss: 0.311500 Loss_avg: 0.355683 LR: 0.00010536 Loss Fine: 0.311500 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:48:55,029 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[3000/25169] Word_acc: 0.927332 Word_acc_case_ins 0.927332 Edit_distance_acc: 0.973967
[2025-01-24 12:48:55,347 - trainer - INFO] - Saving current best (at 22 epoch): model_best.pth Best word_acc: 0.927332
[2025-01-24 12:52:15,498 - trainer - INFO] - Train Epoch:[22/30] Step:[4000/25169] Loss: 0.337332 Loss_avg: 0.354816 LR: 0.00010449 Loss Fine: 0.337332 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:55:35,729 - trainer - INFO] - Train Epoch:[22/30] Step:[5000/25169] Loss: 0.283930 Loss_avg: 0.354954 LR: 0.00010363 Loss Fine: 0.283930 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:58:55,946 - trainer - INFO] - Train Epoch:[22/30] Step:[6000/25169] Loss: 0.355850 Loss_avg: 0.355420 LR: 0.00010276 Loss Fine: 0.355850 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 12:59:01,477 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[6000/25169] Word_acc: 0.926941 Word_acc_case_ins 0.926941 Edit_distance_acc: 0.973673
[2025-01-24 13:02:21,561 - trainer - INFO] - Train Epoch:[22/30] Step:[7000/25169] Loss: 0.327392 Loss_avg: 0.354944 LR: 0.00010190 Loss Fine: 0.327392 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:05:41,690 - trainer - INFO] - Train Epoch:[22/30] Step:[8000/25169] Loss: 0.295386 Loss_avg: 0.354767 LR: 0.00010104 Loss Fine: 0.295386 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:09:01,787 - trainer - INFO] - Train Epoch:[22/30] Step:[9000/25169] Loss: 0.468331 Loss_avg: 0.355251 LR: 0.00010019 Loss Fine: 0.468331 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:09:07,313 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[9000/25169] Word_acc: 0.924462 Word_acc_case_ins 0.924462 Edit_distance_acc: 0.974262
[2025-01-24 13:12:27,429 - trainer - INFO] - Train Epoch:[22/30] Step:[10000/25169] Loss: 0.316826 Loss_avg: 0.354527 LR: 0.00009934 Loss Fine: 0.316826 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:15:47,581 - trainer - INFO] - Train Epoch:[22/30] Step:[11000/25169] Loss: 0.481756 Loss_avg: 0.354320 LR: 0.00009849 Loss Fine: 0.481756 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:19:07,652 - trainer - INFO] - Train Epoch:[22/30] Step:[12000/25169] Loss: 0.313005 Loss_avg: 0.353799 LR: 0.00009764 Loss Fine: 0.313005 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:19:13,216 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[12000/25169] Word_acc: 0.926810 Word_acc_case_ins 0.926810 Edit_distance_acc: 0.974974
[2025-01-24 13:22:33,352 - trainer - INFO] - Train Epoch:[22/30] Step:[13000/25169] Loss: 0.216362 Loss_avg: 0.353446 LR: 0.00009680 Loss Fine: 0.216362 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:25:53,488 - trainer - INFO] - Train Epoch:[22/30] Step:[14000/25169] Loss: 0.284707 Loss_avg: 0.352963 LR: 0.00009595 Loss Fine: 0.284707 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:29:13,682 - trainer - INFO] - Train Epoch:[22/30] Step:[15000/25169] Loss: 0.432051 Loss_avg: 0.352466 LR: 0.00009511 Loss Fine: 0.432051 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:29:19,254 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[15000/25169] Word_acc: 0.929028 Word_acc_case_ins 0.929028 Edit_distance_acc: 0.974409
[2025-01-24 13:29:19,576 - trainer - INFO] - Saving current best (at 22 epoch): model_best.pth Best word_acc: 0.929028
[2025-01-24 13:32:39,658 - trainer - INFO] - Train Epoch:[22/30] Step:[16000/25169] Loss: 0.358185 Loss_avg: 0.352398 LR: 0.00009428 Loss Fine: 0.358185 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:36:04,882 - trainer - INFO] - Train Epoch:[22/30] Step:[17000/25169] Loss: 0.355672 Loss_avg: 0.352150 LR: 0.00009345 Loss Fine: 0.355672 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:39:24,962 - trainer - INFO] - Train Epoch:[22/30] Step:[18000/25169] Loss: 0.246597 Loss_avg: 0.352177 LR: 0.00009262 Loss Fine: 0.246597 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:39:30,501 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[18000/25169] Word_acc: 0.927723 Word_acc_case_ins 0.927723 Edit_distance_acc: 0.974827
[2025-01-24 13:42:50,666 - trainer - INFO] - Train Epoch:[22/30] Step:[19000/25169] Loss: 0.298096 Loss_avg: 0.351788 LR: 0.00009179 Loss Fine: 0.298096 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:46:10,809 - trainer - INFO] - Train Epoch:[22/30] Step:[20000/25169] Loss: 0.291579 Loss_avg: 0.351450 LR: 0.00009096 Loss Fine: 0.291579 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:49:30,894 - trainer - INFO] - Train Epoch:[22/30] Step:[21000/25169] Loss: 0.311846 Loss_avg: 0.351170 LR: 0.00009014 Loss Fine: 0.311846 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:49:36,418 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[21000/25169] Word_acc: 0.930855 Word_acc_case_ins 0.930855 Edit_distance_acc: 0.975490
[2025-01-24 13:49:36,720 - trainer - INFO] - Saving current best (at 22 epoch): model_best.pth Best word_acc: 0.930855
[2025-01-24 13:52:56,899 - trainer - INFO] - Train Epoch:[22/30] Step:[22000/25169] Loss: 0.388745 Loss_avg: 0.350854 LR: 0.00008932 Loss Fine: 0.388745 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:56:17,034 - trainer - INFO] - Train Epoch:[22/30] Step:[23000/25169] Loss: 0.368133 Loss_avg: 0.350834 LR: 0.00008851 Loss Fine: 0.368133 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:59:37,197 - trainer - INFO] - Train Epoch:[22/30] Step:[24000/25169] Loss: 0.360425 Loss_avg: 0.350447 LR: 0.00008769 Loss Fine: 0.360425 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 13:59:42,779 - trainer - INFO] - [Step Validation] Epoch:[22/30] Step:[24000/25169] Word_acc: 0.928115 Word_acc_case_ins 0.928115 Edit_distance_acc: 0.974999
[2025-01-24 14:03:03,014 - trainer - INFO] - Train Epoch:[22/30] Step:[25000/25169] Loss: 0.231717 Loss_avg: 0.350190 LR: 0.00008688 Loss Fine: 0.231717 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:03:42,706 - trainer - INFO] - [Epoch End] Epoch:[22/30] Loss: 0.350147 LR: 0.00008675
 Validation result after 22 epoch: Word_acc: 0.927462 Word_acc_case_ins: 0.927462 Edit_distance_acc: 0.975367
[2025-01-24 14:03:44,231 - trainer - INFO] - Train Epoch:[23/30] Step:[1/25169] Loss: 0.438353 Loss_avg: 0.438353 LR: 0.00008675 Loss Fine: 0.438353 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:07:04,310 - trainer - INFO] - Train Epoch:[23/30] Step:[1000/25169] Loss: 0.290453 Loss_avg: 0.339489 LR: 0.00008594 Loss Fine: 0.290453 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:10:24,545 - trainer - INFO] - Train Epoch:[23/30] Step:[2000/25169] Loss: 0.245696 Loss_avg: 0.340059 LR: 0.00008514 Loss Fine: 0.245696 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:13:44,720 - trainer - INFO] - Train Epoch:[23/30] Step:[3000/25169] Loss: 0.394454 Loss_avg: 0.338997 LR: 0.00008434 Loss Fine: 0.394454 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:13:50,274 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[3000/25169] Word_acc: 0.927854 Word_acc_case_ins 0.927854 Edit_distance_acc: 0.973869
[2025-01-24 14:17:10,437 - trainer - INFO] - Train Epoch:[23/30] Step:[4000/25169] Loss: 0.307669 Loss_avg: 0.338331 LR: 0.00008354 Loss Fine: 0.307669 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:20:30,582 - trainer - INFO] - Train Epoch:[23/30] Step:[5000/25169] Loss: 0.292101 Loss_avg: 0.337791 LR: 0.00008275 Loss Fine: 0.292101 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:23:50,674 - trainer - INFO] - Train Epoch:[23/30] Step:[6000/25169] Loss: 0.239894 Loss_avg: 0.337194 LR: 0.00008195 Loss Fine: 0.239894 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:23:56,238 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[6000/25169] Word_acc: 0.930985 Word_acc_case_ins 0.930985 Edit_distance_acc: 0.976030
[2025-01-24 14:23:56,570 - trainer - INFO] - Saving current best (at 23 epoch): model_best.pth Best word_acc: 0.930985
[2025-01-24 14:27:16,688 - trainer - INFO] - Train Epoch:[23/30] Step:[7000/25169] Loss: 0.404245 Loss_avg: 0.337593 LR: 0.00008117 Loss Fine: 0.404245 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:30:36,849 - trainer - INFO] - Train Epoch:[23/30] Step:[8000/25169] Loss: 0.528841 Loss_avg: 0.337786 LR: 0.00008038 Loss Fine: 0.528841 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:33:56,921 - trainer - INFO] - Train Epoch:[23/30] Step:[9000/25169] Loss: 0.238997 Loss_avg: 0.337690 LR: 0.00007960 Loss Fine: 0.238997 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:34:02,499 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[9000/25169] Word_acc: 0.929680 Word_acc_case_ins 0.929680 Edit_distance_acc: 0.974950
[2025-01-24 14:37:22,602 - trainer - INFO] - Train Epoch:[23/30] Step:[10000/25169] Loss: 0.425429 Loss_avg: 0.337761 LR: 0.00007882 Loss Fine: 0.425429 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:40:42,781 - trainer - INFO] - Train Epoch:[23/30] Step:[11000/25169] Loss: 0.367825 Loss_avg: 0.337789 LR: 0.00007804 Loss Fine: 0.367825 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:44:02,989 - trainer - INFO] - Train Epoch:[23/30] Step:[12000/25169] Loss: 0.333993 Loss_avg: 0.337604 LR: 0.00007727 Loss Fine: 0.333993 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:44:08,533 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[12000/25169] Word_acc: 0.929550 Word_acc_case_ins 0.929550 Edit_distance_acc: 0.975122
[2025-01-24 14:47:28,660 - trainer - INFO] - Train Epoch:[23/30] Step:[13000/25169] Loss: 0.397355 Loss_avg: 0.337456 LR: 0.00007650 Loss Fine: 0.397355 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:50:48,788 - trainer - INFO] - Train Epoch:[23/30] Step:[14000/25169] Loss: 0.362299 Loss_avg: 0.337279 LR: 0.00007573 Loss Fine: 0.362299 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:54:08,903 - trainer - INFO] - Train Epoch:[23/30] Step:[15000/25169] Loss: 0.387381 Loss_avg: 0.337116 LR: 0.00007497 Loss Fine: 0.387381 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 14:54:14,466 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[15000/25169] Word_acc: 0.929419 Word_acc_case_ins 0.929419 Edit_distance_acc: 0.975809
[2025-01-24 14:57:34,677 - trainer - INFO] - Train Epoch:[23/30] Step:[16000/25169] Loss: 0.292733 Loss_avg: 0.337240 LR: 0.00007421 Loss Fine: 0.292733 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:00:54,871 - trainer - INFO] - Train Epoch:[23/30] Step:[17000/25169] Loss: 0.350771 Loss_avg: 0.337102 LR: 0.00007345 Loss Fine: 0.350771 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:04:15,095 - trainer - INFO] - Train Epoch:[23/30] Step:[18000/25169] Loss: 0.320118 Loss_avg: 0.336757 LR: 0.00007270 Loss Fine: 0.320118 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:04:20,634 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[18000/25169] Word_acc: 0.929941 Word_acc_case_ins 0.929941 Edit_distance_acc: 0.975932
[2025-01-24 15:07:40,742 - trainer - INFO] - Train Epoch:[23/30] Step:[19000/25169] Loss: 0.266465 Loss_avg: 0.336597 LR: 0.00007195 Loss Fine: 0.266465 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:11:00,828 - trainer - INFO] - Train Epoch:[23/30] Step:[20000/25169] Loss: 0.253792 Loss_avg: 0.336325 LR: 0.00007120 Loss Fine: 0.253792 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:14:20,934 - trainer - INFO] - Train Epoch:[23/30] Step:[21000/25169] Loss: 0.266645 Loss_avg: 0.336323 LR: 0.00007046 Loss Fine: 0.266645 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:14:26,510 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[21000/25169] Word_acc: 0.932159 Word_acc_case_ins 0.932159 Edit_distance_acc: 0.975760
[2025-01-24 15:14:26,822 - trainer - INFO] - Saving current best (at 23 epoch): model_best.pth Best word_acc: 0.932159
[2025-01-24 15:17:46,994 - trainer - INFO] - Train Epoch:[23/30] Step:[22000/25169] Loss: 0.254160 Loss_avg: 0.336451 LR: 0.00006972 Loss Fine: 0.254160 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:21:07,154 - trainer - INFO] - Train Epoch:[23/30] Step:[23000/25169] Loss: 0.262697 Loss_avg: 0.336292 LR: 0.00006898 Loss Fine: 0.262697 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:24:27,324 - trainer - INFO] - Train Epoch:[23/30] Step:[24000/25169] Loss: 0.359532 Loss_avg: 0.335955 LR: 0.00006825 Loss Fine: 0.359532 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:24:32,859 - trainer - INFO] - [Step Validation] Epoch:[23/30] Step:[24000/25169] Word_acc: 0.929550 Word_acc_case_ins 0.929550 Edit_distance_acc: 0.975269
[2025-01-24 15:27:53,052 - trainer - INFO] - Train Epoch:[23/30] Step:[25000/25169] Loss: 0.283278 Loss_avg: 0.335710 LR: 0.00006751 Loss Fine: 0.283278 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:28:32,647 - trainer - INFO] - [Epoch End] Epoch:[23/30] Loss: 0.335652 LR: 0.00006739
 Validation result after 23 epoch: Word_acc: 0.930594 Word_acc_case_ins: 0.930594 Edit_distance_acc: 0.975539
[2025-01-24 15:28:34,282 - trainer - INFO] - Train Epoch:[24/30] Step:[1/25169] Loss: 0.241176 Loss_avg: 0.241176 LR: 0.00006739 Loss Fine: 0.241176 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:31:54,358 - trainer - INFO] - Train Epoch:[24/30] Step:[1000/25169] Loss: 0.246969 Loss_avg: 0.322016 LR: 0.00006666 Loss Fine: 0.246969 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:35:14,588 - trainer - INFO] - Train Epoch:[24/30] Step:[2000/25169] Loss: 0.360434 Loss_avg: 0.325130 LR: 0.00006594 Loss Fine: 0.360434 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:38:34,852 - trainer - INFO] - Train Epoch:[24/30] Step:[3000/25169] Loss: 0.338893 Loss_avg: 0.325994 LR: 0.00006522 Loss Fine: 0.338893 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:38:40,438 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[3000/25169] Word_acc: 0.934247 Word_acc_case_ins 0.934247 Edit_distance_acc: 0.977258
[2025-01-24 15:38:40,762 - trainer - INFO] - Saving current best (at 24 epoch): model_best.pth Best word_acc: 0.934247
[2025-01-24 15:42:00,998 - trainer - INFO] - Train Epoch:[24/30] Step:[4000/25169] Loss: 0.294969 Loss_avg: 0.326052 LR: 0.00006450 Loss Fine: 0.294969 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:45:21,220 - trainer - INFO] - Train Epoch:[24/30] Step:[5000/25169] Loss: 0.247430 Loss_avg: 0.324615 LR: 0.00006379 Loss Fine: 0.247430 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:48:41,408 - trainer - INFO] - Train Epoch:[24/30] Step:[6000/25169] Loss: 0.222770 Loss_avg: 0.323987 LR: 0.00006308 Loss Fine: 0.222770 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:48:46,974 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[6000/25169] Word_acc: 0.930463 Word_acc_case_ins 0.930463 Edit_distance_acc: 0.975539
[2025-01-24 15:52:07,124 - trainer - INFO] - Train Epoch:[24/30] Step:[7000/25169] Loss: 0.293563 Loss_avg: 0.323330 LR: 0.00006237 Loss Fine: 0.293563 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:55:27,243 - trainer - INFO] - Train Epoch:[24/30] Step:[8000/25169] Loss: 0.302081 Loss_avg: 0.323505 LR: 0.00006167 Loss Fine: 0.302081 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:58:47,381 - trainer - INFO] - Train Epoch:[24/30] Step:[9000/25169] Loss: 0.346924 Loss_avg: 0.323378 LR: 0.00006097 Loss Fine: 0.346924 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 15:58:52,981 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[9000/25169] Word_acc: 0.932942 Word_acc_case_ins 0.932942 Edit_distance_acc: 0.976595
[2025-01-24 16:02:13,060 - trainer - INFO] - Train Epoch:[24/30] Step:[10000/25169] Loss: 0.263306 Loss_avg: 0.323322 LR: 0.00006027 Loss Fine: 0.263306 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:05:33,226 - trainer - INFO] - Train Epoch:[24/30] Step:[11000/25169] Loss: 0.219647 Loss_avg: 0.323336 LR: 0.00005958 Loss Fine: 0.219647 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:08:53,359 - trainer - INFO] - Train Epoch:[24/30] Step:[12000/25169] Loss: 0.333184 Loss_avg: 0.323388 LR: 0.00005889 Loss Fine: 0.333184 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:08:58,952 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[12000/25169] Word_acc: 0.931507 Word_acc_case_ins 0.931507 Edit_distance_acc: 0.976276
[2025-01-24 16:12:19,086 - trainer - INFO] - Train Epoch:[24/30] Step:[13000/25169] Loss: 0.356516 Loss_avg: 0.323271 LR: 0.00005821 Loss Fine: 0.356516 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:15:39,288 - trainer - INFO] - Train Epoch:[24/30] Step:[14000/25169] Loss: 0.277281 Loss_avg: 0.323134 LR: 0.00005752 Loss Fine: 0.277281 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:18:59,458 - trainer - INFO] - Train Epoch:[24/30] Step:[15000/25169] Loss: 0.438405 Loss_avg: 0.323169 LR: 0.00005684 Loss Fine: 0.438405 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:19:05,011 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[15000/25169] Word_acc: 0.930724 Word_acc_case_ins 0.930724 Edit_distance_acc: 0.976178
[2025-01-24 16:22:25,192 - trainer - INFO] - Train Epoch:[24/30] Step:[16000/25169] Loss: 0.235153 Loss_avg: 0.322692 LR: 0.00005617 Loss Fine: 0.235153 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:25:45,344 - trainer - INFO] - Train Epoch:[24/30] Step:[17000/25169] Loss: 0.282031 Loss_avg: 0.322905 LR: 0.00005550 Loss Fine: 0.282031 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:29:05,444 - trainer - INFO] - Train Epoch:[24/30] Step:[18000/25169] Loss: 0.270715 Loss_avg: 0.322867 LR: 0.00005483 Loss Fine: 0.270715 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:29:11,020 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[18000/25169] Word_acc: 0.932811 Word_acc_case_ins 0.932811 Edit_distance_acc: 0.976890
[2025-01-24 16:32:31,156 - trainer - INFO] - Train Epoch:[24/30] Step:[19000/25169] Loss: 0.364730 Loss_avg: 0.322818 LR: 0.00005416 Loss Fine: 0.364730 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:35:51,269 - trainer - INFO] - Train Epoch:[24/30] Step:[20000/25169] Loss: 0.412168 Loss_avg: 0.322795 LR: 0.00005350 Loss Fine: 0.412168 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:39:11,411 - trainer - INFO] - Train Epoch:[24/30] Step:[21000/25169] Loss: 0.284411 Loss_avg: 0.322745 LR: 0.00005284 Loss Fine: 0.284411 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:39:17,009 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[21000/25169] Word_acc: 0.931898 Word_acc_case_ins 0.931898 Edit_distance_acc: 0.976890
[2025-01-24 16:42:37,204 - trainer - INFO] - Train Epoch:[24/30] Step:[22000/25169] Loss: 0.423952 Loss_avg: 0.322685 LR: 0.00005219 Loss Fine: 0.423952 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:45:57,361 - trainer - INFO] - Train Epoch:[24/30] Step:[23000/25169] Loss: 0.241735 Loss_avg: 0.322473 LR: 0.00005154 Loss Fine: 0.241735 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:49:17,496 - trainer - INFO] - Train Epoch:[24/30] Step:[24000/25169] Loss: 0.268156 Loss_avg: 0.322313 LR: 0.00005089 Loss Fine: 0.268156 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:49:23,106 - trainer - INFO] - [Step Validation] Epoch:[24/30] Step:[24000/25169] Word_acc: 0.933725 Word_acc_case_ins 0.933725 Edit_distance_acc: 0.977037
[2025-01-24 16:52:43,289 - trainer - INFO] - Train Epoch:[24/30] Step:[25000/25169] Loss: 0.450720 Loss_avg: 0.322112 LR: 0.00005025 Loss Fine: 0.450720 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:53:22,922 - trainer - INFO] - [Epoch End] Epoch:[24/30] Loss: 0.322100 LR: 0.00005014
 Validation result after 24 epoch: Word_acc: 0.933333 Word_acc_case_ins: 0.933333 Edit_distance_acc: 0.977258
[2025-01-24 16:53:24,518 - trainer - INFO] - Train Epoch:[25/30] Step:[1/25169] Loss: 0.309564 Loss_avg: 0.309564 LR: 0.00005014 Loss Fine: 0.309564 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 16:56:44,526 - trainer - INFO] - Train Epoch:[25/30] Step:[1000/25169] Loss: 0.274569 Loss_avg: 0.315108 LR: 0.00004950 Loss Fine: 0.274569 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:00:04,708 - trainer - INFO] - Train Epoch:[25/30] Step:[2000/25169] Loss: 0.527174 Loss_avg: 0.314687 LR: 0.00004887 Loss Fine: 0.527174 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:03:24,829 - trainer - INFO] - Train Epoch:[25/30] Step:[3000/25169] Loss: 0.250298 Loss_avg: 0.313846 LR: 0.00004823 Loss Fine: 0.250298 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:03:30,462 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[3000/25169] Word_acc: 0.934638 Word_acc_case_ins 0.934638 Edit_distance_acc: 0.976939
[2025-01-24 17:03:30,777 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.934638
[2025-01-24 17:06:50,872 - trainer - INFO] - Train Epoch:[25/30] Step:[4000/25169] Loss: 0.291337 Loss_avg: 0.312333 LR: 0.00004761 Loss Fine: 0.291337 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:10:10,957 - trainer - INFO] - Train Epoch:[25/30] Step:[5000/25169] Loss: 0.223794 Loss_avg: 0.311583 LR: 0.00004698 Loss Fine: 0.223794 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:13:31,025 - trainer - INFO] - Train Epoch:[25/30] Step:[6000/25169] Loss: 0.336532 Loss_avg: 0.311822 LR: 0.00004636 Loss Fine: 0.336532 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:13:36,591 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[6000/25169] Word_acc: 0.934247 Word_acc_case_ins 0.934247 Edit_distance_acc: 0.977258
[2025-01-24 17:16:56,803 - trainer - INFO] - Train Epoch:[25/30] Step:[7000/25169] Loss: 0.355728 Loss_avg: 0.311173 LR: 0.00004574 Loss Fine: 0.355728 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:20:17,032 - trainer - INFO] - Train Epoch:[25/30] Step:[8000/25169] Loss: 0.211040 Loss_avg: 0.311126 LR: 0.00004513 Loss Fine: 0.211040 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:23:37,200 - trainer - INFO] - Train Epoch:[25/30] Step:[9000/25169] Loss: 0.347239 Loss_avg: 0.310570 LR: 0.00004452 Loss Fine: 0.347239 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:23:42,760 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[9000/25169] Word_acc: 0.935682 Word_acc_case_ins 0.935682 Edit_distance_acc: 0.978069
[2025-01-24 17:23:43,064 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.935682
[2025-01-24 17:27:03,178 - trainer - INFO] - Train Epoch:[25/30] Step:[10000/25169] Loss: 0.338266 Loss_avg: 0.310731 LR: 0.00004392 Loss Fine: 0.338266 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:30:23,210 - trainer - INFO] - Train Epoch:[25/30] Step:[11000/25169] Loss: 0.331241 Loss_avg: 0.310508 LR: 0.00004331 Loss Fine: 0.331241 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:33:43,324 - trainer - INFO] - Train Epoch:[25/30] Step:[12000/25169] Loss: 0.214741 Loss_avg: 0.310243 LR: 0.00004272 Loss Fine: 0.214741 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:33:48,910 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[12000/25169] Word_acc: 0.934768 Word_acc_case_ins 0.934768 Edit_distance_acc: 0.977479
[2025-01-24 17:37:09,033 - trainer - INFO] - Train Epoch:[25/30] Step:[13000/25169] Loss: 0.346018 Loss_avg: 0.309960 LR: 0.00004212 Loss Fine: 0.346018 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:40:29,167 - trainer - INFO] - Train Epoch:[25/30] Step:[14000/25169] Loss: 0.273254 Loss_avg: 0.309966 LR: 0.00004153 Loss Fine: 0.273254 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:43:49,283 - trainer - INFO] - Train Epoch:[25/30] Step:[15000/25169] Loss: 0.389133 Loss_avg: 0.309995 LR: 0.00004094 Loss Fine: 0.389133 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:43:54,850 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[15000/25169] Word_acc: 0.935812 Word_acc_case_ins 0.935812 Edit_distance_acc: 0.977823
[2025-01-24 17:43:55,178 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.935812
[2025-01-24 17:47:15,277 - trainer - INFO] - Train Epoch:[25/30] Step:[16000/25169] Loss: 0.329480 Loss_avg: 0.309699 LR: 0.00004036 Loss Fine: 0.329480 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:50:35,332 - trainer - INFO] - Train Epoch:[25/30] Step:[17000/25169] Loss: 0.338992 Loss_avg: 0.309560 LR: 0.00003978 Loss Fine: 0.338992 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:53:55,428 - trainer - INFO] - Train Epoch:[25/30] Step:[18000/25169] Loss: 0.271153 Loss_avg: 0.309300 LR: 0.00003921 Loss Fine: 0.271153 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 17:54:00,993 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[18000/25169] Word_acc: 0.933072 Word_acc_case_ins 0.933072 Edit_distance_acc: 0.976595
[2025-01-24 17:57:27,014 - trainer - INFO] - Train Epoch:[25/30] Step:[19000/25169] Loss: 0.333211 Loss_avg: 0.309195 LR: 0.00003863 Loss Fine: 0.333211 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:00:47,098 - trainer - INFO] - Train Epoch:[25/30] Step:[20000/25169] Loss: 0.254565 Loss_avg: 0.308998 LR: 0.00003807 Loss Fine: 0.254565 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:04:07,288 - trainer - INFO] - Train Epoch:[25/30] Step:[21000/25169] Loss: 0.257262 Loss_avg: 0.308589 LR: 0.00003750 Loss Fine: 0.257262 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:04:12,845 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[21000/25169] Word_acc: 0.937247 Word_acc_case_ins 0.937247 Edit_distance_acc: 0.978486
[2025-01-24 18:04:13,147 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.937247
[2025-01-24 18:07:33,271 - trainer - INFO] - Train Epoch:[25/30] Step:[22000/25169] Loss: 0.317071 Loss_avg: 0.308303 LR: 0.00003694 Loss Fine: 0.317071 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:10:53,457 - trainer - INFO] - Train Epoch:[25/30] Step:[23000/25169] Loss: 0.321039 Loss_avg: 0.308088 LR: 0.00003639 Loss Fine: 0.321039 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:14:13,534 - trainer - INFO] - Train Epoch:[25/30] Step:[24000/25169] Loss: 0.269146 Loss_avg: 0.307976 LR: 0.00003583 Loss Fine: 0.269146 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:14:19,117 - trainer - INFO] - [Step Validation] Epoch:[25/30] Step:[24000/25169] Word_acc: 0.937378 Word_acc_case_ins 0.937378 Edit_distance_acc: 0.978462
[2025-01-24 18:14:19,430 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.937378
[2025-01-24 18:17:39,581 - trainer - INFO] - Train Epoch:[25/30] Step:[25000/25169] Loss: 0.268239 Loss_avg: 0.307863 LR: 0.00003528 Loss Fine: 0.268239 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:18:19,169 - trainer - INFO] - [Epoch End] Epoch:[25/30] Loss: 0.307830 LR: 0.00003519
 Validation result after 25 epoch: Word_acc: 0.938682 Word_acc_case_ins: 0.938682 Edit_distance_acc: 0.978486
[2025-01-24 18:18:19,499 - trainer - INFO] - Saving current best (at 25 epoch): model_best.pth Best word_acc: 0.938682
[2025-01-24 18:18:21,103 - trainer - INFO] - Train Epoch:[26/30] Step:[1/25169] Loss: 0.231567 Loss_avg: 0.231567 LR: 0.00003519 Loss Fine: 0.231567 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:21:41,228 - trainer - INFO] - Train Epoch:[26/30] Step:[1000/25169] Loss: 0.385372 Loss_avg: 0.294157 LR: 0.00003465 Loss Fine: 0.385372 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:25:01,461 - trainer - INFO] - Train Epoch:[26/30] Step:[2000/25169] Loss: 0.433684 Loss_avg: 0.296348 LR: 0.00003411 Loss Fine: 0.433684 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:28:21,659 - trainer - INFO] - Train Epoch:[26/30] Step:[3000/25169] Loss: 0.321691 Loss_avg: 0.295789 LR: 0.00003357 Loss Fine: 0.321691 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:28:27,255 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[3000/25169] Word_acc: 0.938030 Word_acc_case_ins 0.938030 Edit_distance_acc: 0.978412
[2025-01-24 18:31:47,361 - trainer - INFO] - Train Epoch:[26/30] Step:[4000/25169] Loss: 0.470593 Loss_avg: 0.296300 LR: 0.00003304 Loss Fine: 0.470593 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:35:07,525 - trainer - INFO] - Train Epoch:[26/30] Step:[5000/25169] Loss: 0.292648 Loss_avg: 0.296129 LR: 0.00003251 Loss Fine: 0.292648 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:38:27,680 - trainer - INFO] - Train Epoch:[26/30] Step:[6000/25169] Loss: 0.268470 Loss_avg: 0.296323 LR: 0.00003199 Loss Fine: 0.268470 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:38:33,232 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[6000/25169] Word_acc: 0.936204 Word_acc_case_ins 0.936204 Edit_distance_acc: 0.978069
[2025-01-24 18:41:53,487 - trainer - INFO] - Train Epoch:[26/30] Step:[7000/25169] Loss: 0.305321 Loss_avg: 0.296561 LR: 0.00003147 Loss Fine: 0.305321 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:45:13,745 - trainer - INFO] - Train Epoch:[26/30] Step:[8000/25169] Loss: 0.265378 Loss_avg: 0.296698 LR: 0.00003095 Loss Fine: 0.265378 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:48:33,961 - trainer - INFO] - Train Epoch:[26/30] Step:[9000/25169] Loss: 0.338590 Loss_avg: 0.296585 LR: 0.00003044 Loss Fine: 0.338590 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:48:39,545 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[9000/25169] Word_acc: 0.939204 Word_acc_case_ins 0.939204 Edit_distance_acc: 0.979100
[2025-01-24 18:48:39,857 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.939204
[2025-01-24 18:52:00,041 - trainer - INFO] - Train Epoch:[26/30] Step:[10000/25169] Loss: 0.347178 Loss_avg: 0.297015 LR: 0.00002993 Loss Fine: 0.347178 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:55:20,218 - trainer - INFO] - Train Epoch:[26/30] Step:[11000/25169] Loss: 0.337097 Loss_avg: 0.296695 LR: 0.00002943 Loss Fine: 0.337097 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:58:40,319 - trainer - INFO] - Train Epoch:[26/30] Step:[12000/25169] Loss: 0.418414 Loss_avg: 0.296342 LR: 0.00002893 Loss Fine: 0.418414 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 18:58:45,886 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[12000/25169] Word_acc: 0.938030 Word_acc_case_ins 0.938030 Edit_distance_acc: 0.978535
[2025-01-24 19:02:05,963 - trainer - INFO] - Train Epoch:[26/30] Step:[13000/25169] Loss: 0.217322 Loss_avg: 0.296314 LR: 0.00002843 Loss Fine: 0.217322 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:05:26,123 - trainer - INFO] - Train Epoch:[26/30] Step:[14000/25169] Loss: 0.293951 Loss_avg: 0.295986 LR: 0.00002794 Loss Fine: 0.293951 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:08:46,252 - trainer - INFO] - Train Epoch:[26/30] Step:[15000/25169] Loss: 0.208657 Loss_avg: 0.295843 LR: 0.00002745 Loss Fine: 0.208657 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:08:51,838 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[15000/25169] Word_acc: 0.938552 Word_acc_case_ins 0.938552 Edit_distance_acc: 0.978314
[2025-01-24 19:12:12,025 - trainer - INFO] - Train Epoch:[26/30] Step:[16000/25169] Loss: 0.355674 Loss_avg: 0.295762 LR: 0.00002697 Loss Fine: 0.355674 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:15:32,168 - trainer - INFO] - Train Epoch:[26/30] Step:[17000/25169] Loss: 0.316889 Loss_avg: 0.295629 LR: 0.00002649 Loss Fine: 0.316889 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:18:52,365 - trainer - INFO] - Train Epoch:[26/30] Step:[18000/25169] Loss: 0.277334 Loss_avg: 0.295559 LR: 0.00002601 Loss Fine: 0.277334 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:18:57,967 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[18000/25169] Word_acc: 0.938682 Word_acc_case_ins 0.938682 Edit_distance_acc: 0.978634
[2025-01-24 19:22:18,118 - trainer - INFO] - Train Epoch:[26/30] Step:[19000/25169] Loss: 0.384400 Loss_avg: 0.295222 LR: 0.00002554 Loss Fine: 0.384400 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:25:38,278 - trainer - INFO] - Train Epoch:[26/30] Step:[20000/25169] Loss: 0.265489 Loss_avg: 0.295077 LR: 0.00002507 Loss Fine: 0.265489 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:28:58,420 - trainer - INFO] - Train Epoch:[26/30] Step:[21000/25169] Loss: 0.267128 Loss_avg: 0.294696 LR: 0.00002461 Loss Fine: 0.267128 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:29:04,016 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[21000/25169] Word_acc: 0.939596 Word_acc_case_ins 0.939596 Edit_distance_acc: 0.979198
[2025-01-24 19:29:04,325 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.939596
[2025-01-24 19:32:24,484 - trainer - INFO] - Train Epoch:[26/30] Step:[22000/25169] Loss: 0.247610 Loss_avg: 0.294579 LR: 0.00002415 Loss Fine: 0.247610 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:35:44,678 - trainer - INFO] - Train Epoch:[26/30] Step:[23000/25169] Loss: 0.241532 Loss_avg: 0.294526 LR: 0.00002369 Loss Fine: 0.241532 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:39:04,752 - trainer - INFO] - Train Epoch:[26/30] Step:[24000/25169] Loss: 0.275354 Loss_avg: 0.294453 LR: 0.00002324 Loss Fine: 0.275354 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:39:10,350 - trainer - INFO] - [Step Validation] Epoch:[26/30] Step:[24000/25169] Word_acc: 0.940770 Word_acc_case_ins 0.940770 Edit_distance_acc: 0.980009
[2025-01-24 19:39:10,681 - trainer - INFO] - Saving current best (at 26 epoch): model_best.pth Best word_acc: 0.940770
[2025-01-24 19:42:31,011 - trainer - INFO] - Train Epoch:[26/30] Step:[25000/25169] Loss: 0.188600 Loss_avg: 0.294311 LR: 0.00002280 Loss Fine: 0.188600 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:43:10,628 - trainer - INFO] - [Epoch End] Epoch:[26/30] Loss: 0.294376 LR: 0.00002272
 Validation result after 26 epoch: Word_acc: 0.938813 Word_acc_case_ins: 0.938813 Edit_distance_acc: 0.978855
[2025-01-24 19:43:12,294 - trainer - INFO] - Train Epoch:[27/30] Step:[1/25169] Loss: 0.306032 Loss_avg: 0.306032 LR: 0.00002272 Loss Fine: 0.306032 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:46:32,267 - trainer - INFO] - Train Epoch:[27/30] Step:[1000/25169] Loss: 0.276583 Loss_avg: 0.287595 LR: 0.00002228 Loss Fine: 0.276583 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:49:52,337 - trainer - INFO] - Train Epoch:[27/30] Step:[2000/25169] Loss: 0.187957 Loss_avg: 0.285476 LR: 0.00002184 Loss Fine: 0.187957 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:53:12,408 - trainer - INFO] - Train Epoch:[27/30] Step:[3000/25169] Loss: 0.318093 Loss_avg: 0.285168 LR: 0.00002141 Loss Fine: 0.318093 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:53:18,044 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[3000/25169] Word_acc: 0.939335 Word_acc_case_ins 0.939335 Edit_distance_acc: 0.979321
[2025-01-24 19:56:38,159 - trainer - INFO] - Train Epoch:[27/30] Step:[4000/25169] Loss: 0.288375 Loss_avg: 0.285335 LR: 0.00002098 Loss Fine: 0.288375 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 19:59:58,384 - trainer - INFO] - Train Epoch:[27/30] Step:[5000/25169] Loss: 0.361806 Loss_avg: 0.286058 LR: 0.00002055 Loss Fine: 0.361806 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:03:18,556 - trainer - INFO] - Train Epoch:[27/30] Step:[6000/25169] Loss: 0.264093 Loss_avg: 0.285230 LR: 0.00002013 Loss Fine: 0.264093 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:03:24,146 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[6000/25169] Word_acc: 0.940117 Word_acc_case_ins 0.940117 Edit_distance_acc: 0.979223
[2025-01-24 20:06:44,286 - trainer - INFO] - Train Epoch:[27/30] Step:[7000/25169] Loss: 0.543489 Loss_avg: 0.284666 LR: 0.00001971 Loss Fine: 0.543489 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:10:04,380 - trainer - INFO] - Train Epoch:[27/30] Step:[8000/25169] Loss: 0.361766 Loss_avg: 0.284754 LR: 0.00001930 Loss Fine: 0.361766 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:13:24,480 - trainer - INFO] - Train Epoch:[27/30] Step:[9000/25169] Loss: 0.362077 Loss_avg: 0.284481 LR: 0.00001889 Loss Fine: 0.362077 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:13:30,055 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[9000/25169] Word_acc: 0.940248 Word_acc_case_ins 0.940248 Edit_distance_acc: 0.979616
[2025-01-24 20:16:50,204 - trainer - INFO] - Train Epoch:[27/30] Step:[10000/25169] Loss: 0.216949 Loss_avg: 0.284165 LR: 0.00001849 Loss Fine: 0.216949 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:20:10,328 - trainer - INFO] - Train Epoch:[27/30] Step:[11000/25169] Loss: 0.309916 Loss_avg: 0.284073 LR: 0.00001808 Loss Fine: 0.309916 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:23:30,468 - trainer - INFO] - Train Epoch:[27/30] Step:[12000/25169] Loss: 0.200331 Loss_avg: 0.284115 LR: 0.00001769 Loss Fine: 0.200331 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:23:36,080 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[12000/25169] Word_acc: 0.940248 Word_acc_case_ins 0.940248 Edit_distance_acc: 0.979444
[2025-01-24 20:26:56,269 - trainer - INFO] - Train Epoch:[27/30] Step:[13000/25169] Loss: 0.449779 Loss_avg: 0.284017 LR: 0.00001730 Loss Fine: 0.449779 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:30:16,372 - trainer - INFO] - Train Epoch:[27/30] Step:[14000/25169] Loss: 0.380923 Loss_avg: 0.283790 LR: 0.00001691 Loss Fine: 0.380923 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:33:36,480 - trainer - INFO] - Train Epoch:[27/30] Step:[15000/25169] Loss: 0.478677 Loss_avg: 0.283592 LR: 0.00001653 Loss Fine: 0.478677 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:33:42,087 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[15000/25169] Word_acc: 0.941422 Word_acc_case_ins 0.941422 Edit_distance_acc: 0.979861
[2025-01-24 20:33:42,402 - trainer - INFO] - Saving current best (at 27 epoch): model_best.pth Best word_acc: 0.941422
[2025-01-24 20:37:02,457 - trainer - INFO] - Train Epoch:[27/30] Step:[16000/25169] Loss: 0.247369 Loss_avg: 0.283250 LR: 0.00001615 Loss Fine: 0.247369 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:40:22,561 - trainer - INFO] - Train Epoch:[27/30] Step:[17000/25169] Loss: 0.333449 Loss_avg: 0.283111 LR: 0.00001577 Loss Fine: 0.333449 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:43:42,681 - trainer - INFO] - Train Epoch:[27/30] Step:[18000/25169] Loss: 0.278322 Loss_avg: 0.282755 LR: 0.00001540 Loss Fine: 0.278322 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:43:48,313 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[18000/25169] Word_acc: 0.939987 Word_acc_case_ins 0.939987 Edit_distance_acc: 0.979493
[2025-01-24 20:47:08,415 - trainer - INFO] - Train Epoch:[27/30] Step:[19000/25169] Loss: 0.294039 Loss_avg: 0.282661 LR: 0.00001503 Loss Fine: 0.294039 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:50:28,586 - trainer - INFO] - Train Epoch:[27/30] Step:[20000/25169] Loss: 0.307281 Loss_avg: 0.282536 LR: 0.00001467 Loss Fine: 0.307281 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:53:48,716 - trainer - INFO] - Train Epoch:[27/30] Step:[21000/25169] Loss: 0.213017 Loss_avg: 0.282431 LR: 0.00001431 Loss Fine: 0.213017 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 20:53:54,280 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[21000/25169] Word_acc: 0.940248 Word_acc_case_ins 0.940248 Edit_distance_acc: 0.979567
[2025-01-24 20:57:14,372 - trainer - INFO] - Train Epoch:[27/30] Step:[22000/25169] Loss: 0.238242 Loss_avg: 0.282302 LR: 0.00001396 Loss Fine: 0.238242 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:00:34,487 - trainer - INFO] - Train Epoch:[27/30] Step:[23000/25169] Loss: 0.286736 Loss_avg: 0.282289 LR: 0.00001361 Loss Fine: 0.286736 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:03:54,529 - trainer - INFO] - Train Epoch:[27/30] Step:[24000/25169] Loss: 0.282595 Loss_avg: 0.282224 LR: 0.00001327 Loss Fine: 0.282595 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:04:00,059 - trainer - INFO] - [Step Validation] Epoch:[27/30] Step:[24000/25169] Word_acc: 0.941161 Word_acc_case_ins 0.941161 Edit_distance_acc: 0.979861
[2025-01-24 21:07:20,164 - trainer - INFO] - Train Epoch:[27/30] Step:[25000/25169] Loss: 0.222329 Loss_avg: 0.281877 LR: 0.00001292 Loss Fine: 0.222329 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:07:59,763 - trainer - INFO] - [Epoch End] Epoch:[27/30] Loss: 0.281820 LR: 0.00001287
 Validation result after 27 epoch: Word_acc: 0.940770 Word_acc_case_ins: 0.940770 Edit_distance_acc: 0.979591
[2025-01-24 21:08:01,377 - trainer - INFO] - Train Epoch:[28/30] Step:[1/25169] Loss: 0.271008 Loss_avg: 0.271008 LR: 0.00001287 Loss Fine: 0.271008 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:11:21,343 - trainer - INFO] - Train Epoch:[28/30] Step:[1000/25169] Loss: 0.279115 Loss_avg: 0.272157 LR: 0.00001253 Loss Fine: 0.279115 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:14:41,420 - trainer - INFO] - Train Epoch:[28/30] Step:[2000/25169] Loss: 0.277132 Loss_avg: 0.273838 LR: 0.00001220 Loss Fine: 0.277132 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:18:01,618 - trainer - INFO] - Train Epoch:[28/30] Step:[3000/25169] Loss: 0.191959 Loss_avg: 0.275161 LR: 0.00001187 Loss Fine: 0.191959 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:18:07,205 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[3000/25169] Word_acc: 0.941944 Word_acc_case_ins 0.941944 Edit_distance_acc: 0.979886
[2025-01-24 21:18:07,545 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.941944
[2025-01-24 21:21:27,694 - trainer - INFO] - Train Epoch:[28/30] Step:[4000/25169] Loss: 0.322179 Loss_avg: 0.275412 LR: 0.00001155 Loss Fine: 0.322179 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:24:47,945 - trainer - INFO] - Train Epoch:[28/30] Step:[5000/25169] Loss: 0.217538 Loss_avg: 0.275774 LR: 0.00001123 Loss Fine: 0.217538 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:28:08,223 - trainer - INFO] - Train Epoch:[28/30] Step:[6000/25169] Loss: 0.166224 Loss_avg: 0.275424 LR: 0.00001092 Loss Fine: 0.166224 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:28:13,809 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[6000/25169] Word_acc: 0.940900 Word_acc_case_ins 0.940900 Edit_distance_acc: 0.980107
[2025-01-24 21:31:33,914 - trainer - INFO] - Train Epoch:[28/30] Step:[7000/25169] Loss: 0.237950 Loss_avg: 0.274735 LR: 0.00001061 Loss Fine: 0.237950 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:34:54,085 - trainer - INFO] - Train Epoch:[28/30] Step:[8000/25169] Loss: 0.185552 Loss_avg: 0.274611 LR: 0.00001030 Loss Fine: 0.185552 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:38:14,208 - trainer - INFO] - Train Epoch:[28/30] Step:[9000/25169] Loss: 0.228507 Loss_avg: 0.274432 LR: 0.00001000 Loss Fine: 0.228507 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:38:19,811 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[9000/25169] Word_acc: 0.940900 Word_acc_case_ins 0.940900 Edit_distance_acc: 0.980107
[2025-01-24 21:41:39,916 - trainer - INFO] - Train Epoch:[28/30] Step:[10000/25169] Loss: 0.256006 Loss_avg: 0.274063 LR: 0.00000971 Loss Fine: 0.256006 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:44:59,998 - trainer - INFO] - Train Epoch:[28/30] Step:[11000/25169] Loss: 0.261322 Loss_avg: 0.274218 LR: 0.00000941 Loss Fine: 0.261322 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:48:20,033 - trainer - INFO] - Train Epoch:[28/30] Step:[12000/25169] Loss: 0.276475 Loss_avg: 0.273858 LR: 0.00000913 Loss Fine: 0.276475 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:48:25,621 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[12000/25169] Word_acc: 0.942466 Word_acc_case_ins 0.942466 Edit_distance_acc: 0.980132
[2025-01-24 21:48:25,936 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.942466
[2025-01-24 21:51:46,113 - trainer - INFO] - Train Epoch:[28/30] Step:[13000/25169] Loss: 0.239132 Loss_avg: 0.273877 LR: 0.00000884 Loss Fine: 0.239132 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:55:06,398 - trainer - INFO] - Train Epoch:[28/30] Step:[14000/25169] Loss: 0.195546 Loss_avg: 0.273957 LR: 0.00000856 Loss Fine: 0.195546 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:58:26,655 - trainer - INFO] - Train Epoch:[28/30] Step:[15000/25169] Loss: 0.290162 Loss_avg: 0.273791 LR: 0.00000829 Loss Fine: 0.290162 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 21:58:32,249 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[15000/25169] Word_acc: 0.943118 Word_acc_case_ins 0.943118 Edit_distance_acc: 0.980230
[2025-01-24 21:58:32,571 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.943118
[2025-01-24 22:01:52,664 - trainer - INFO] - Train Epoch:[28/30] Step:[16000/25169] Loss: 0.293808 Loss_avg: 0.273654 LR: 0.00000802 Loss Fine: 0.293808 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:05:12,799 - trainer - INFO] - Train Epoch:[28/30] Step:[17000/25169] Loss: 0.285187 Loss_avg: 0.273291 LR: 0.00000775 Loss Fine: 0.285187 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:08:32,991 - trainer - INFO] - Train Epoch:[28/30] Step:[18000/25169] Loss: 0.308950 Loss_avg: 0.273206 LR: 0.00000749 Loss Fine: 0.308950 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:08:38,590 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[18000/25169] Word_acc: 0.942466 Word_acc_case_ins 0.942466 Edit_distance_acc: 0.980033
[2025-01-24 22:11:58,778 - trainer - INFO] - Train Epoch:[28/30] Step:[19000/25169] Loss: 0.262738 Loss_avg: 0.273099 LR: 0.00000723 Loss Fine: 0.262738 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:15:18,868 - trainer - INFO] - Train Epoch:[28/30] Step:[20000/25169] Loss: 0.237321 Loss_avg: 0.273264 LR: 0.00000698 Loss Fine: 0.237321 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:18:39,039 - trainer - INFO] - Train Epoch:[28/30] Step:[21000/25169] Loss: 0.236979 Loss_avg: 0.273386 LR: 0.00000673 Loss Fine: 0.236979 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:18:44,695 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[21000/25169] Word_acc: 0.942727 Word_acc_case_ins 0.942727 Edit_distance_acc: 0.980107
[2025-01-24 22:22:04,783 - trainer - INFO] - Train Epoch:[28/30] Step:[22000/25169] Loss: 0.268039 Loss_avg: 0.273275 LR: 0.00000649 Loss Fine: 0.268039 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:25:24,924 - trainer - INFO] - Train Epoch:[28/30] Step:[23000/25169] Loss: 0.242181 Loss_avg: 0.273125 LR: 0.00000625 Loss Fine: 0.242181 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:28:45,056 - trainer - INFO] - Train Epoch:[28/30] Step:[24000/25169] Loss: 0.204366 Loss_avg: 0.273162 LR: 0.00000602 Loss Fine: 0.204366 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:28:50,662 - trainer - INFO] - [Step Validation] Epoch:[28/30] Step:[24000/25169] Word_acc: 0.943509 Word_acc_case_ins 0.943509 Edit_distance_acc: 0.980574
[2025-01-24 22:28:50,982 - trainer - INFO] - Saving current best (at 28 epoch): model_best.pth Best word_acc: 0.943509
[2025-01-24 22:32:11,194 - trainer - INFO] - Train Epoch:[28/30] Step:[25000/25169] Loss: 0.405048 Loss_avg: 0.273017 LR: 0.00000579 Loss Fine: 0.405048 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:32:50,805 - trainer - INFO] - [Epoch End] Epoch:[28/30] Loss: 0.272975 LR: 0.00000575
 Validation result after 28 epoch: Word_acc: 0.941944 Word_acc_case_ins: 0.941944 Edit_distance_acc: 0.980132
[2025-01-24 22:32:52,508 - trainer - INFO] - Train Epoch:[29/30] Step:[1/25169] Loss: 0.341331 Loss_avg: 0.341331 LR: 0.00000575 Loss Fine: 0.341331 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:36:12,509 - trainer - INFO] - Train Epoch:[29/30] Step:[1000/25169] Loss: 0.185652 Loss_avg: 0.269611 LR: 0.00000552 Loss Fine: 0.185652 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:39:32,687 - trainer - INFO] - Train Epoch:[29/30] Step:[2000/25169] Loss: 0.373092 Loss_avg: 0.268742 LR: 0.00000530 Loss Fine: 0.373092 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:42:52,839 - trainer - INFO] - Train Epoch:[29/30] Step:[3000/25169] Loss: 0.249798 Loss_avg: 0.268117 LR: 0.00000509 Loss Fine: 0.249798 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:42:58,430 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[3000/25169] Word_acc: 0.942596 Word_acc_case_ins 0.942596 Edit_distance_acc: 0.980304
[2025-01-24 22:46:18,596 - trainer - INFO] - Train Epoch:[29/30] Step:[4000/25169] Loss: 0.303139 Loss_avg: 0.267317 LR: 0.00000487 Loss Fine: 0.303139 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:49:38,764 - trainer - INFO] - Train Epoch:[29/30] Step:[5000/25169] Loss: 0.249309 Loss_avg: 0.267126 LR: 0.00000467 Loss Fine: 0.249309 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:53:05,686 - trainer - INFO] - Train Epoch:[29/30] Step:[6000/25169] Loss: 0.258732 Loss_avg: 0.266999 LR: 0.00000446 Loss Fine: 0.258732 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:53:11,278 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[6000/25169] Word_acc: 0.942466 Word_acc_case_ins 0.942466 Edit_distance_acc: 0.980304
[2025-01-24 22:56:31,457 - trainer - INFO] - Train Epoch:[29/30] Step:[7000/25169] Loss: 0.273649 Loss_avg: 0.266526 LR: 0.00000426 Loss Fine: 0.273649 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 22:59:51,604 - trainer - INFO] - Train Epoch:[29/30] Step:[8000/25169] Loss: 0.368433 Loss_avg: 0.266550 LR: 0.00000407 Loss Fine: 0.368433 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:03:11,743 - trainer - INFO] - Train Epoch:[29/30] Step:[9000/25169] Loss: 0.364439 Loss_avg: 0.266480 LR: 0.00000388 Loss Fine: 0.364439 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:03:17,359 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[9000/25169] Word_acc: 0.941944 Word_acc_case_ins 0.941944 Edit_distance_acc: 0.980181
[2025-01-24 23:06:37,532 - trainer - INFO] - Train Epoch:[29/30] Step:[10000/25169] Loss: 0.403795 Loss_avg: 0.266379 LR: 0.00000370 Loss Fine: 0.403795 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:09:57,619 - trainer - INFO] - Train Epoch:[29/30] Step:[11000/25169] Loss: 0.138489 Loss_avg: 0.266151 LR: 0.00000352 Loss Fine: 0.138489 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:13:17,695 - trainer - INFO] - Train Epoch:[29/30] Step:[12000/25169] Loss: 0.342340 Loss_avg: 0.266102 LR: 0.00000334 Loss Fine: 0.342340 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:13:23,261 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[12000/25169] Word_acc: 0.942857 Word_acc_case_ins 0.942857 Edit_distance_acc: 0.980304
[2025-01-24 23:16:43,386 - trainer - INFO] - Train Epoch:[29/30] Step:[13000/25169] Loss: 0.414859 Loss_avg: 0.266145 LR: 0.00000317 Loss Fine: 0.414859 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:20:03,519 - trainer - INFO] - Train Epoch:[29/30] Step:[14000/25169] Loss: 0.219720 Loss_avg: 0.266304 LR: 0.00000300 Loss Fine: 0.219720 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:23:23,651 - trainer - INFO] - Train Epoch:[29/30] Step:[15000/25169] Loss: 0.205424 Loss_avg: 0.266175 LR: 0.00000284 Loss Fine: 0.205424 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:23:29,221 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[15000/25169] Word_acc: 0.943249 Word_acc_case_ins 0.943249 Edit_distance_acc: 0.980205
[2025-01-24 23:26:49,429 - trainer - INFO] - Train Epoch:[29/30] Step:[16000/25169] Loss: 0.308093 Loss_avg: 0.266028 LR: 0.00000268 Loss Fine: 0.308093 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:30:09,688 - trainer - INFO] - Train Epoch:[29/30] Step:[17000/25169] Loss: 0.259712 Loss_avg: 0.265948 LR: 0.00000253 Loss Fine: 0.259712 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:33:29,920 - trainer - INFO] - Train Epoch:[29/30] Step:[18000/25169] Loss: 0.302257 Loss_avg: 0.265774 LR: 0.00000238 Loss Fine: 0.302257 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:33:35,497 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[18000/25169] Word_acc: 0.942335 Word_acc_case_ins 0.942335 Edit_distance_acc: 0.980205
[2025-01-24 23:36:55,585 - trainer - INFO] - Train Epoch:[29/30] Step:[19000/25169] Loss: 0.275300 Loss_avg: 0.265720 LR: 0.00000223 Loss Fine: 0.275300 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:40:15,773 - trainer - INFO] - Train Epoch:[29/30] Step:[20000/25169] Loss: 0.308809 Loss_avg: 0.265570 LR: 0.00000209 Loss Fine: 0.308809 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:43:35,960 - trainer - INFO] - Train Epoch:[29/30] Step:[21000/25169] Loss: 0.311445 Loss_avg: 0.265599 LR: 0.00000196 Loss Fine: 0.311445 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:43:41,541 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[21000/25169] Word_acc: 0.941813 Word_acc_case_ins 0.941813 Edit_distance_acc: 0.980205
[2025-01-24 23:47:01,713 - trainer - INFO] - Train Epoch:[29/30] Step:[22000/25169] Loss: 0.232830 Loss_avg: 0.265331 LR: 0.00000183 Loss Fine: 0.232830 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:50:21,844 - trainer - INFO] - Train Epoch:[29/30] Step:[23000/25169] Loss: 0.184430 Loss_avg: 0.265409 LR: 0.00000170 Loss Fine: 0.184430 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:53:41,951 - trainer - INFO] - Train Epoch:[29/30] Step:[24000/25169] Loss: 0.323830 Loss_avg: 0.265360 LR: 0.00000158 Loss Fine: 0.323830 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:53:47,579 - trainer - INFO] - [Step Validation] Epoch:[29/30] Step:[24000/25169] Word_acc: 0.942466 Word_acc_case_ins 0.942466 Edit_distance_acc: 0.980475
[2025-01-24 23:57:07,683 - trainer - INFO] - Train Epoch:[29/30] Step:[25000/25169] Loss: 0.404100 Loss_avg: 0.265564 LR: 0.00000146 Loss Fine: 0.404100 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-24 23:57:47,326 - trainer - INFO] - [Epoch End] Epoch:[29/30] Loss: 0.265551 LR: 0.00000144
 Validation result after 29 epoch: Word_acc: 0.943509 Word_acc_case_ins: 0.943509 Edit_distance_acc: 0.980721
[2025-01-24 23:57:47,660 - trainer - INFO] - Saving current best (at 29 epoch): model_best.pth Best word_acc: 0.943509
[2025-01-24 23:57:49,283 - trainer - INFO] - Train Epoch:[30/30] Step:[1/25169] Loss: 0.248219 Loss_avg: 0.248219 LR: 0.00000144 Loss Fine: 0.248219 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:01:09,269 - trainer - INFO] - Train Epoch:[30/30] Step:[1000/25169] Loss: 0.351755 Loss_avg: 0.260665 LR: 0.00000133 Loss Fine: 0.351755 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:04:29,412 - trainer - INFO] - Train Epoch:[30/30] Step:[2000/25169] Loss: 0.330951 Loss_avg: 0.261071 LR: 0.00000122 Loss Fine: 0.330951 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:07:49,532 - trainer - INFO] - Train Epoch:[30/30] Step:[3000/25169] Loss: 0.174522 Loss_avg: 0.261024 LR: 0.00000112 Loss Fine: 0.174522 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:07:55,156 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[3000/25169] Word_acc: 0.942857 Word_acc_case_ins 0.942857 Edit_distance_acc: 0.980205
[2025-01-25 00:11:15,309 - trainer - INFO] - Train Epoch:[30/30] Step:[4000/25169] Loss: 0.250541 Loss_avg: 0.262035 LR: 0.00000102 Loss Fine: 0.250541 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:14:35,448 - trainer - INFO] - Train Epoch:[30/30] Step:[5000/25169] Loss: 0.299027 Loss_avg: 0.261938 LR: 0.00000093 Loss Fine: 0.299027 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:17:55,519 - trainer - INFO] - Train Epoch:[30/30] Step:[6000/25169] Loss: 0.253490 Loss_avg: 0.261310 LR: 0.00000084 Loss Fine: 0.253490 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:18:01,098 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[6000/25169] Word_acc: 0.943640 Word_acc_case_ins 0.943640 Edit_distance_acc: 0.980304
[2025-01-25 00:18:01,415 - trainer - INFO] - Saving current best (at 30 epoch): model_best.pth Best word_acc: 0.943640
[2025-01-25 00:21:21,589 - trainer - INFO] - Train Epoch:[30/30] Step:[7000/25169] Loss: 0.289215 Loss_avg: 0.261850 LR: 0.00000075 Loss Fine: 0.289215 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:24:41,738 - trainer - INFO] - Train Epoch:[30/30] Step:[8000/25169] Loss: 0.170402 Loss_avg: 0.262102 LR: 0.00000067 Loss Fine: 0.170402 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:28:01,830 - trainer - INFO] - Train Epoch:[30/30] Step:[9000/25169] Loss: 0.170211 Loss_avg: 0.262133 LR: 0.00000060 Loss Fine: 0.170211 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:28:07,472 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[9000/25169] Word_acc: 0.942988 Word_acc_case_ins 0.942988 Edit_distance_acc: 0.980377
[2025-01-25 00:31:27,649 - trainer - INFO] - Train Epoch:[30/30] Step:[10000/25169] Loss: 0.225841 Loss_avg: 0.261972 LR: 0.00000053 Loss Fine: 0.225841 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:34:47,857 - trainer - INFO] - Train Epoch:[30/30] Step:[11000/25169] Loss: 0.352585 Loss_avg: 0.262121 LR: 0.00000046 Loss Fine: 0.352585 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:38:08,124 - trainer - INFO] - Train Epoch:[30/30] Step:[12000/25169] Loss: 0.337134 Loss_avg: 0.262431 LR: 0.00000040 Loss Fine: 0.337134 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:38:13,721 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[12000/25169] Word_acc: 0.943901 Word_acc_case_ins 0.943901 Edit_distance_acc: 0.980304
[2025-01-25 00:38:14,028 - trainer - INFO] - Saving current best (at 30 epoch): model_best.pth Best word_acc: 0.943901
[2025-01-25 00:41:34,157 - trainer - INFO] - Train Epoch:[30/30] Step:[13000/25169] Loss: 0.143931 Loss_avg: 0.262572 LR: 0.00000034 Loss Fine: 0.143931 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:44:54,295 - trainer - INFO] - Train Epoch:[30/30] Step:[14000/25169] Loss: 0.310206 Loss_avg: 0.262607 LR: 0.00000029 Loss Fine: 0.310206 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:48:14,410 - trainer - INFO] - Train Epoch:[30/30] Step:[15000/25169] Loss: 0.186901 Loss_avg: 0.262605 LR: 0.00000024 Loss Fine: 0.186901 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:48:19,984 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[15000/25169] Word_acc: 0.943249 Word_acc_case_ins 0.943249 Edit_distance_acc: 0.980279
[2025-01-25 00:51:40,165 - trainer - INFO] - Train Epoch:[30/30] Step:[16000/25169] Loss: 0.254932 Loss_avg: 0.262699 LR: 0.00000019 Loss Fine: 0.254932 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:55:00,294 - trainer - INFO] - Train Epoch:[30/30] Step:[17000/25169] Loss: 0.367752 Loss_avg: 0.262651 LR: 0.00000015 Loss Fine: 0.367752 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:58:20,432 - trainer - INFO] - Train Epoch:[30/30] Step:[18000/25169] Loss: 0.144907 Loss_avg: 0.262398 LR: 0.00000012 Loss Fine: 0.144907 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 00:58:26,101 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[18000/25169] Word_acc: 0.943640 Word_acc_case_ins 0.943640 Edit_distance_acc: 0.980377
[2025-01-25 01:01:46,158 - trainer - INFO] - Train Epoch:[30/30] Step:[19000/25169] Loss: 0.249638 Loss_avg: 0.262427 LR: 0.00000009 Loss Fine: 0.249638 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:05:06,272 - trainer - INFO] - Train Epoch:[30/30] Step:[20000/25169] Loss: 0.208439 Loss_avg: 0.262541 LR: 0.00000006 Loss Fine: 0.208439 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:08:26,375 - trainer - INFO] - Train Epoch:[30/30] Step:[21000/25169] Loss: 0.325387 Loss_avg: 0.262632 LR: 0.00000004 Loss Fine: 0.325387 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:08:31,978 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[21000/25169] Word_acc: 0.943640 Word_acc_case_ins 0.943640 Edit_distance_acc: 0.980230
[2025-01-25 01:11:52,069 - trainer - INFO] - Train Epoch:[30/30] Step:[22000/25169] Loss: 0.356022 Loss_avg: 0.262583 LR: 0.00000002 Loss Fine: 0.356022 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:15:12,141 - trainer - INFO] - Train Epoch:[30/30] Step:[23000/25169] Loss: 0.218325 Loss_avg: 0.262602 LR: 0.00000001 Loss Fine: 0.218325 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:18:32,254 - trainer - INFO] - Train Epoch:[30/30] Step:[24000/25169] Loss: 0.210890 Loss_avg: 0.262434 LR: 0.00000001 Loss Fine: 0.210890 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:18:37,894 - trainer - INFO] - [Step Validation] Epoch:[30/30] Step:[24000/25169] Word_acc: 0.943640 Word_acc_case_ins 0.943640 Edit_distance_acc: 0.980230
[2025-01-25 01:21:58,200 - trainer - INFO] - Train Epoch:[30/30] Step:[25000/25169] Loss: 0.340602 Loss_avg: 0.262305 LR: 0.00000000 Loss Fine: 0.340602 Loss Coarse: 0.000000 Loss Length: 0.000000 Loss ITC: 0.000000
[2025-01-25 01:22:37,906 - trainer - INFO] - [Epoch End] Epoch:[30/30] Loss: 0.262352 LR: 0.00000000
 Validation result after 30 epoch: Word_acc: 0.943640 Word_acc_case_ins: 0.943640 Edit_distance_acc: 0.980205
[2025-01-25 01:22:37,915 - train - INFO] - Distributed training end...
